---
site: bookdown::bookdown_site
output: bookdown::gitbook
---

# Biostatistiques {#chapitre-biostats}

 ***
Ô∏è\ **Objectifs sp√©cifiques**:

√Ä la fin de ce chapitre, vous

- serez en mesure de d√©finir les concepts de base en statistique: population, √©chantillon, variable, probabilit√© et distribution
- serez en mesure de calculer des statistiques descriptives de base: moyenne et √©cart-type, quartiles, maximum et minimum
- comprendrez les notions de test d'hypoth√®se, d'effet et de p-value, ainsi qu'√©viter les erreurs communes dans leur interpr√©tation
- saurez effectuer une mod√©lisation statistique lin√©aire simple, multiple et mixte, entre autre sur des cat√©gories
- saurez effectuer une mod√©lisation statistique non lin√©aire simple, multiple et mixte

 ***

Aux chapitres pr√©c√©dents, nous avons vu comment visualiser, organiser et manipuler des tableaux de donn√©es. La statistique est une collection de disciplines li√©es √† la collecte, l‚Äôorganisation, l'analyse, l'interpr√©tation et la pr√©sentation de donn√©es. Les biostatistiques sont des applications de ces disciplines √† la biosph√®re.

Dans [*Principles and procedures of statistics: A biometrical approach*](https://www.amazon.com/Principles-Procedures-Statistics-Biometrical-Approach/dp/0070610282), Steel, Torie et Dickey (1997) d√©finissent les statistiques ainsi:

> Les statistiques forment la science, pure et appliqu√©e, de la cr√©ation, du d√©veloppement, et de l'application de techniques par lesquelles l'incertitude de l'induction inf√©rentielle peut √™tre √©valu√©e. (ma traduction)

Alors que l'**inf√©rence** consiste √† g√©n√©raliser des √©chantillons √† l'ensemble d'une population, l'**induction** est un type de raisonnement qui permet de g√©n√©raliser des observations sous forme de th√©ories. En d'autres mots, les statistiques permettent d'√©valuer l'incertitude sur des processus, de passer par infrence de l'√©chantillon √† la population, puis par induction de passer de cette repr√©sentation d'une population en lois g√©n√©rales la concernant.

La d√©finition de Whitlock et Schuluter (2015), dans [The Analysis of Biological Data](http://whitlockschluter.zoology.ubc.ca/), est plus simple et n'insiste que sur l'inf√©rence:

> La statistique est l‚Äô√©tude des m√©thodes pour mesurer des aspects de populations √† partir d‚Äô√©chantillons et pour quantifier l'incertitude des mesures. (ma traduction)

Les statistiques consistent √† *faire du sens* (anglicisme assum√©) avec des observations dans l'objectif de r√©pondre √† une question que vous aurez formul√©e clairement, pr√©alablement √† votre exp√©rience.

<blockquote class="twitter-tweet" data-lang="fr"><p lang="en" dir="ltr">The more time I spend as The Statistician in the room, the more I think the best skill you can cultivate is the ability to remain calm and repeatedly ask &quot;What question are you trying to answer?&quot;</p>&mdash; Bryan Howie (@bryan_howie) <a href="https://twitter.com/bryan_howie/status/1073054519808876544?ref_src=twsrc%5Etfw">13 d√©cembre 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

Le flux de travail conventionnel en statistiques consiste √† collecter des √©chantillons, transformer (pr√©traiter) les donn√©es, effectuer des tests, analyser les r√©sultats, les interpr√©ter et les visualiser.

$$Collecte \rightarrow Pr√©traitement \rightarrow Tests~statistiques \rightarrow Analyse \rightarrow Interpr√©tation \rightarrow Visualisation $$

Ce chapitre √† lui seul est trop court pour permettre d'int√©grer toutes les connaissances n√©cessaires √† une utilisation raisonn√©e des statistiques, mais fourni les bases pour aller plus loin. Notez que les erreurs d'interpr√©tation statistiques sont courantes et la consultation de sp√©cialistes n'est souvent pas un luxe. Mais bien que les statistiques soient complexes, *la plupart des op√©rations statistiques peuvent √™tre effectu√©es sans l'assistance de statisticien.ne.s*... √† condition de comprendre suffisamment les concepts utilis√©s.

Dans ce chapitre, nous verrons comment r√©pondre correctement √† une question valide et ad√©quate avec l'aide d'outils de calcul scientifique. Nous couvrirons les notions de bases des distributions et des variables al√©atoires qui nous permettront d'effectuer des tests statistiques communs avec R. Nous couvrirons aussi les erreurs commun√©ment commises en recherche acad√©mique et les moyens simples de les √©viter.

En plus des modules de base de R nous utiliserons

* les modules de la **`tidyverse`**,
* le module de donn√©es agricoles **`agridat`**, ainsi que
* le module **`nlme`** sp√©cialis√© pour la mod√©lisation mixte.

Avant de survoler les applications statistiques avec R, je vais rapidement pr√©senter quelques notions importantes en statistiques : populations et √©chantillons, variables, probabilit√©s et distributions. Puis nous allons effectuer des tests d'hypoth√®se univari√©s (notamment les tests de *t* et les analyses de variance) et d√©tailler la notion controvers√©e de *p-value*. Je vais m'attarder plus longuement aux mod√®les lin√©aires g√©n√©ralis√©s, incluant en particulier des effets fixes et al√©atoires (mod√®les mixtes), qui fournissent une trousse d'analyse polyvalente en analyse multivari√©e. Je terminerai avec les perspectives multivari√©es que sont les matrices de covariance et de corr√©lation.

## Populations et √©chantillons

Le principe d'inf√©rence consiste √† g√©n√©raliser des conclusions √† l'√©chelle d'une population √† partir d'√©chantillons issus de cette population. Alors qu'une **population** contient tous les √©l√©ments √©tudi√©s, un **√©chantillon** d'une population est une observation unique. Une exp√©rience bien con√ßue fera en sorte que les √©chantillons soient repr√©sentatifs de la population qui, la plupart du temps, ne peut √™tre observ√©e enti√®rement pour des raisons pratiques.

Les principes d'exp√©rimentation servant de base √† la conception d'une bonne m√©thodologie sont pr√©sent√©s dans le cours [*Dispositifs exp√©rimentaux (BVG-7002)*](https://www.ulaval.ca/les-etudes/cours/repertoire/detailsCours/bvg-7002-dispositifs-experimentaux.html). √âgalement, je recommande le livre *Principes d'exp√©rimentation: planification des exp√©riences et analyse de leurs r√©sultats* de Pierre Dagnelie (2012), [disponible en ligne en format PDF](http://www.dagnelie.be/docpdf/ex2012.pdf). Un bon aper√ßu des dispositifs exp√©rimentaux est aussi pr√©sent√© dans [*Introductory Statistics with R*](https://www.springer.com/us/book/9780387790534), de Peter Dalgaard (2008), que vous pouvez t√©l√©charger [du site de la biblioth√®que de l'Universit√© Laval](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=*&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=introductory+statistics+with+R&rq.r.la=*&rq.r.loc=*&rq.r.pft=false&rq.r.ta=*&rq.r.td=*&rq.rows=15&rq.st=0) vous avez un identifiant autoris√©.

Une population est √©chantillonn√©e pour induire des **param√®tres**: un rendement typique dans des conditions m√©t√©orologiques, √©daphiques et manag√©riales donn√©es, la masse typique des faucons p√®lerins, m√¢les et femelles, le microbiome typique d'un sol agricole ou forestier, etc. Une **statistique** est une estimation d'un param√®tre calcul√©e √† partir des donn√©es, par exemple une moyenne et un √©cart-type, ou un intercept et une pente.

Par exemple, la moyenne ($\mu$) et l'√©cart-type ($\sigma$) d'une population sont estim√©s par les moyennes ($\bar{x}$) et √©carts-types ($s$) calcul√©s sur les donn√©es issues de l'√©chantillonnage.

Chaque param√®tre est li√©e √† une perspective que l'on d√©sire conna√Ætre chez une population. Ces angles d'observations sont les **variables**.

## Les variables

Nous avons abord√© au chapitre \@ref(chapitre-tableaux) la notion de *variable* par l'interm√©diaire d'une donn√©e. Une variable est l'observation d'une caract√©ristique d√©crivant un √©chantillon. Si la charact√©ristique varie d'un √©chantillon √† un autre sans que vous en expliquiez la raison (i.e. si identifier la source de la variabilit√© ne fait pas partie de votre exp√©rience), on parlera de variable al√©atoire. M√™me le hasard est r√©gi par certaines lois: ce qui est al√©atoire dans une variable peut √™tre d√©crit par des **lois de probabilit√©**, que nous verrons plus bas.

Mais restons aux variables pour l'instant. Par convention, on peut attribuer aux variables un symbole math√©matique. Par exemple, on peut donner √† la masse volumique d'un sol (qui est le r√©sultat d'une m√©thodologie pr√©cise) le symbole $\rho$. Lorsque l'on attribue une valeur √† $\rho$, on parle d'une donn√©e. Chaque donn√©e d'une observation a un indice qui lui est propre, que l'on d√©signe souvent par $i$, que l'on place en indice $\rho_i$. Pour la premi√®re donn√©e, on a $i=1$, donc $\rho_1$. Pour un nombre $n$ d'√©chantillons, on aura $\rho_1$, $\rho_2$, $\rho_3$, ..., $\rho_n$, formant le vecteur $\rho = \left[\rho_1, \rho_2, \rho_3, ..., \rho_n \right]$.

En R, une variable est associ√©e √† un vecteur ou une colonne d'un tableau.

```{r biostats-data}
rho <- c(1.34, 1.52, 1.26, 1.43, 1.39) # matrice 1D
data <- data.frame(rho = rho) # tableau
data
```

Il existe plusieurs types de variables, qui se regroupe en deux grandes cat√©gories: les **variables quantitatives** et les **variables qualitatives**.

### Variables quantitatives

Ces variables peuvent √™tre continues dans un espace √©chantillonnal r√©el ou discr√®tes dans un espace √©chantillonnal ne consid√©rant que des valeurs fixes. Notons que la notion de nombre r√©el est toujours une approximation en sciences exp√©rimentales comme en calcul num√©rique, √©tant donn√©e que l'on est limit√© par la pr√©cision des appareils comme par le nombre d'octets √† utiliser. Bien que les valeurs fixes des distributions discr√®tes ne soient pas toujours des valeurs enti√®res, c'est bien souvent le cas en biostatistiques comme en d√©mographie, o√π les d√©comptes d'individus sont souvent pr√©sents (et o√π la notion de fraction d'individus n'est pas accept√©e).

### Variables qualitatives

On exprime parfois qu'une variable qualitative est une variable impossible √† mesurer num√©riquement: une couleur, l'appartenance √† esp√®ce ou √† une s√©rie de sol. Pourtant, dans bien des cas, les variables qualitatives peut √™tre encod√©es en variables quantitatives. Par exemple, on peut accoler des pourcentages de sable, limon et argile √† un loam sableux, qui autrement est d√©crit par la classe texturale d'un sol. Pour une couleur, on peut lui associer une longueur d'onde ou des pourcentages de rouge, vert et bleu, ainsi qu'un ton. En ce qui a trait aux variables ordonn√©es, il est possible de supposer un √©talement. Par exemple, une variable d'intensit√© faible-moyenne-forte peut √™tre transform√©e lin√©airement en valeurs quantitatives -1, 0 et 1. Attention toutefois, l'√©talement peut parfois √™tre quadratique ou logarithmique. Les s√©ries de sol peuvent √™tre encod√©es par la proportion de gleyfication ([Parent et al., 2017](https://www.frontiersin.org/articles/10.3389/fenvs.2017.00081/full#B4)). Quant aux cat√©gories difficilement transformables en quantit√©s, on pourra passer par l'**encodage cat√©goriel**, souvent appel√© *dummyfication*, qui nous verrons plus loin. L'analyse qualitative consiste en l'analyse de verbatims, essentiellement utile en sciences sociales: nous n'en n'aurons pas besoin ici. Nous consid√©rerons les variables qualitatives comme des variables quantitatives qui n'ont pas subi de pr√©traitement.

## Les probabilit√©s

> ¬´ Nous sommes si √©loign√©s de conna√Ætre tous les agens de la nature, et leurs divers modes d'action ; qu'il ne serait pas philosophique de nier les ph√©nom√®nes, uniquement parce qu'ils sont inexplicables dans l'√©tat actuel de nos connaissances. Seulement, nous devons les examiner avec une attention d'autant plus scrupuleuse, qu'il para√Æt plus difficile de les admettre ; et c'est ici que le calcul des probabilit√©s devient indispensable, pour d√©terminer jusqu'√† quel point il faut multiplier les observations ou les exp√©riences, afin d'obtenir en faveur des agens qu'elles indiquent, une probabilit√© sup√©rieure aux raisons que l'on peut avoir d'ailleurs, de ne pas les admettre. ¬ª ‚Äî Pierre-Simon de Laplace

Une probabilit√© est la vraisemblance qu'un √©v√®nement se r√©alise chez un √©chantillon. Les probabilit√©s forment le cadre des syst√®mes stochastiques, c'est-√†-dire des syst√®mes trop complexes pour en conna√Ætre exactement les aboutissants, auxquels on attribue une part de hasard. Ces syst√®mes sont pr√©dominants dans les processus vivants.

On peut d√©gager deux perspectives sur les probabilit√©s: l'une passe par une interpr√©tation fr√©quentielle, l'autre bay√©sienne.

- L'interpr√©tation **fr√©quentielle** repr√©sente la fr√©quence des occurrences apr√®s un nombre infini d‚Äô√©v√®nements. Par exemple, si vous jouez √† pile ou face un grand nombre de fois, le nombre de pile sera √©gal √† la moiti√© du nombre de lanc√©s. *L'approche fr√©quentielle teste si les donn√©es concordent avec un mod√®le du r√©el*. Il s'agit de l'interpr√©tation commun√©ment utilis√©e.
- L'interpr√©tation **bay√©sienne** vise √† quantifier l'incertitude des ph√©nom√®nes. Dans cette perspective, plus l'information s'accumule, plus l'incertitude diminue. Cette approche gagne en notori√©t√© notamment parce qu'elle permet de d√©crire des ph√©nom√®nes qui, intrins√®quement, ne peuvent √™tre r√©p√©t√©s infiniment (absence d'asymptote), comme celles qui sont bien d√©finis dans le temps ou sur des populations limit√©s. *L'approche bay√©sienne √©value la probabilit√© que le mod√®le soit r√©el*.

Une erreur courante consiste √† aborder des statistiques fr√©quentielles comme des statistiques bay√©siennes. Par exemple, si l'on d√©sire √©valuer la probabilit√© de l‚Äôexistence de vie sur Mars, on devra passer par le bay√©sien, car avec les stats fr√©quentielles, l'on devra plut√¥t conclure si les donn√©es sont conformes ou non avec l'hypoth√®se de la vie sur Mars (exemple tir√©e du blogue [Dynamic Ecology](https://dynamicecology.wordpress.com/2011/10/11/frequentist-vs-bayesian-statistics-resources-to-help-you-choose/)).

Des rivalit√©s factices s'installent enter les tenants des diff√©rentes approches, dont chacune, en r√©alit√©, r√©pond √† des questions diff√©rentes dont il convient r√©fl√©chir sur les limitations. Bien que les statistiques bay√©siennes soient de plus en plus utilis√©es, nous ne couvrirons dans ce chapitre que l'approche fr√©quentielle. L'approche bay√©sienne est n√©anmoins trait√©e dans le chapitre \@ref(chapitre-biostats-bayes), qui est facultatif au cours.

## Les distributions

Une variable al√©atoire peut prendre des valeurs selon des mod√®les de distribution des probabilit√©s. Une distribution est une fonction math√©matique d√©crivant la probabilit√© d'observer une s√©rie d'√©v√®nements. Ces √©v√®nements peuvent √™tre des valeurs continues, des nombres entiers, des cat√©gories, des valeurs bool√©ennes (Vrai/Faux), etc. D√©pendemment du type de valeur et des observations obtenues, on peut associer des variables √† diff√©rentes lois de probabilit√©. Toujours, l'aire sous la courbe d'une distribution de probabilit√© est √©gale √† 1.

En statistiques inf√©rentielles, les distributions sont les mod√®les, comprenant certains param√®tres comme la moyenne et la variance pour les distributions normales, √† partir desquelles les donn√©es sont g√©n√©r√©es.

Il existe deux grandes familles de distribution: **discr√®tes** et **continues**. Les distributions discr√®tes sont contraintes √† des valeurs pr√©d√©finies (finies ou infinies), alors que les distributions continues prennent n√©cessairement un nombre infini de valeur, dont la probabilit√© ne peut pas √™tre √©valu√©e ponctuellement, mais sur un intervalle.

L'**esp√©rance** math√©matique est une fonction de tendance centrale, souvent d√©crite par un param√®tre. Il s'agit de la moyenne d'une population pour une distribution normale. La **variance**, quant √† elle, d√©crit la variabilit√© d'une population, i.e. son √©talement autour de l'esp√©rance. Pour une distribution normale, la variance d'une population est aussi appel√©e variance, souvent pr√©sent√©e par l'√©cart-type (√©gal √† la racine carr√©e de la variance).

### Distribution binomiale

En tant que sc√©nario √† deux issues possibles, des tirages √† pile ou face suivent une loi binomiale, comme toute variable bool√©enne prenant une valeur vraie ou fausse. En biostatistiques, les cas communs sont la pr√©sence/absence d'une esp√®ce, d'une maladie, d'un trait phylog√©n√©tique, ainsi que les cat√©gories encod√©es. Lorsque l'op√©ration ne comprend qu'un seul √©chantillon (i.e. un seul tirage √† pile ou face), il s'agit d'un cas particulier d'une loi binomiale que l'on nomme une loi de *Bernouilli*.

Pour 25 tirages √† pile ou face ind√©pendants (i.e. dont l'ordre des tirages ne compte pas), on peut dessiner une courbe de distribution dont la somme des probabilit√©s est de 1. La fonction `dbinom` est une fonction de distribution de probabilit√©s. Les fonctions de distribution de probabilit√©s discr√®tes sont appel√©es des fonctions de masse.

```{r biostats-binom}
library("tidyverse")
x <- 0:25
y <- dbinom(x = x, size = 25, prob = 0.5)
print(paste('La somme des probabilit√©s est de', sum(y)))
ggplot(data = tibble(x, y), mapping = aes(x, y)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y), color = "grey50") +
  geom_point()
```

### Distribution de Poisson

La loi de Poisson (avec un P majuscule, introduite par le math√©maticien fran√ßais Sim√©on Denis Poisson et non pas l'animal) d√©crit des distributions discr√®tes de probabilit√© d'un nombre d‚Äô√©v√®nements se produisant dans l'espace ou dans le temps. Les distributions de Poisson d√©crivent ce qui tient du d√©compte. Il peut s'agir du nombre de grenouilles traversant une rue quotidiennement, du nombre de plants d'ascl√©piades se trouvant sur une terre cultiv√©e, ou du nombre d‚Äô√©v√®nements de pr√©cipitation au mois de juin, etc. La distribution de Poisson n'a qu'un seul param√®tre, $\lambda$, qui d√©crit tant la moyenne des d√©comptes.

Par exemple, en un mois de 30 jours, et une moyenne de 8 √©v√®nements de pr√©cipitation pour ce mois, on obtient la distribution suivante.

```{r biostats-poisson}
x <- 1:30
y <- dpois(x, lambda = 8)
print(paste('La somme des probabilit√©s est de', sum(y)))
ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y), color = "grey50") +
  geom_point()
```

### Distribution uniforme

La distribution la plus simple est probablement la distribution uniforme. Si la variable est discr√®te, chaque cat√©gorie est associ√©e √† une probabilit√© √©gale. Si la variable est continue, la probabilit√© est directement proportionnelle √† la largeur de l'intervalle. On utilise rarement la distribution uniforme en biostatistiques, sinon pour d√©crire des *a priori* vagues pour l'analyse bay√©sienne (ce sujet est trait√© dans le chapitre \@ref(chapitre-biostats-bayes)). Nous utilisons la fonction `dunif`. √Ä la diff√©rence des distributions discr√®tes, les fonctions de distribution de probabilit√©s continues sont appel√©es des fonctions de densit√© d'une loi de probabilit√© (*probability density function*).

```{r biostats-unif}
increment <- 0.01
x <- seq(-4, 4, by = increment)
y1 <- dunif(x, min = -3, max = 3)
y2 <- dunif(x, min = -2, max = 2)
y3 <- dunif(x, min = -1, max = 1)

print(paste('La somme des probabilit√©s est de', sum(y3 * increment)))

gg_unif <- data.frame(x, y1, y2, y3) %>% gather(variable, value, -x)

ggplot(data = gg_unif, mapping = aes(x = x, y = value)) +
  geom_line(aes(colour = variable))
```

### Distribution normale

La plus r√©pandue de ces lois est probablement la loi normale, parfois nomm√©e loi gaussienne et plus rarement loi laplacienne. Il s'agit de la distribution classique en forme de cloche.

La loi normale est d√©crite par une moyenne, qui d√©signe la tendance centrale, et une variance, qui d√©signe l'√©talement des probabilit√©s autour de la moyenne. La racine carr√©e de la variance est l'√©cart-type.

Les distributions de mesures exclusivement positives (comme le poids ou la taille) sont parfois avantageusement approxim√©es par une loi **log-normale**, qui est une loi normale sur le logarithme des valeurs: la moyenne d'une loi log-normale est la moyenne g√©om√©trique.

```{r biostats-norm}
increment <- 0.01
x <- seq(-10, 10, by = increment)
y1 <- dnorm(x, mean = 0, sd = 1)
y2 <- dnorm(x, mean = 0, sd = 2)
y3 <- dnorm(x, mean = 0, sd = 3)

print(paste('La somme des probabilit√©s est de', sum(y3 * increment)))

gg_norm <- data.frame(x, y1, y2, y3) %>% gather(variable, value, -x)

ggplot(data = gg_norm, mapping = aes(x = x, y = value)) +
  geom_line(aes(colour = variable))
```

Quelle est la probabilit√© d'obtenir le nombre 0 chez une observation continue distribu√©e normalement dont la moyenne est 0 et l'√©cart-type est de 1? R√©ponse: 0. La loi normale √©tant une distribution continue, les probabilit√©s non-nulles ne peuvent √™tre calcul√©s que sur des intervalles. Par exemple, la probabilit√© de retrouver une valeur dans l'intervalle entre -1 et 2 est calcul√©e en soustrayant la probabilit√© cumul√©e √† -1 de la probabilit√© cumul√©e √† 2.

```{r biostats-norm-prob}
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

prob_between <- c(-1, 2)

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data.frame(x, y), aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line()

prob_norm_between <- pnorm(q = prob_between[2], mean = 0, sd = 1) - pnorm(q = prob_between[1], mean = 0, sd = 1)
print(paste("La probabilit√© d'obtenir un nombre entre",
            prob_between[1], "et",
            prob_between[2], "est d'environ",
            round(prob_norm_between, 2) * 100, "%"))
```

La courbe normale peut √™tre utile pour √©valuer la distribution d'une population. Par exemple, on peut calculer les limites de r√©gion sur la courbe normale qui contient 95% des valeurs possibles en tranchant 2.5% de part et d'autre de la moyenne. Il s'agit ainsi de l'intervalle de confiance sur la d√©viation de la distribution.

```{r biostats-norm-ci}
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

alpha <- 0.05
prob_between <- c(qnorm(p = alpha/2, mean = 0, sd = 1),
                  qnorm(p = 1 - alpha/2, mean = 0, sd = 1))

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line() +
  geom_text(data = data.frame(x = prob_between,
                              y = c(0, 0),
                              labels = round(prob_between, 2)),
            mapping = aes(label = labels))
```

On pourrait aussi √™tre int√©ress√© √† l'intervalle de confiance sur la moyenne. En effet, la moyenne suit aussi une distribution normale, dont la tendance centrale est la moyenne de la distribution, et dont l'√©cart-type est not√© *erreur standard*. On calcule cette erreur en divisant la variance par le nombre d'observation, ou en divisant l'√©cart-type par la racine carr√©e du nombre d'observations. Ainsi, pour 10 √©chantillons:

```{rbiostats-norm-mean-ci}
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

alpha <- 0.05
prob_between <- c(qnorm(p = alpha/2, mean = 0, sd = 1) / sqrt(10),
                  qnorm(p = 1 - alpha/2, mean = 0, sd = 1) / sqrt(10))

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line() +
  geom_text(data = data.frame(x = prob_between,
                              y = c(0, 0),
                              labels = round(prob_between, 2)),
            mapping = aes(label = labels))
```

## Statistiques descriptives

On a vu comment g√©n√©rer des statistiques sommaires en R avec la fonction `summary()`. Reprenons les donn√©es d'iris.

```{r biostats-summ-oros}
data("iris")
summary(iris)
```

Pour pr√©cis√©ment effectuer une moyenne et un √©cart-type sur un vecteur, passons par les fonctions `mean()` et `sd()`.

```{r biostats-stats-iris}
mean(iris$Sepal.Length)
sd(iris$Sepal.Length)
```

Pour effectuer un sommaire de tableau pilot√© par une fonction, nous passons par la gamme de fonctions `summarise()`, de dplyr. Dans ce cas, avec `group_by()`, nous fragmentons le tableau par esp√®ce pour effectuer un sommaire sur toutes les variables.

```{r biostats-stats-iris-tv}
iris %>%
  group_by(Species) %>%
  summarise_all(mean)
```

Vous pourriez √™tre int√©ress√© par les quartiles √† 25, 50 et 75%. Mais la fonction `summarise()` n'autorise que les fonctions dont la sortie est d'un seul objet, alors faisons sorte que l'objet soit une liste - lorsque l'on imbrique une fonction `funs`, le tableau √† ins√©rer dans la fonction est indiqu√© par un `.`.

```{r biostats-iris-tv-quantile}
iris %>%
  group_by(Species) %>%
  summarise_all(list(q25 = ~ quantile(., probs = 0.25),
                     q50 = ~ quantile(., probs = 0.50),
                     q75 = ~ quantile(., probs = 0.75)))
```

En mode programmation classique de R, on pourra g√©n√©rer les quartiles √† la pi√®ce.

```{r biostats-iris-classic-quantile}
quantile(iris$Sepal.Length[iris$Species == 'setosa'])
quantile(iris$Sepal.Length[iris$Species == 'versicolor'])
quantile(iris$Sepal.Length[iris$Species == 'virginica'])
```

La fonction `table()` permettra d'obtenir des d√©comptes par cat√©gorie, ici par plages de longueurs de s√©pales. Pour obtenir les proportions du nombre total, il s'agit d'encapsuler le tableau crois√© dans la fonction `prop.table()`.

```{r biostats-table}
tableau_croise <- table(iris$Species,
                        cut(iris$Sepal.Length, breaks = quantile(iris$Sepal.Length)))
tableau_croise
```

```{r biostats-prop-table}
prop.table(tableau_croise)
```

## Tests d'hypoth√®ses √† un et deux √©chantillons

Un test d'hypoth√®se permet de d√©cider si une hypoth√®se est confirm√©e ou rejet√©e √† un seuil de probabilit√© pr√©d√©termin√©.

Cette section est inspir√©e du chapitre 5 de [Dalgaard, 2008](https://www.springer.com/us/book/9780387790534).

----

**Information: l'hypoth√®se nulle**. Les tests d'hypoth√®se √©valuent des *effets* statistiques (qui ne sont pas n√©cessairement des effets de causalit√©). L'effet √† √©valuer peut √™tre celui d'un traitement, d'indicateurs m√©t√©orologiques (e.g. pr√©cipitations totales, degr√©-jour, etc.), de techniques de gestion des paysages, etc. Une recherche est men√©e pour √©valuer l'hypoth√®se que l'on retrouve des diff√©rences entre des unit√©s exp√©rimentales. Par convention, l'**hypoth√®se nulle** (√©crite $H_0$) est l'hypoth√®se qu'il n'y ait pas d'effet (c'est l'hypoth√®se de l'avocat du diable üòà) √† l'√©chelle de la population (et non pas √† l'√©chelle de l'√©chantillon). √Ä l'inverse, l'**hypoth√®se alternative** (√©crite $H_1$) est l'hypoth√®se qu'il y ait un effet √† l'√©chelle de la population.

----

√Ä titre d'exercice en stats, on d√©bute souvent par en testant si deux vecteurs de valeurs continues proviennent de populations √† moyennes diff√©rentes ou si un vecteur de valeurs a √©t√© g√©n√©r√© √† partir d'une population ayant une moyenne donner. Dans cette section, nous utiliserons la fonction `t.test()` pour les tests de t et la fonction `wilcox.test()` pour les tests de Wilcoxon (aussi appel√© de Mann-Whitney).

### Test de t √† un seul √©chantillon

Nous devons assumer, pour ce test, que l'√©chantillon est recueillit d'une population dont la distribution est normale, $\mathcal{N} \sim \left( \mu, \sigma^2 \right)$, et que chaque √©chantillon est ind√©pendant l'un de l'autre. L'hypoth√®se nulle est souvent celle de l'avocat du diable, que la moyenne soit √©gale √† une valeur donn√©e (donc la diff√©rence entre la moyenne de la population et une moyenne donn√©e est de z√©ro): ici, que $\mu = \bar{x}$. L'erreur standard sur la moyenne (ESM) de l'√©chantillon, $\bar{x}$ est calcul√©e comme suit.

$$ESM = \frac{s}{\sqrt{n}}$$

o√π $s$ est l'√©cart-type de l'√©chantillon et $n$ est le nombre d'√©chantillons.

Pour tester l'intervalle de confiance de l'√©chantillon, on multiplie l'ESM par l'aire sous la courbe de densit√© couvrant une certaine proportion de part et d'autre de l'√©chantillon. Pour un niveau de confiance de 95%, on retranche 2.5% de part et d'autre.

```{r biostats-norm-error}
set.seed(33746)
x <- rnorm(20, 16, 4)

level <-  0.95
alpha <- 1-level

x_bar <- mean(x)
s <- sd(x)
n <- length(x)

error <- qnorm(1 - alpha/2) * s / sqrt(n)
error
```

intervalle de confiance est l'erreur de par et d'autre de la moyenne.

```{r biostats-norm-error-ci}
c(x_bar - error, x_bar + error)
```

Si la moyenne de la population est de 16, un nombre qui se situe dans l'intervalle de confiance on accepte l'hypoth√®se nulle au seuil 0.05. Si le nombre d'√©chantillon est r√©duit (g√©n√©ralement < 30), on passera plut√¥t par une distribution de t, avec $n-1$ degr√©s de libert√©.

```{r biostats-student-error-ci}
error <- qt(1 - alpha/2, n-1) * s / sqrt(n)
c(x_bar - error, x_bar + error)
```

Plus simplement, on pourra utiliser la fonction `t.test()` en sp√©cifiant la moyenne de la population. Nous avons g√©n√©r√© 20 donn√©es avec une moyenne de 16 et un √©cart-type de 4. Nous savons donc que la vraie moyenne de l'√©chantillon est de 16. Mais disons que nous testons l'hypoth√®se que ces donn√©es sont tir√©es d'une population dont la moyenne est 18 (et implicitement que sont √©cart-type est de 4).

```{r biostats-ttest}
t.test(x, mu = 18)
```

La fonction retourne la valeur de t (*t-value*), le nombre de degr√©s de libert√© ($n-1 = 19$), une description de l'hypoth√®se alternative (`alternative hypothesis: true mean is not equal to 18`), ainsi que l'intervalle de confiance au niveau de 95%. Le test contient aussi la *p-value*. Bien que la *p-value* soit largement utilis√©e en science

----

#### Information: la *p-value*

La *p-value*, ou valeur-p ou p-valeur, est utilis√©e pour trancher si, oui ou non, un r√©sultat est **significatif**. En langage scientifique, le mot significatif ne devrait √™tre utilis√© *que* lorsque l'on r√©f√®re √† un test d'hypoth√®se statistique. Vous retrouverez des *p-values* partout en stats. Les *p-values* indiquent la probabilit√© que les donn√©es ait √©t√© √©chantillonn√©es d'une population o√π un effet est observable selon le mod√®le statistique utilis√©.

> La p-value est la probabilit√© que les donn√©es aient √©t√© g√©n√©r√©es pour obtenir un effet √©quivalent ou plus prononc√© si l'hypoth√®se nulle est vraie.

Une *p-value* √©lev√©e indique que le mod√®le appliqu√© √† vos donn√©es concorde avec la conclusion que l'hypoth√®se nulle est vraie, et inversement si la *p-value* est faible. Le seuil arbitraire utilis√©e en √©cologie et en agriculture, comme dans plusieurs domaines, est de 0.05. L'utilisation d'un seuil est toutefois contest√©e **√† raison**. Une enqu√™te men√©e dans la litt√©rature scientifiques a r√©v√©l√© que 49% des 791 articles √©tudi√©s interpr√©taient un effet non significatif comme un effet nul ([Amrhein et al., 2019](https://www.nature.com/articles/d41586-019-00857-9)). En effet, une cat√©gorisation de la p-value avec un seuil de significativit√© brouille le jugement sur l'importance des effets et de leur incertitude. Les six principes de l'[American Statistical Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html) guident l'interpr√©tation des *p-values*. [ma traduction]

1. Les *p-values* indique l'ampleur de l‚Äôincompatibilit√© des donn√©es avec le mod√®le statistique
2. Les *p-values* ne mesurent pas la probabilit√© que l'hypoth√®se √©tudi√©e soit vraie, ni la probabilit√© que les donn√©es ont √©t√© g√©n√©r√©es uniquement par la chance.
3. Les conclusions scientifiques et d√©cisions d'affaire ou politiques ne devraient pas √™tre bas√©es sur l'atteinte d'une *p-value* √† un seuil sp√©cifique.
4. Une inf√©rence appropri√©e demande un rapport complet et transparent.
5. Une *p-value*, ou une signification statistique, ne mesure pas l'ampleur d'un effet ou l'importance d'un r√©sultat.
6. En tant que tel, une *p-value* n'offre pas une bonne mesure des √©vidences d'un mod√®le ou d'une hypoth√®se.

----

Dans le cas pr√©c√©dent, la *p-value* √©tait de 0.01014. Pour aider notre interpr√©tation, prenons l'hypoth√®se alternative: `true mean is not equal to 18`. L'hypoth√®se nulle √©tait bien que *la vraie moyenne est √©gale √† 18*. Ins√©rons la *p-value* dans la d√©finition: la probabilit√© que les donn√©es aient √©t√© g√©n√©r√©es pour obtenir un effet √©quivalent ou plus prononc√© si l'hypoth√®se nulle est vraie est de 0.01014. Il est donc tr√®s peu probable que les donn√©es soient tir√©es d'un √©chantillon dont la moyenne est de 18. Au seuil de signification de 0.05, on rejette l'hypoth√®se nulle et l'on conclut qu'√† ce seuil de confiance, l'√©chantillon ne provient pas d'une population ayant une moyenne de 18.

### Attention: mauvaises interpr√©tations des *p-values*

> "La p-value n'a jamais √©t√© con√ßue comme substitut au raisonnement scientifique" [Ron Wasserstein, directeur de l'American Statistical Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html) [ma traduction].

**Un r√©sultat montrant une p-value plus √©lev√©e que 0.05 est-il pertinent?**

Lors d'une conf√©rence, Dr Evil ne pr√©sentent que les r√©sultats significatifs de ses essais au seuil de 0.05. Certains essais ne sont pas significatifs, mais bon, ceux-ci ne sont pas importants... En √©cartant ces r√©sultats, Dr Evil commet 3 erreurs:

1. La *p-value* n'est pas un bon indicateur de l'importance d'un test statistique. L'importance d'une variable dans un mod√®le devrait √™tre √©valu√©e par la valeur de son coefficient. Son incertitude devrait √™tre √©valu√©e par sa variance. Une mani√®re d'√©valuer plus intuitive la variance est l'√©cart-type ou l'intervalle de confiance. √Ä un certain seuil d'intervalle de confiance, la p-value traduira la probabilit√© qu'un coefficient soit r√©ellement nul ait pu g√©n√©rer des donn√©es d√©montrant un coefficient √©gal ou sup√©rieur.
1. Il est tout aussi important de savoir que le traitement fonctionne que de savoir qu'il ne fonctionne pas. Les r√©sultats d√©montrant des effets sont malheureusement davantage soumis aux journaux et davantage publi√©s que ceux ne d√©montrant pas d'effets ([Decullier et al., 2005]( https://doi.org/10.1136/bmj.38488.385995.8F )).
1. Le seuil de 0.05 est arbitraire.

----

#### Attention au *p-hacking*

Le *p-hacking* (ou *data dredging*) consiste √† manipuler les donn√©es et les mod√®les pour faire en sorte d'obtenir des *p-values* favorables √† l'hypoth√®se test√©e et, √©ventuellement, aux conclusions recherch√©es. **√Ä √©viter dans tous les cas. Toujours. Toujours. Toujours.**

```{r biostats-johnoliver, fig.align="center", fig.cap="Un sketch humoristique de John Oliver sur le *p-hacking*, [Last week tonight, 2016](https://youtu.be/0Rnq1NpHdmw) (en anglais)", echo = FALSE}
knitr::include_graphics("images/05_p-hacking.png")
```

----

### Test de Wilcoxon √† un seul √©chantillon

Le test de t suppose que la distribution des donn√©es est normale... ce qui est rarement le cas, surtout lorsque les √©chantillons sont peu nombreux. Le test de Wilcoxon ne demande aucune supposition sur la distribution: c'est un test non-param√©trique bas√© sur le tri des valeurs.

```{r biostats-wilcox-test}
wilcox.test(x, mu = 18)
```

Le `V` est la somme des rangs positifs. Dans ce cas, la *p-value* est semblable √† celle du test de t, et les m√™mes conclusions s'appliquent.

### Tests de t √† deux √©chantillons

Les tests √† un √©chantillon servent plut√¥t √† s'exercer: rarement en aura-t-on besoin en recherche, o√π plus souvent, on voudra comparer les moyennes de deux unit√©s exp√©rimentales. L'exp√©rience comprend donc deux s√©ries de donn√©es continues, $x_1$ et $x_2$, issus de lois de distribution normale $\mathcal{N} \left( \mu_1, \sigma_1^2 \right)$ et $\mathcal{N} \left( \mu_2, \sigma_2^2 \right)$, et nous testons l'hypoth√®se nulle que $\mu_1 = \mu_2$. La statistique t est calcul√©e comme suit.

$$t = \frac{\bar{x_1} - \bar{x_2}}{ESDM}$$

L'ESDM est l'erreur standard de la diff√©rence des moyennes:

$$ESDM = \sqrt{ESM_1^2 + ESM_2^2}$$

Si vous supposez que les variances sont identiques, l'erreur standard (s) est calcul√©e pour les √©chantillons des deux groupes, puis ins√©r√©e dans le calcul des ESM. La statistique t sera alors √©valu√©e √† $n_1 + n_2 - 2$ degr√©s de libert√©. Si vous supposez que la variance est diff√©rente (*proc√©dure de Welch*), vous calculez les ESM avec les erreurs standards respectives, et la statistique t devient une approximation de la distribution de t avec un nombre de degr√©s de libert√© calcul√© √† partir des erreurs standards et du nombre d'√©chantillon dans les groupes: cette proc√©dure est consid√©r√©e comme plus prudente ([Dalgaard, 2008](https://www.springer.com/us/book/9780387790534), page 101).

Prenons les donn√©es d'iris pour l'exemple en excluant l'iris setosa √©tant donn√©e que les tests de t se restreignent √† deux groupes. Nous allons tester la longueur des p√©tales.

```{r biostats-iris-petal}
iris_pl <- iris %>%
    filter(Species != "setosa") %>%
    select(Species, Petal.Length)
sample_n(iris_pl, 5)
```

Dans la prochaine cellule, nous introduisons l'*interface-formule* de R, o√π l'on retrouve typiquement le `~`, entre les variables de sortie √† gauche et les variables d'entr√©e √† droite. Dans notre cas, la variable de sortie est la variable test√©e, `Petal.Length`, qui varie en fonction du groupe `Species`, qui est la variable d'entr√©e (variable explicative) - nous verrons les types de variables plus en d√©tails dans la section [Les mod√®les statistiques](#Les-mod%C3%A8les-statistiques), plus bas.

```{r biostats-iris-petal-ttest}
t.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = FALSE)
```

Nous obtenons une sortie similaire aux pr√©c√©dentes. L'intervalle de confiance √† 95% exclu le z√©ro, ce qui est coh√©rent avec la p-value tr√®s faible, qui nous indique le rejet de l'hypoth√®se nulle au seuil 0.05. Les donn√©es montrent que les groupes ont des moyennes de longueurs de p√©tale diff√©rentes.

----

#### Enregistrer les r√©sultats d'un test

Il est possible d'enregistrer un test dans un objet.

```{r biostats-save-test}
tt_pl <- t.test(formula = Petal.Length ~ Species,
                data = iris_pl, var.equal = FALSE)
summary(tt_pl)
str(tt_pl)
```

----

### Comparaison des variances

Pour comparer les variances, on a recours au test de F (F pour Fisher).

```{r biostats-ftest}
var.test(formula = Petal.Length ~ Species,
         data = iris_pl)
```

Il semble que l'on pourrait relancer le test de *t* sans la proc√©dure Welch, avec `var.equal = TRUE`.

### Tests de Wilcoxon √† deux √©chantillons

Cela ressemble au test de t!

```{r biostats-wilcox-2ech}
wilcox.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = TRUE)
```

### Les tests pair√©s

Les tests pair√©s sont utilis√©s lorsque deux √©chantillons proviennent d'une m√™me unit√© exp√©rimentale: il s'agit en fait de tests sur la diff√©rence entre deux observations.

```{r biostats-ap}
set.seed(2555)

n <- 20
avant <- rnorm(n, 16, 4)
apres <- rnorm(n, 18, 3)
```

Il est important de sp√©cifier que le test est pair√©, la valeur par d√©faut de `paired` √©tant `FALSE`.

```{r biostats-ttest-paired}
t.test(avant, apres, paired = TRUE)
```

L'hypoth√®se nulle qu'il n'y ait pas de diff√©rence entre l'avant et l'apr√®s traitement est accept√©e au seuil 0.05.

**Exercice**. Effectuer un test de Wilcoxon pair√©.

## L'analyse de variance

L'analyse de variance consiste √† comparer des moyennes de plusieurs groupe distribu√©s normalement et de m√™me variance. Cette section sera √©labor√©e prochainement plus en profondeur. Consid√©rons-la pour le moment comme une r√©gression sur une variable cat√©gorielle.

```{r biostats-anova}
pl_aov <- aov(Petal.Length ~ Species, iris)
summary(pl_aov)
```

La prochaine section, justement, est vou√©e aux mod√®les statistiques explicatifs, qui incluent la r√©gression.

## Les mod√®les statistiques

La mod√©lisation statistique consiste √† lier de mani√®re explicite des variables de sortie $y$ (ou variables-r√©ponse ou variables d√©pendantes) √† des variables explicatives $x$ (ou variables pr√©dictives / ind√©pendantes / covariables). Les variables-r√©ponse sont mod√©lis√©es par une fonction des variables explicatives ou pr√©dictives.

Pourquoi garder les termes *explicatives* et *pr√©dictives*? Parce que les mod√®les statistiques (bas√©s sur des donn√©es et non pas sur des m√©canismes) sont de deux ordres. D'abord, les mod√®les **pr√©dictifs** sont con√ßus pour pr√©dire de mani√®re fiable une ou plusieurs variables-r√©ponse √† partir des informations contenues dans les variables qui sont, dans ce cas, pr√©dictives. Ces mod√®les sont couverts dans le chapitre 11 de ce manuel (en d√©veloppement). Lorsque l'on d√©sire tester des hypoth√®ses pour √©valuer quelles variables expliquent la r√©ponse, on parlera de mod√©lisation (et de variables) **explicatives**. En inf√©rence statistique, on √©valuera les *corr√©lations* entre les variables explicatives et les variables-r√©ponse. Un lien de corr√©lation n'est pas un lien de causalit√©. L'inf√©rence causale peut en revanche √™tre √©valu√©e par des [*mod√®les d'√©quations structurelles*](https://www.amazon.com/Cause-Correlation-Biology-Structural-Equations/dp/1107442591), sujet qui fera √©ventuellement partie de ce cours.

Cette section couvre la mod√©lisation explicative. Les variables qui contribuent √† cr√©er les mod√®les peuvent √™tre de diff√©rentes natures et distribu√©es selon diff√©rentes lois de probabilit√©. Alors que les mod√®les lin√©aires simples (*lm*) impliquent une variable-r√©ponse distribu√©e de mani√®re continue, les mod√®les lin√©aires g√©n√©ralis√©s peuvent aussi expliquer des variables de sorties discr√®tes.

Dans les deux cas, on distinguera les variables fixes et les variables al√©atoires. Les **variables fixes** sont les variables test√©es lors de l'exp√©rience: dose du traitement, esp√®ce/cultivar, m√©t√©o, etc. Les **variables al√©atoires** sont les sources de variation qui g√©n√®rent du bruit dans le mod√®le: les unit√©s exp√©rimentales ou le temps lors de mesures r√©p√©t√©es. Les mod√®les incluant des effets fixes seulement sont des mod√®les √† effets fixes. G√©n√©ralement, les mod√®les incluant des variables al√©atoires incluent aussi des variables fixes: on parlera alors de mod√®les mixtes. Nous couvrirons ces deux types de mod√®le.

### Mod√®les √† effets fixes

Les tests de t et de Wilcoxon, explor√©s pr√©c√©demment, sont des mod√®les statistiques √† une seule variable. Nous avons vu dans l'*interface-formule* qu'une variable-r√©ponse peut √™tre li√©e √† une variable explicative avec le tilde `~`. En particulier, le test de t est r√©gression lin√©aire univari√©e (√† une seule variable explicative) dont la variable explicative comprend deux cat√©gories. De m√™me, l'anova est une r√©gression lin√©aire univari√©e dont la variable explicative comprend plusieurs cat√©gories. Or l'interface-formule peut √™tre utilis√© dans plusieurs circonstances, notamment pour ajouter plusieurs variables de diff√©rents types: on parlera de r√©gression multivari√©e.

La plupart des mod√®les statistiques peuvent √™tre approxim√©s comme une combinaison lin√©aire de variables: ce sont des mod√®les lin√©aires. Les mod√®les non-lin√©aires impliquent des strat√©gies computationnelles complexes qui rendent leur utilisation plus difficile √† man≈ìuvrer.

Un mod√®le lin√©aire univari√© prendra la forme $y = \beta_0 + \beta_1 x + \epsilon$, o√π $\beta_0$ est l'intercept et $\beta_1$ est la pente et $\epsilon$ est l'erreur.

Vous verrez parfois la notation $\hat{y} = \beta_0 + \beta_1 x$. La notation avec le chapeau $\hat{y}$ exprime qu'il s'agit des valeurs g√©n√©r√©es par le mod√®le. En fait, $y = \hat{y} - \epsilon$.

#### Mod√®le lin√©aire univari√© avec variable continue

Prenons les donn√©es [`lasrosas.corn`](https://rdrr.io/cran/agridat/man/lasrosas.corn.html) incluses dans le module `agridat`, o√π l'on retrouve le rendement d'une production de ma√Øs √† dose d'azote variable, en Argentine.

```{r biostats-load-agridat}
library("agridat")
data("lasrosas.corn")
sample_n(lasrosas.corn, 10)
```

Ces donn√©es comprennent plusieurs variables. Prenons le rendement (`yield`) comme variable de sortie et, pour le moment, ne retenons que la dose d'azote (`nitro`) comme variable explicative: il s'agit d'une r√©gression univari√©e. Les deux variables sont continues. Explorons d'abord le nuage de points de l'une et l'autre.

```{r biostats-plot-nitro-agridat}
ggplot(data = lasrosas.corn, mapping = aes(x = nitro, y = yield)) +
    geom_point()
```

L'hypoth√®se nulle est que la dose d'azote n'affecte pas le rendement, c'est √† dire que le coefficient de pente et nul. Une autre hypoth√®se est que l'intercept est nul: donc qu'√† dose de 0, rendement de 0. Un mod√®le lin√©aire √† variable de sortie continue est cr√©√© avec la fonction `lm()`, pour *linear model*.

```{r biostats-lm1-agridat}
modlin_1 <- lm(yield ~ nitro, data = lasrosas.corn)
summary(modlin_1)
```

Le diagnostic du mod√®le comprend plusieurs informations. D'abord la formule utilis√©e, affich√©e pour la tra√ßabilit√©. Viens ensuite un aper√ßu de la distribution des r√©sidus. La m√©diane devrait s'approcher de la moyenne des r√©sidus (qui est toujours de 0). Bien que le -3.079 peut sembler important, il faut prendre en consid√©ration de l'√©chelle de y, et ce -3.079 est exprim√© en terme de rendement, ici en quintaux (i.e. 100 kg) par hectare. La distribution des r√©sidus m√©rite d'√™tre davantage investigu√©e. Nous verrons cela un peu plus tard.

Les coefficients apparaissent ensuite. Les estim√©s sont les valeurs des effets. R fournit aussi l'erreur standard associ√©e, la valeur de t ainsi que la p-value (la probabilit√© d'obtenir cet effet ou un effet plus extr√™me si en r√©alit√© il y avait absence d'effet). L'intercept est bien s√ªr plus √©lev√© que 0 (√† dose nulle, on obtient 65.8 quintaux par hectare en moyenne). La pente de la variable `nitro` est de ~0.06: pour chaque augmentation d'un kg/ha de dose, on a obtenu ~0.06 quintaux/ha de plus de ma√Øs. Donc pour 100 kg/ha de N, on a obtenu un rendement moyen de 6 quintaux de plus que l'intercept. Soulignons que l'ampleur du coefficient est tr√®s important pour guider la fertilisation: ne rapporter que la p-value, ou ne rapporter que le fait qu'elle est inf√©rieure √† 0.05 (ce qui arrive souvent dans la litt√©rature), serait tr√®s insuffisant pour l'interpr√©tation des statistiques. La p-value nous indique n√©anmoins qu'il serait tr√®s improbable qu'une telle pente ait √©t√© g√©n√©r√©e alors que celle-ci est nulle en r√©alit√©. Les √©toiles √† c√¥t√© des p-values indiquent l'ampleur selon l'√©chelle `Signif. codes` indiqu√©e en-dessous du tableau des coefficients.

Sous ce tableau, R offre d'autres statistiques. En outre, les R¬≤ et R¬≤ ajust√©s indiquent si la r√©gression passe effectivement par les points. Le R¬≤ prend un maximum de 1 lorsque la droite passe exactement sur les points.

Enfin, le test de F g√©n√®re une p-value indiquant la probabilit√© que les coefficients de pente ait √©t√© g√©n√©r√©s si les vrais coefficients √©taient nuls. Dans le cas d'une r√©gression univari√©e, cela r√©p√®te l'information sur l'unique coefficient.

On pourra √©galement obtenir les intervalles de confiance avec la fonction `confint()`.

```{r biostats-lm1-agridat-ci}
confint(modlin_1, level = 0.95)
```

Ou soutirer l'information de diff√©rentes mani√®res, comme avec la fonction `coefficients()`.

```{r biostats-lm1-agridat-coeff}
coefficients(modlin_1)
```

√âgalement, on pourra ex√©cuter le mod√®le sur les donn√©es qui ont servi √† le g√©n√©rer:

```{r biostats-lm1-agridat-predict}
predict(modlin_1)[1:5]
```

Ou sur des donn√©es externes.

```{r biostats-lm1-agridat-predict-newdata}
nouvelles_donnees <- data.frame(nitro = seq(from = 0, to = 100, by = 5))
predict(modlin_1, newdata = nouvelles_donnees)[1:5]
```

#### Analyse des r√©sidus

Les r√©sidus sont les erreurs du mod√®le. C'est le vecteur $\epsilon$, qui est un d√©calage entre les donn√©es et le mod√®le. Le R¬≤ est un indicateur de l'ampleur du d√©calage, mais une r√©gression lin√©aire explicative en bonne et due forme devrait √™tre accompagn√©e d'une analyse des r√©sidus. On peut les calculer par $\epsilon = y - \hat{y}$, mais aussi bien utiliser la fonction `residuals()`.

```{r biostats-lm1-residual}
res_df <- data.frame(nitro = lasrosas.corn$nitro,
                     residus_lm = residuals(modlin_1),
                     residus_calcul = lasrosas.corn$yield - predict(modlin_1))
sample_n(res_df, 10)
```

Dans une bonne r√©gression lin√©aire, on ne retrouvera pas de structure identifiable dans les r√©sidus, c'est-√†-dire que les r√©sidus sont bien distribu√©s de part et d'autre du mod√®le de r√©gression.

```{r biostats-lm1-residuals-plot}
ggplot(res_df, aes(x = nitro, y = residus_lm)) +
  geom_point() +
  labs(x = "Dose N", y = "R√©sidus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```

Bien que le jugement soit subjectif, on peut dire avec confiance qu'il n'y a pas structure particuli√®re. En revanche, on pourrait g√©n√©rer un $y$ qui varie de mani√®re quadratique avec $x$, un mod√®le lin√©aire montrera une structure √©vidente.

```{r biostats-residuals-example-banana}
set.seed(36164)
x <- 0:100
y <- 10 + x*1 + x^2 * 0.05 + rnorm(length(x), 0, 50)
modlin_2 <- lm(y ~ x)
ggplot(data.frame(y, residus = residuals(modlin_2)),
       aes(x = x, y = residus)) +
  geom_point() +
  labs(x = "x", y = "R√©sidus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```
De m√™me, les r√©sidus ne devraient pas cro√Ætre avec $x$.

```{r biostats-residuals-example-expand}
set.seed(3984)
x <- 0:100
y <-  10 + x + x * rnorm(length(x), 0, 2)
modlin_3 <- lm(y ~ x)
ggplot(data.frame(x, residus = residuals(modlin_3)),
       aes(x = x, y = residus)) +
  geom_point() +
  labs(x = "x", y = "R√©sidus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```

On pourra aussi inspecter les r√©sidus avec un graphique de leur distribution. Reprenons notre mod√®le de rendement du ma√Øs.

```{r biostats-residuals-agridat-groups}
ggplot(res_df, aes(x = residus_lm)) +
  geom_histogram(binwidth = 2, color = "white") +
  labs(x = "Residual")
```

L'histogramme devrait pr√©senter une distribution normale. Les tests de normalit√© comme le test de Shapiro-Wilk peuvent aider, mais ils sont g√©n√©ralement tr√®s s√©v√®res.

```{r biostats-residuals-shapiro}
shapiro.test(res_df$residus_lm)
```

L'hypoth√®se nulle que la distribution est normale est rejet√©e au seuil 0.05. Dans notre cas, il est √©vident que la s√©v√©rit√© du test n'est pas en cause, car les r√©sidus semble g√©n√©rer trois ensembles. Ceci indique que les variables explicatives sont insuffisantes pour expliquer la variabilit√© de la variable-r√©ponse.

#### R√©gression multiple

Comme c'est le cas pour bien des ph√©nom√®nes en √©cologie, le rendement d'une culture n'est certainement pas expliqu√© seulement par la dose d'azote.

Lorsque l'on combine plusieurs variables explicatives, on cr√©e un mod√®le de r√©gression multivari√©e, ou une r√©gression multiple. Bien que les tendances puissent sembler non-lin√©aires, l'ajout de variables et le calcul des coefficients associ√©s reste un probl√®me d'alg√®bre lin√©aire.

On pourra en effet g√©n√©raliser les mod√®les lin√©aires, univari√©s et multivari√©s, de la mani√®re suivante.

$$ y = X \beta + \epsilon $$

o√π:

$X$ est la matrice du mod√®le √† $n$ observations et $p$ variables.

$$ X = \left( \begin{matrix}
1 & x_{11} & \cdots & x_{1p}  \\
1 & x_{21} & \cdots & x_{2p}  \\
\vdots & \vdots & \ddots & \vdots  \\
1 & x_{n1} & \cdots & x_{np}
\end{matrix} \right) $$

$\beta$ est la matrice des $p$ coefficients, $\beta_0$ √©tant l'intercept qui multiplie la premi√®re colonne de la matrice $X$.

$$ \beta = \left( \begin{matrix}
\beta_0  \\
\beta_1  \\
\vdots \\
\beta_p
\end{matrix} \right) $$

$\epsilon$ est l'erreur de chaque observation.

$$ \epsilon = \left( \begin{matrix}
\epsilon_0  \\
\epsilon_1  \\
\vdots \\
\epsilon_n
\end{matrix} \right) $$

#### Mod√®les lin√©aires univari√©s avec variable cat√©gorielle **nominale**

Une variable cat√©gorielle nominale (non ordonn√©e) utilis√©e √† elle seule dans un mod√®le comme variable explicative, est un cas particulier de r√©gression multiple. En effet, l'**encodage cat√©goriel** (ou *dummyfication*) transforme une variable cat√©gorielle nominale en une matrice de mod√®le comprenant une colonne d√©signant l'intercept (une s√©rie de 1) d√©signant la cat√©gorie de r√©f√©rence, ainsi que des colonnes pour chacune des autres cat√©gories d√©signant l'appartenance (1) ou la non appartenance (0) de la cat√©gorie d√©sign√©e par la colonne.

##### L'encodage cat√©goriel

Une variable √† $C$ cat√©gories pourra √™tre d√©clin√©e en $C$ variables dont chaque colonne d√©signe par un 1 l'appartenance au groupe de la colonne et par un 0 la non-appartenance. Pour l'exemple, cr√©ons un vecteur d√©signant le cultivar de pomme de terre.

```{r biostats-dummy-coding}
data <- data.frame(cultivar = factor(c('Superior', 'Superior', 'Superior', 'Russet', 'Kenebec', 'Russet')))
model.matrix(~cultivar, data)
```

Nous avons trois cat√©gories, encod√©es en trois colonnes. La premi√®re colonne est un intercept et les deux autres d√©crivent l'absence (0) ou la pr√©sence (1) des cultivars Russet et Superior. Le cultivar Kenebec est absent du tableau. En effet, en partant du principe que l'appartenance √† une cat√©gorie est mutuellement exclusive, c'est-√†-dire qu'un √©chantillon ne peut √™tre assign√© qu'√† une seule cat√©gorie, on peut d√©duire une cat√©gorie √† partir de l'information sur toutes les autres. Par exemple, si `cultivar_Russet` et `cultivar_Superior` sont toutes deux √©gales √† $0$, on conclura que `cultivar_Kenebec` est n√©cessairement √©gal √† $1$. Et si l'un d'entre `cultivar_Russet` et `cultivar_Superior` est √©gal √† $1$, `cultivar_Kenebec` est n√©cessairement √©gal √† $0$. L'information contenue dans un nombre $C$ de cat√©gorie peut √™tre encod√©e dans un nombre $C-1$ de colonnes. C'est pourquoi, dans une analyse statistique, on d√©signera une cat√©gorie comme une r√©f√©rence, que l'on d√©tecte lorsque toutes les autres cat√©gories sont encod√©es avec des $0$: cette r√©f√©rence sera incluse dans l'intercept. La cat√©gorie de r√©f√©rence par d√©faut en R est celle la premi√®re cat√©gorie dans l'ordre alphab√©tique. On pourra modifier cette r√©f√©rence avec la fonction `relevel()`.

```{r biostats-dummy-coding-relevel}
data$cultivar <- relevel(data$cultivar, ref = "Superior")
model.matrix(~cultivar, data)
```

Pour certains mod√®les, vous devrez vous assurer vous-m√™me de l'encodage cat√©goriel. Pour d'autre, en particulier avec l'*interface par formule* de R, ce sera fait automatiquement.

##### Exemple d'application

Prenons la topographie du terrain, qui peut prendre plusieurs niveaux.

```{r biostats-lasrosas-topo-levels}
levels(lasrosas.corn$topo)
```

Explorons le rendement selon la topographie.

```{r biostats-lasrosas-topo-boxplot}
ggplot(lasrosas.corn, aes(x = topo, y = yield)) +
    geom_boxplot()
```

Les diff√©rences sont √©videntes, et la mod√©lisation devrait montrer des effets diff√©rents.

L'encodage cat√©goriel peut √™tre visualis√© en g√©n√©rant la matrice de mod√®le avec la fonction `model.matrix()` et l'interface-formule - sans la variable-r√©ponse.

```{r biostats-lasrosas-topo-model-matrix}
model.matrix(~ topo, data = lasrosas.corn) %>%
    tbl_df() %>% # tbl_df pour transformer la matrice en tableau
    sample_n(10)
```

Dans le cas d'un mod√®le avec une variable cat√©gorielle nominale seule, l'intercept repr√©sente la cat√©gorie de r√©f√©rence, ici `E`. Les autres colonnes sp√©cifient l'appartenance (1) ou la non-appartenance (0) de la cat√©gorie pour chaque observation.

Cette matrice de mod√®le utilis√©e pour la r√©gression donnera un intercept, qui indiquera l'effet de la cat√©gorie de r√©f√©rence, puis les diff√©rences entre les cat√©gories subs√©quentes et la cat√©gorie de r√©f√©rence.

```{r biostats-lasrosas-topo-levels-lm}
modlin_4 <- lm(yield ~ topo, data = lasrosas.corn)
summary(modlin_4)
```

Le mod√®le lin√©aire est √©quivalent √† l'anova, mais les r√©sultats de `lm` sont plus √©labor√©s.

```{r biostats-lasrosas-topo-levels-summ}
summary(aov(yield ~ topo, data = lasrosas.corn))
```

L'analyse de r√©sidus peut √™tre effectu√©e de la m√™me mani√®re.

#### Mod√®les lin√©aires univari√©s avec variable cat√©gorielle **ordinale**

Bien que j'introduise la r√©gression sur variable cat√©gorielle ordinale √† la suite de la section sur les variables nominales, nous revenons dans ce cas √† une r√©gression simple, univari√©e. Voyons un cas √† 5 niveaux.

```{r biostats-encoding-ordinal}
statut <- c("Totalement en d√©saccord",
            "En d√©saccord",
            "Ni en accord, ni en d√©saccord",
            "En accord",
            "Totalement en accord")
statut_o <- factor(statut, levels = statut, ordered=TRUE)
model.matrix(~statut_o) # ou bien, sans passer par model.matrix, contr.poly(5) o√π 5 est le nombre de niveaux
```

La matrice de mod√®le a 5 colonnes, soit le nombre de niveaux: un intercept, puis 4 autres d√©signant diff√©rentes valeurs que peuvent prendre les niveaux. Ces niveaux croient-ils lin√©airement? De mani√®re quadratique, cubique ou plus loin dans des distributions polynomiales?

```{r biostats-encoding-ordinal-plot}
modmat_tidy <- data.frame(statut, model.matrix(~statut_o)[, -1]) %>%
    gather(variable, valeur, -statut)
modmat_tidy$statut <- factor(modmat_tidy$statut,
                             levels = statut,
                             ordered=TRUE)
ggplot(data = modmat_tidy, mapping = aes(x = statut, y = valeur)) +
    facet_wrap(. ~ variable) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

R√®gle g√©n√©rale, pour les variables ordinales, on pr√©f√©rera une distribution lin√©aire, et c'est l'option par d√©faut de la fonction `lm()`. L'utilisation d'une autre distribution peut √™tre effectu√©e √† la mitaine en utilisant dans le mod√®le la colonne d√©sir√©e de la sortie de la fonction `model.matrix()`.

#### R√©gression multiple √† plusieurs variables

Reprenons le tableau de donn√©es du rendement de ma√Øs.

```{r biostats-multivariate-lm-data}
head(lasrosas.corn)
```

Pour ajouter des variables au mod√®le dans l'interface-formule, on additionne les noms de colonne. La variable `lat` d√©signe la latitude, la variable `long` d√©signe la latitude et la variable `bv` (*brightness value*) d√©signe la teneur en mati√®re organique du sol (plus `bv` est √©lev√©e, plus faible est la teneur en mati√®re organique).

```{r biostats-multivariate-lm}
modlin_5 <- lm(yield ~ lat + long + nitro + topo + bv,
               data = lasrosas.corn)
summary(modlin_5)
```

L'ampleur des coefficients est relatif √† l'√©chelle de la variable. En effet, un coefficient de 5541 sur la variable `lat` n'est pas comparable au coefficient de la variable `bv`, de -0.5089, √©tant donn√© que les variables ne sont pas exprim√©es avec la m√™me √©chelle. Pour les comparer sur une m√™me base, on peut centrer (soustraire la moyenne) et r√©duire (diviser par l'√©cart-type).

```{r biostats-multivariate-lm-scaled}
lasrosas.corn_sc <- lasrosas.corn %>%
    mutate_at(c("lat", "long", "nitro", "bv"), scale)

modlin_5_sc <- lm(yield ~ lat + long + nitro + topo + bv,
               data = lasrosas.corn_sc)
summary(modlin_5_sc)
```

Typiquement, les variables cat√©gorielles, qui ne sont pas mises √† l'√©chelle, donneront des coefficients plus √©lev√©es, et devrons √™tre √©valu√©es entre elles et non comparativement aux variables mises √† l'√©chelle. Une mani√®re conviviale de repr√©senter des coefficients consiste √† utiliser la fonction `tidy` du module **`broom`**, qui g√©n√®re un tableau contennt les coefficients ainsi que leurs intervalles de confiance, que nous pourrons ensuite porter graphiquement.

```{r biostats-multivariate-lm-ci}
library("broom") # ou bien charger le m√©ta-module tidymodels
intervals <- tidy(modlin_5_sc, conf.int = TRUE, conf.level = 0.95)
intervals
```

La valeur par d√©faut de l'argument `conf.level` est de 0.95, mais je vous sugg√®re de toujours l'√©crire de mani√®re explicite, ne serait-ce que pour rappeler √† vous-m√™me ainsi qu'√† vos coll√®gues, que cette valeur est arbitraire: il s'agit d'une d√©cision d'analyse, non pas d'une valeur √† utiliser par convention.

Pour le graphique, on aura avantage √† s√©parer les effets cat√©goriels aux effets num√©riques pour mieux interpr√©ter leurs effets entre eux. J'utilise la fonction `dplyr::case_when()` pour cr√©er une nouvelle colonne qui cat√©gorisera les termes de l'√©quation. Cette cat√©gorie me permettra d'effectuer un `facet_wrap()`.

```{r biostats-multivariate-lm-ci-plot}
intervals %>% 
  mutate(type = case_when(
    term %in% c("topoHT", "topoLO", "topoW") ~ "Cat√©gorie", # condition ~ r√©sultat
    term == "(Intercept)" ~ "Intercept",  # condition ~ r√©sultat
    TRUE ~ "num√©rique" # pour toute autre condition (TRUE) ~ r√©sultat
  )) %>% 
  ggplot(mapping = aes(x = estimate, y = term)) +
  geom_vline(xintercept = 0, lty = 2) +
  geom_segment(mapping = aes(x = conf.low, xend = conf.high, yend = term)) +
  geom_point() +
  labs(x = "Coefficient standardis√©", y = "") +
  facet_wrap(~type, scales = "free", ncol = 1, strip.position = "right")
```

On y voit qu'√† l'exception de la variable `long`, tous les coefficients sont √©loign√©s de 0. Le coefficient `bv` est n√©gatif, indiquant que plus la valeur de `bv` est √©lev√© (donc plus le sol est pauvre en mati√®re organique), plus le rendement est faible. Plus la latitude est √©lev√©e (plus on se dirige vers le Nord de l'Argentine), plus le rendement est √©lev√©. La dose d'azote a aussi un effet statistique positif sur le rendement.

Quant aux cat√©gories topographiques, elles sont toutes √©loign√©es de la cat√©gorie `E`, plac√©e √† z√©ro. De plus, les intervalles de confiance √† 0.95 ne se chevauchant pas, on peut conclure que la variabilit√© du ph√©nom√®ne √©chantillonn√© n'est pas suffisante pour expliquer les diff√©rences importantes d'une √† l'autre.

On pourra retrouver des cas o√π l'effet combin√© de plusieurs variables diff√®re de l'effet des deux variables prises s√©par√©ment. Par exemple, on pourrait √©valuer l'effet de l'azote et celui de la topographie dans un m√™me mod√®le, puis y ajouter une interaction entre l'azote et la topographie, qui d√©finira des effets suppl√©mentaires de l'azote selon chaque cat√©gorie topographique. C'est ce que l'on appelle une interaction.

Dans l'interface-formule, l‚Äôinteraction entre l'azote et la topographie est not√©e `nitro:topo`. Pour ajouter cette interaction, la formule deviendra `yield ~ nitro + topo + nitro:topo`. Une approche √©quivalente est d'utiliser le raccourci `yield ~ nitro * topo`.

```{r biostats-multivariate-lm-interaction}
modlin_5_sc <- lm(yield ~ nitro * topo,
               data = lasrosas.corn_sc)
summary(modlin_5_sc)
```

Les r√©sultats montre des effets de l'azote et des cat√©gories topographiques, mais il y a davantage d'incertitude sur les interactions, indiquant que l'effet statistique de l'azote est sensiblement le m√™me ind√©pendamment des niveaux topographiques.

Dans le cas des r√©gressions multiples, les r√©sidus ne peuvent pas √™tre pr√©sent√©s selon une variable explicative $x$, puisqu'il y en a plusieurs. On fera l'analyse des r√©sidus selon la variable r√©ponse $y$.

```{r biostats-residuals-mult-reg}
tibble(
  y = lasrosas.corn_sc$yield,
  residus = residuals(modlin_5_sc)
) %>% 
  ggplot(aes(x = y, y = residus)) +
  geom_point() +
  labs(x = "y", y = "R√©sidus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```
Dans ce mod√®le, il y a clairement une structure qui nous √©chappe! L'ajout de d'autres variables nous permettrait √©ventuellement d'obtenir une distribution qui s'approche d'un bruit.

#### Les interactions

Une interaction est un effet suppl√©mentaire qui est investigu√© pour des combinaisons de variables. L'interaction entre l'azote et la topographie est une nouvelle variable cr√©√©e par la multiplication de l'azote, une variable num√©rique, et de la topographie, qui ici est une variable cat√©gorielle.

```{r biostats-multivariate-modmat-interaction}
model.matrix(~ nitro * topo, data = lasrosas.corn_sc) %>% head()
```
L'ent√™te de la matrice mod√®le montre que l'interaction est l'addition de trois variables, qui sont nulles si la cat√©gorie topographique est absente, mais qui prend la dose d'azote pour la cat√©gorie pr√©sente seulement.

L'interpr√©tation d'une interaction est sp√©cifique au mod√®le utilis√©. Une mani√®re de l'interpr√©ter est de se demander dans quelles unit√©s elle est exprim√©e. Dans notre exemple, il s'agit de kg/ha standardis√©s.

Prenons un autre exemple, cette fois-ci avec des donn√©es fictives. Une enqu√™te a √©t√© men√©e, o√π des personnes √©valuait le karma (√©chelle 0 √† 10) de pieds nus, en bas (chaussettes) et/ou en sandales.

```{r biostats-karma-load-data}
karma_df <- read_csv("data/karma_df.csv")
```

Nous d√©sirons savoir quelle est l'effet des bas et des sandales sur le karma, donc üíñ ~ üë° + üß¶.

```{r biostats-karma-lm-simple}
tidy(lm(karma ~ sandales + bas, karma_df))
```
√Ä partir du sc√©nario √† pieds nus d'un karma de 3.67, les sandales ajoutent 2.29 de points de karma, alors que les bas en ajoutent 1.8. Mais ce mod√®le est incomplet, cas on n'√©value pas l'effet des bas ET des sandales, donc üíñ ~ üë° * üß¶.

```{r biostats-karma-lm-interaction}
tidy(lm(karma ~ sandales * bas, karma_df))
```

Le mod√®les est plus clair. Sans interaction, les effets sur le karma des bas et des sandales √©taient n√©gativement affect√©s par l'effet d'interaction `sandales:bas`, le karma √©tant pouss√© √† la baisse par le [bas blanc dans vos sandales](https://youtu.be/_whvVXX0hCk?t=86).

Il est possible d'ajouter des interactions doubles, triples, quadruples, etc. Mais plus il y a d‚Äôinteractions, plus votre mod√®le comprendra de variables et vos tests d'hypoth√®se perdront en puissance statistique.

#### Les mod√®les lin√©aires g√©n√©ralis√©s

Dans un mod√®le lin√©aire ordinaire, un changement constant dans les variables explicatives r√©sulte en un changement constant de la variable-r√©ponse. Cette supposition ne serait pas ad√©quate si la variable-r√©ponse √©tait un d√©compte, si elle est bool√©enne ou si, de mani√®re g√©n√©rale, la variable-r√©ponse ne suivait pas une distribution continue. Ou, de mani√®re plus sp√©cifique, il n'y a pas moyen de retrouver une distribution normale des r√©sidus? On pourra bien s√ªr transformer les variables (sujet du chapitre 6, en d√©veloppement). Mais il pourrait s'av√©rer impossible, ou tout simplement non souhaitable de transformer les variables. Le mod√®le lin√©aire g√©n√©ralis√© (MLG, ou *generalized linear model* - GLM) est une g√©n√©ralisation du mod√®le lin√©aire ordinaire chez qui la variable-r√©ponse peut √™tre caract√©ris√© par une distribution de Poisson, de Bernouilli, etc.

Prenons d'abord cas d'un d√©compte de vers fil-de-fer (`worms`) retrouv√©s dans des parcelles sous diff√©rents traitements (`trt`). Les d√©comptes sont typiquement distribu√© selon une loi de Poisson.

```{r biostats-multivariate-glm-hist}
cochran.wireworms %>% ggplot(aes(x = worms)) + geom_histogram(bins = 10)
```

Explorons les d√©comptes selon les traitements.

```{r biostats-multivariate-glm-boxplot}
cochran.wireworms %>% ggplot(aes(x = trt, y = worms)) + geom_boxplot()
```

Les traitements semble √† premi√®re vue avoir un effet comparativement au contr√¥le. Lan√ßons un MLG avec la fonction `glm()`, et sp√©cifions que la sortie est une distribution de Poisson. Bien que la fonction de lien (`link = "log"`) soit explictement impos√©e, le log est la valeur par d√©faut pour les distributions de Poisson. Ainsi, les coefficients du mod√®les devront √™tre interpr√©t√©s selon un mod√®le $log \left(worms \right) = intercept + pente \times coefficient$.

```{r biostats-multivariate-glm-model}
modglm_1 <- glm(worms ~ trt, cochran.wireworms, family = stats::poisson(link="log"))
summary(modglm_1)
```

L'interpr√©tation sp√©cifique des coefficients d'une r√©gression de Poisson doit passer par la fonction de lien $log \left(worms \right) = intercept + pente \times coefficient$. Le traitement de r√©f√©rence (K), qui correspond √† l'intercept, sera accompagn√© d'un nombre de vers de $exp \left(0.1823\right) = 1.20$ vers, et le traitement M, √† $exp \left(1.6422\right) = 5.17$ vers. Cela correspond √† ce que l'on observe sur les boxplots plus haut.

Il est tr√®s probable (p-value de ~0.66) qu'un intercept (traitement K) de 0.18 ayant une erreur standard de 0.4082 ait √©t√© g√©n√©r√© depuis une population dont l'intercept est nul. Quant aux autres traitements, leurs effets sont tous significatifs au seuil 0.05, mais peuvent-ils √™tre consid√©r√©s comme √©quivalents?

```{r biostats-multivariate-glm-ci}
intervals <- tibble(Estimate = coefficients(modglm_1), # [-1] enlever l'intercept
                    LL = confint(modglm_1)[, 1], # [-1, ] enlever la premi√®re ligne, celle de l'intercept
                    UL = confint(modglm_1)[, 2],
                    variable = names(coefficients(modglm_1)))
intervals
```

```{r biostats-multivariate-glm-plot-effects}
ggplot(data = intervals, mapping = aes(x = Estimate, y = variable)) +
    geom_vline(xintercept = 0, lty = 2) +
    geom_segment(mapping = aes(x = LL, xend = UL,
                               y = variable, yend = variable)) +
    geom_point() +
    labs(x = "Coefficient", y = "")
```

Les intervalles de confiance se superposant, on ne peut pas conclure qu'un traitement est li√© √† une r√©duction plus importante de vers qu'un autre, au seuil 0.05.

Maintenant, √† d√©faut de trouver un tableau de donn√©es plus appropri√©, prenons le tableau `mtcars`, qui rassemble des donn√©es sur des mod√®les de voitures. La colonne `vs`, pour v-shaped, inscrit 0 si les pistons sont droit et 1 s'ils sont plac√©s en V dans le moteur. Peut-on expliquer la forme des pistons selon le poids du v√©hicule (`wt`)?

```{r biostats-multivariate-glm-cars}
mtcars %>% sample_n(6)
```

```{r biostats-multivariate-glm-cars-plot}
mtcars %>%
    ggplot(aes(x = wt, y = vs)) + geom_point()
```

Il semble y avoir une tendance: les v√©hicules plus lourds ont plut√¥t des pistons droits (`vs = 0`). V√©rifions cela.

```{r biostats-multivariate-glm-cars-model}
modglm_2 <- glm(vs ~ wt, data = mtcars, family = stats::binomial())
summary(modglm_2)
```

**Exercice**. Analyser les r√©sultats.

#### Les mod√®les non-lin√©aires

La hauteur d'un arbre en fonction du temps n'est typiquement pas lin√©aire. Elle tend √† cro√Ætre de plus en plus lentement jusqu'√† un plateau. De m√™me, le rendement d'une culture trait√© avec des doses croissantes de fertilisants tend √† atteindre un maximum, puis √† se stabiliser.

Ces ph√©nom√®nes ne peuvent pas √™tre approxim√©s par des mod√®les lin√©aires. Examinons les donn√©es du tableau `engelstad.nitro`.

```{r biostats-multivariate-nls-data}
engelstad.nitro %>% sample_n(10)
```

```{r biostats-multivariate-nls-plot}
engelstad.nitro %>%
    ggplot(aes(x = nitro, y = yield)) +
        facet_grid(year ~ loc) +
        geom_line() +
        geom_point()
```

Le mod√®le de Mitscherlich pourrait √™tre utilis√©.

$$ y = A \left( 1 - e^{-R \left( E + x \right)} \right) $$

o√π $y$ est le rendement, $x$ est la dose, $A$ est l'asymptote vers laquelle la courbe converge √† dose croissante, $E$ est l'√©quivalent de dose fourni par l'environnement et $R$ est le taux de r√©ponse.

Explorons la fonction.

```{r biostats-multivariate-nls-miscth-explore}
mitscherlich_f <- function(x, A, E, R) {
    A * (1 - exp(-R*(E + x)))
}

x <- seq(0, 350, by = 5)
y <- mitscherlich_f(x, A = 75, E = 30, R = 0.02)

ggplot(tibble(x, y), aes(x, y)) +
    geom_point(data = engelstad.nitro, aes(x = nitro, y = yield)) +
    geom_line() + ylim(c(0, 100))
```

**Exercice**. Changez les param√®tres pour visualiser comment la courbe r√©agit.

Nous pouvons d√©crire le mod√®le gr√¢ce √† l'interface formule dans la fonction `nls()`. Notez que les mod√®les non-lin√©aires demandent des strat√©gies de calcul diff√©rentes de celles des mod√®les lin√©aires. En tout temps, nous devons identifier des valeurs de d√©part raisonnables pour les param√®tres dans l'argument `start`. Vous r√©ussirez rarement √† obtenir une convergence du premier coup avec vos param√®tres de d√©part. Le d√©fi est d'en trouver qui permettront au mod√®le de converger. Parfois, le mod√®le ne convergera jamais. D'autres fois, il convergera vers des solutions diff√©rentes selon les variables de d√©part choisies.

```
modnl_1 <- nls(yield ~ A * (1 - exp(-R*(E + nitro))),
                data = engelstad.nitro,
                start = list(A = 50, E = 10, R = 0.2))
```

Le mod√®le ne converge pas (le bloc de calcul est d√©sactiv√©). Essayons les valeurs prises plus haut, lors de la cr√©ation du graphique, qui semblent bien s'ajuster.

```{r biostats-multivariate-nls-model}
modnl_1 <-  nls(yield ~ A * (1 - exp(-R*(E + nitro))),
                data = engelstad.nitro,
                start = list(A = 75, E = 30, R = 0.02))
```

Bingo! Voyons maintenant le sommaire.

```{r biostats-multivariate-nls-summary}
summary(modnl_1)
```

Les param√®tres sont diff√©rents de z√©ro, et donnent la courbe suivante.

```{r biostats-multivariate-nls-resultat-plot}
x <- seq(0, 350, by = 5)
y <- mitscherlich_f(x,
                    A = coefficients(modnl_1)[1],
                    E = coefficients(modnl_1)[2],
                    R = coefficients(modnl_1)[3])

ggplot(tibble(x, y), aes(x, y)) +
    geom_point(data = engelstad.nitro, aes(x = nitro, y = yield)) +
    geom_line() + ylim(c(0, 100))
```

Et les r√©sidus...

```{r biostats-multivariate-nls-residuals}
tibble(res = residuals(modnl_1)) %>%
    ggplot(aes(x = res)) + geom_histogram(bins = 20)
```

```{r biostats-multivariate-nls-residuals2}
tibble(nitro = engelstad.nitro$nitro, res = residuals(modnl_1)) %>%
    ggplot(aes(x = nitro, y = res)) +
        geom_point() +
        geom_hline(yintercept = 0, colour = "red")
```

Les r√©sidus ne sont pas distribu√©s normalement, mais semble bien partag√©s de part et d'autre de la courbe.

### Mod√®les √† effets mixtes

Lorsque l'on combine des variables fixes (test√©es lors de l'exp√©rience) et des variables al√©atoire (variation des unit√©s exp√©rimentales), on obtient un mod√®le mixte. Les mod√®les mixtes peuvent √™tre univari√©s, multivari√©s, lin√©aires ordinaires ou g√©n√©ralis√©s ou non lin√©aires.

√Ä la diff√©rence d'un effet fixe, un effet al√©atoire sera toujours distribu√© normalement avec une moyenne de 0 et une certaine variance. Dans un mod√®le lin√©aire o√π l'effet al√©atoire est un d√©calage d'intercept, cet effet s'additionne aux effets fixes:

$$ y = X \beta + Z b + \epsilon $$

o√π:

$Z$ est la matrice du mod√®le √† $n$ observations et $p$ variables al√©atoires. Les variables al√©atoires sont souvent des variables nominales qui subissent un encodage cat√©goriel.

$$ Z = \left( \begin{matrix}
z_{11} & \cdots & z_{1p}  \\
z_{21} & \cdots & z_{2p}  \\
\vdots & \ddots & \vdots  \\
z_{n1} & \cdots & z_{np}
\end{matrix} \right) $$

$b$ est la matrice des $p$ coefficients al√©atoires.

$$ b = \left( \begin{matrix}
b_0  \\
b_1  \\
\vdots \\
b_p
\end{matrix} \right) $$

Le tableau `lasrosas.corn`, utilis√© pr√©c√©demment, contenait trois r√©p√©titions effectu√©s au cours de deux ann√©es, 1999 et 2001. √âtant donn√© que la r√©p√©tition R1 de 1999 n'a rien √† voir avec la r√©p√©tition R1 de 2001, on dit qu'elle est **embo√Æt√©e** dans l'ann√©e.

Le module `nlme` nous aidera √† monter notre mod√®le mixte.

```{r biostats-multivariate-nlme-model}
library("nlme")
mmodlin_1 <- lme(fixed = yield ~ lat + long + nitro + topo + bv,
                 random = ~ 1|year/rep,
                 data = lasrosas.corn)
```

√Ä ce stade vous devriez commencer √† √™tre familier avec l'interface formule et vous deviez saisir l'argument `fixed`, qui d√©signe l'effet fixe. L'effet al√©atoire, `random`, suit un tilde `~`. √Ä gauche de la barre verticale `|`, on place les variables d√©signant les effets al√©atoire sur la pente. Nous n'avons pas couvert cet aspect, alors nous le laissons √† `1`. √Ä droite, on retrouve un structure d'embo√Ætement d√©signant l'effet al√©atoire: le premier niveau est l'ann√©e, dans laquelle est embo√Æt√©e la r√©p√©tition.

```{r biostats-multivariate-nlme-model}-summ
summary(mmodlin_1)
```

La sortie est semblable √† celle de la fonction `lm()`.

#### Mod√®les mixtes non-lin√©aires

Le mod√®le non lin√©aire cr√©√© plus haut liait le rendement √† la dose d'azote. Toutefois, les unit√©s exp√©rimentales (le site `loc` et l'ann√©e `year`) n'√©taient pas pris en consid√©ration. Nous allons maintenant les consid√©rer.

Nous devons d√©cider la structure de l'effet al√©atoire, et sur quelles variables il doit √™tre appliqu√© - la d√©cision appartient √† l'analyste. Il me semble plus convenable de supposer que le site et l'ann√©e affectera le rendement maximum plut√¥t que l'environnement et le taux: les effets al√©atoires seront donc affect√©s √† la variable `A`. Les effets al√©atoires n'ont pas de structure d'embo√Ætement. L'effet de l'ann√©e sur A sera celui d'une pente et l'effet de site sera celui de l'intercept. La fonction que nous utiliserons est `nlme()`.

```{r biostats-multivariate-nlme-nl-model}
mm <- nlme(yield ~ A * (1 - exp(-R*(E + nitro))),
           data = engelstad.nitro,
           start = c(A = 75, E = 30, R = 0.02),
           fixed = list(A ~ 1, E ~ 1, R ~ 1),
           random = A ~ year | loc)
summary(mm)
```

Et sur graphique:

```{r biostats-multivariate-nlme-nl-plot}
engelstad.nitro %>%
  ggplot(aes(x = nitro, y = yield)) +
  facet_grid(year ~ loc) +
  geom_line(data = tibble(nitro = engelstad.nitro$nitro,
                          yield = predict(mm, level = 0)),
            colour = "grey35") +
  geom_point() +
  ylim(c(0, 95))
```


Les mod√®les mixtes non lin√©aires peuvent devenir tr√®s complexes lorsque les param√®tres, par exemple A, E et R, sont eux-m√™me affect√©s lin√©airement par des variables (par exemple `A ~ topo`). Pour aller plus loin, consultez [Parent et al. (2017) ](https://doi.org/10.3389/fenvs.2017.00081) ainsi que les [calculs associ√©s √† l'article](https://github.com/essicolo/site-specific-multilevel-modeling-of-potato-response-to-nitrogen-fertilization). Ou √©crivez-moi un courriel pour en discuter!

**Note**. L'interpr√©tation de p-values sur les mod√®les mixtes est controvers√©e. √Ä ce sujet, Douglas Bates a √©crit une longue lettre √† la communaut√© de d√©veloppement du module `lme4`, une alternative √† `nlme`, qui remet en cause l'utilisation des p-values, [ici](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html). De plus en plus, pour les mod√®les mixtes, on se tourne vers les statistiques bay√©siennes, couvertes dans le chapitre \@ref(chapitre-biostats-bayes) avec le module greta. Mais en ce qui a trait aux mod√®les mixtes, le module [`brms`](https://github.com/paul-buerkner/brms) automatise bien des aspects de l'approche bay√©sienne.

### Aller plus loin

#### Statistiques g√©n√©rales:
- [The analysis of biological data](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=the+analysis+of+biological+data&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=5&rq.st=1)

#### Statistiques avec R

- Disponibles en version √©lectronique √† la biblioth√®que de l'Universit√© Laval:
    - Introduction aux statistiques avec R: [Introductory statistics with R](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=Introductory+statistics+with+R&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=1&rq.st=0)
    - Approfondir les statistiques avec R: [The R Book, Second edition](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=the+r+book&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=15&rq.st=2)
    - Approfondir les mod√®les √† effets mixtes avec R: [Mixed Effects Models and Extensions in Ecology with R](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=Mixed+Effects+Models+and+Extensions+in+Ecology+with+R&rq.r.la=*&rq.r.loc=*&rq.r.pft=false&rq.r.ta=*&rq.r.td=*&rq.rows=2&rq.st=1)
- [ModernDive](https://moderndive.com/index.html), un livre en ligne offrant une approche moderne avec le package `moderndive`.

```{r biostats-rm-all, include=FALSE}
rm(list = ls())
```
