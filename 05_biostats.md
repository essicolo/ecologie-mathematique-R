Biostatistiques
================
Serge-√âtienne Parent
2018-11-27

Aux chapitres pr√©c√©dents, nous avons vu comment visualiser, organiser et
manipuler des tableaux de donn√©es. La statistique est une collection de
disciplines li√©es √† la collecte, l‚Äôoragnisation, l‚Äôanalyse,
l‚Äôinterpr√©tation et la pr√©sentation de donn√©es. Les biostatistiques
est l‚Äôapplication de ces disciplines √† la biosph√®re.

Dans [*Principles and procedures of statistics: A biometrical
approach*](https://www.amazon.com/Principles-Procedures-Statistics-Biometrical-Approach/dp/0070610282),
Steel, Torie et Dickey (1997) d√©finissent les statistiques ainsi:

> Les statistiques forment la science, pure et appliqu√©e, de la
> cr√©ation, du d√©veloppement, et de l‚Äôapplication de techniques par
> lesquelles l‚Äôincertitude de l‚Äôinduction inf√©rentielle peut √™tre
> √©valu√©e. (ma traduction)

Alors que l‚Äôinf√©rence consiste √† g√©n√©raliser des observations sur des
√©chantillons √† l‚Äôensemble d‚Äôune population, l‚Äôinduction est un type de
raisonnement qui permet de g√©n√©raliser des observations en th√©ories. Les
statistiques permettent d‚Äô√©valuer l‚Äôincertitude d√©coulant du processus
qui permet d‚Äôabord de passer de l‚Äô√©chantillon √† la population repr√©sent√©
par cet √©chantillon, puis de passer de cette repr√©sentation d‚Äôune
population en lois g√©n√©rales la concernant.

La d√©finition de Whitlock et Schuluter (2015), dans [The Analysis of
Biological Data](http://whitlockschluter.zoology.ubc.ca/), est plus
simple, insistant sur l‚Äôinf√©rence:

> La statistique est l‚Äô√©tude des m√©thodes pour d√©crire et mesures des
> aspects de la nature √† partir d‚Äô√©chantillons. (ma traduction)

Les statistiques consistent √† *faire du sens* (anglicisme assum√©) avec
des observations: collecter des √©chantillons, transformer les donn√©es,
effectuer des tests, analyser les r√©sultats, les interpr√©ter et les
visualiser. Bien que ces t√¢ches soient complexes, en particulier en ce
qui a trait aux tests statistiques, la plupart des op√©rations
statistiques peuvent √™tre effectu√©es sans l‚Äôassistance de
statisticien.ne.s‚Ä¶ √† condition de comprendre suffisamment les concepts
utilis√©s. Ce chapitre √† lui seul est trop court pour permettre
d‚Äôint√©grer toutes les connaissances n√©cessaires √† une utilisation
raisonn√©e des statistiques, mais fourni les bases pour aller plus loin.
Notez que les erreurs d‚Äôinterpr√©tation statistiques sont courantes et la
consultation de sp√©cialistes n‚Äôest souvent pas un luxe.

Dans ce chapitre, nous verrons comment r√©pondre correctement √† une
question valide et ad√©quate avec l‚Äôaide d‚Äôoutils de calcul scientifique.
Nous couvrirons les notions de bases des distributions et des variables
al√©atoires qui nous permettront d‚Äôeffectuer des tests statistiques
commun avec R. Nous couvrirons aussi les erreurs commun√©ment commises en
recherche acad√©mique et les moyens simples de les √©viter.

Ce chapitre est une introduction aux statistiques avec R, et ne
rempalcera pas un bon cours de stats.

En plus des modules de base de R nous utiliserons

  - les modules de la `tidyverse`,
  - le module de don√©es agricoles `agridat`, ainsi que
  - le module `nlme` sp√©cialis√© pour la mod√©lisation mixte.

Avant de survoler les applications statistiques avec R, je vais d‚Äôabord
et rapidement pr√©senter quelques notions importantes en statistiques:
populations et √©chantillons, variables, probabilit√©s et distributions.
Nous allons effectuer des tests d‚Äôhypoth√®se univari√©s (notamment les
tests de *t* et les analyses de variance) et d√©tailler la notion de
p-value. Mais avant tout, je vais m‚Äôattarder plus longuement aux mod√®les
lin√©aires g√©n√©ralis√©s, incluant en particulier des effets fixes et
al√©atoires (mod√®les mixtes), qui fournissent une trousse d‚Äôanalyse
polyvalente en analyse multivari√©e. Je terminerai avec les perspectives
multivari√©s que sont les matrices de covariance et de corr√©lation.

# Populations et √©chantillons

Le principe d‚Äôinf√©rence consiste √† g√©n√©raliser des conclusions √†
l‚Äô√©chelle d‚Äôune population √† partir d‚Äô√©chantillons issus de cette
population. Alors qu‚Äôune **population** contient tous les √©l√©ments
√©tudi√©s, un **√©chantillon** d‚Äôune population est une observation
unique. Une exp√©rience bien con√ßue fera en sorte que les √©chantillons
sont repr√©sentatifs de la population qui, la plupart du temps, ne peut
√™tre observ√©e enti√®rement pour des raisons pratiques.

Les principes d‚Äôexp√©rimentation servant de base √† la conception d‚Äôune
bonne m√©thodologie sont pr√©sent√©s dans le cours [*Dispositifs
exp√©rimentaux
(BVG-7002)*](https://www.ulaval.ca/les-etudes/cours/repertoire/detailsCours/bvg-7002-dispositifs-experimentaux.html).
√âgalement, je recommande le livre *Princpes d‚Äôexp√©rimentation:
planification des exp√©riences et analyse de leurs r√©sultats* de Pierre
Dagnelie (2012), [disponible en ligne en format
PDF](http://www.dagnelie.be/docpdf/ex2012.pdf). Un bon aper√ßu des
dispositifs exp√©rimentaux est aussi pr√©sent√© dans [*Introductory
Statistics with R*](https://www.springer.com/us/book/9780387790534), de
Peter Dalgaard (2008).

Une population est √©chantillonn√©e pour induire des **param√®tres**: un
rendement typique dans des conditions m√©t√©orologiques, √©daphiques et
manag√©riales donn√©es, la masse typique des faucons p√©lerins, m√¢les et
femelles, le microbiome typique d‚Äôun sol agricole ou forestier, etc. Une
**statistique** est une estimation d‚Äôun param√®tre calcul√©e √† partir des
donn√©es, par exemple une moyenne et un √©cart-type.

Par exemple, la moyenne (\(\mu\)) et l‚Äô√©cart-type (\(\sigma\)) d‚Äôune
population sont estim√©s par les moyennes (\(\bar{x}\)) et √©carts-types
(\(s\)) calcul√©s sur les donn√©es issues de l‚Äô√©chantillonnage.

Chaque param√®tre est li√©e √† une perspective que l‚Äôon d√©sire cona√Ætre
chez une population. Ces angles d‚Äôobservations sont les **variables**.

# Les variables

Nous avons abord√© au chapitre 4 la notion de *variable* par
l‚Äôinterm√©diaire d‚Äôune donn√©e. Une variable est l‚Äôobservation d‚Äôune
caract√©ristique d√©crivant un √©chantillon et qui est susceptible de
varier d‚Äôun √©chantillon √† un autre. Si les observations varient en effet
d‚Äôun √©chantillon √† un autre, on parlera de variable al√©atoire. M√™me le
hasard est r√©git par certaines loi: ce qui est al√©atoire dans une
variable peut √™tre d√©crit par des **lois de probabilit√©**, que nous
verrons plus bas.

Mais restons aux variables pour l‚Äôinstant. Par convention, on peut
attribuer aux variables un symbole math√©matique. Par exemple, on peut
donner √† la masse volumique d‚Äôun sol (qui est le r√©sultat d‚Äôune
m√©thodologie pr√©cise) le sympole \(\rho\). Lorsque l‚Äôon attribue une
valeur √† \(\rho\), on parle d‚Äôune donn√©e. Chaque donn√©e d‚Äôune
observation a un indice qui lui est propre, que l‚Äôon d√©signe souvent par
\(i\), que l‚Äôon place en indice \(\rho_i\). Pour la premi√®re donn√©e, on
a \(i=1\), donc \(\rho_1\). Pour un nombre \(n\) d‚Äô√©chantillons, on aura
\(\rho_1\), \(\rho_2\), \(\rho_3\), ‚Ä¶, \(\rho_n\), formant le vecteur
\(\rho = \left[\rho_1, \rho_2, \rho_3, ..., \rho_n \right]\).

En R, une variable est associ√©e √† un vecteur ou une colonne d‚Äôun
tableau.

``` r
rho <- c(1.34, 1.52, 1.26, 1.43, 1.39) # matrice 1D
data <- data.frame(rho = rho) # tableau
data
```

    ##    rho
    ## 1 1.34
    ## 2 1.52
    ## 3 1.26
    ## 4 1.43
    ## 5 1.39

Il existe plusieurs types de variables, qui se regroupe en deux grandes
cat√©gories: les **variables quantitatives** et les **variables
qualitatives**.

## Variables quantitatives

Ces variables peuvent √™tre continuent dans un espace √©chantillonal r√©el
ou discr√®tes dans un espace √©chantillonnal ne consid√©rant que des
valeurs fixes. Notons que la notion de nombre r√©el est toujours une
approximation en sciences exp√©rimentales comme en calcul num√©rique,
√©tant donn√©e que l‚Äôon est limit√© par la pr√©cision des appareils comme
par le nombre d‚Äôoctets √† utiliser. Bien que les valeurs fixes des
disctributions discr√®tes ne soient pas toujours des valeurs enti√®res,
c‚Äôest bien souvent le cas en biostatistiques comme en d√©mocgraphie, o√π
les d√©comptes d‚Äôindividus sont souvents pr√©sents (et o√π la notion de
fraction d‚Äôindividus n‚Äôest pas accept√©e).

## Variables qualitatives

On exprime parfois qu‚Äôune variable qualitative est une variable
impossible √† mesurer num√©riquement: une couleur, l‚Äôappartenance √† esp√®ce
ou √† une s√©rie de sol. Pourtant, dans bien des cas, les variables
qualitatives peut √™tre encod√©es en variables quantitatives. Par exemple,
on peut accoler des pourcentages de sable, limon et argile √† un loam
sableux, qui autrement est d√©crit par la classe texturale d‚Äôun sol. Pour
une couleur, on peut lui associer des pourcentages de rouge, vert et
bleu, ainsi qu‚Äôun ton. En ce qui a trait aux variables ordonn√©es, il est
possible de supposer un √©talement. Par exemple, une variable d‚Äôintensit√©
faible-moyenne-forte peut √™tre transform√©e lin√©airement en valeurs
quantitatives -1, 0 et 1. Attention toutefois, l‚Äô√©talement peut parfois
√™tre quadratique ou logarithmique. Les s√©ries de sol peuvent √™tre
encod√©es par la proportion de gleyfication ([Parent et
al., 2017](https://www.frontiersin.org/articles/10.3389/fenvs.2017.00081/full#B4)).
Quant aux cat√©gories difficilement transformables en quantit√©s, on
pourra passer par l‚Äô**encodage cat√©goriel**, souvent appel√©
*dummyfication*, qui nous verrons plus loin.

# Les probabilit√©s

> ¬´ Nous sommes si √©loign√©s de conna√Ætre tous les agens de la nature, et
> leurs divers modes d‚Äôaction ; qu‚Äôil ne serait pas philosophique de
> nier les ph√©nom√®nes, uniquement parce qu‚Äôils sont inexplicables dans
> l‚Äô√©tat actuel de nos connaissances. Seulement, nous devons les
> examiner avec une attention d‚Äôautant plus scrupuleuse, qu‚Äôil para√Æt
> plus difficile de les admettre ; et c‚Äôest ici que le calcul des
> probabilit√©s devient indispensable, pour d√©terminer jusqu‚Äô√† quel point
> il faut multiplier les observations ou les exp√©riences, afin d‚Äôobtenir
> en faveur des agens qu‚Äôelles indiquent, une probabilit√© sup√©rieure aux
> raisons que l‚Äôon peut avoir d‚Äôailleurs, de ne pas les admettre. ¬ª ‚Äî
> Pierre-Simon de Laplace

Une probabilit√© est la vraissemblance qu‚Äôun √©v√©nements se r√©alise chez
un √©chantillon. Les probabilit√©s forment le cadre des syst√®mes
stochastiques, c‚Äôest-√†-dire des syst√®mes trop complexes pour en
conna√Ætre exactement les aboutissants, auxquels ont attribue une part
de hasard. Ces syst√®mes sont pr√©dominants dans les processus vivants.

On peut d√©gager deux perspectives sur les probabilit√©s: l‚Äôune passe par
une interpr√©tations fr√©quentistes, l‚Äôautre bay√©siennes. L‚Äôinterpr√©tation
**fr√©quentiste** repr√©sente la fr√©quence des occurences apr√®s un nombre
infini d‚Äô√©v√©nements. Par exemple, si vous jouez √† pile ou face un grand
nombre de fois, le nombre de pile sera √©gal √† la moiti√© du nombre de
lanc√©s. Il s‚Äôagit de l‚Äôinterpr√©tation commun√©ment utilis√©e.

L‚Äôinterpr√©tation **bay√©sienne** vise √† quantifier l‚Äôincertitude des
ph√©nom√®nes. Dans cette perspective, plus l‚Äôinformation s‚Äôaccumule, plus
l‚Äôincertitude diminue. Cette approche gagne en notori√©t√© notamment parce
qu‚Äôelle permet de d√©crire des ph√©nom√®nes qui, intrins√®quement, ne
peuvent √™tre r√©p√©t√©s infiniments (absence d‚Äôasymptote), comme celles qui
sont bien d√©finis dans le temps ou sur des populations limit√©s.

L‚Äôapproche fr√©quentielle teste si les donn√©es concordent avec un mod√®le
du r√©el, tandis que l‚Äôapproche bay√©sienne √©value la probabilit√© que le
mod√®le soit r√©el. Une erreur courrante consiste √† aborder des
statistiques fr√©quentielles comme des statistiques bay√©siennes. Par
exemple, si l‚Äôon d√©sire √©valuer la probabilit√© de l‚Äôexistance de vie sur
Mars, on devra passer par le bay√©sien, car avec les stats
fr√©quentielles, l‚Äôon devra plut√¥t conclure si les donn√©es sont conforme
ou non avec l‚Äôhypoth√®se de la vie sur Mars (exemple tir√©e du blogue
[Dynamic
Ecology](https://dynamicecology.wordpress.com/2011/10/11/frequentist-vs-bayesian-statistics-resources-to-help-you-choose/)).

Des rivalit√©s factices s‚Äôinstallent enter les tenants des diff√©rentes
approches, dont chacune, en r√©alit√©, r√©pond √† des questions diff√©rentes
dont il convient r√©fl√©chir sur les limitations. Bien que les
statistiques bay√©siennes soient de plus en plus utilis√©es, nous ne
couvrirons dans ce chapitre que l‚Äôapproche fr√©quentielle. L‚Äôapproche
bay√©sienne est n√©amoins trait√©e dans le document comppl√©mentaire
statistiques\_bayes.ipynb (section en d√©veloppement).

# Les distributions

Une variable al√©atoire peut prendre des valeurs selon des mod√®les de
distribution des probabilit√©s. Une distribution est une fonction
math√©matique d√©crivant la probabilit√© d‚Äôobserver une s√©rie
d‚Äô√©vennements. Ces √©v√©nemements peuvent √™tre des valeurs continues,
des nombres entiers, des cat√©gories, des valeurs bool√©ennes (Vrai/Faux),
etc. D√©pendamment du type de valeur et des observations obtenues, on
peut associer des variables √† diff√©rentes lois de probabilit√©. Toujours,
l‚Äôaire sous la courbe d‚Äôune distribution de probabilit√© est √©gale √† 1.

En statistiques inf√©rentielle, les distributions sont les mod√®les,
comprenant certains param√®tres comme la moyenne et la variance pour les
distributions normales, √† partir desquelles les donn√©es sont g√©n√©r√©es.

Il existe deux grandes familles de distribution: **discr√®tes** et
**continues**. Les distributions discr√®tes sont contraintes √† des
valeurs pr√©d√©finies (finies ou infinies), alors que les distributions
continues prennent n√©cessairement un nombre infinie de valeur, dont la
probabilit√© ne peut pas √™tre √©valu√©e ponctuellement, mais sur un
intervalle.

L‚Äô**esp√©rance** math√©matique est une fonction de tendance centrale,
souvent d√©crite par un param√®tre. Il s‚Äôagit de la moyenne d‚Äôune
population pour une distribution normale. La **variance**, quant √† elle,
d√©crit la variabilit√© d‚Äôune population, i.e.¬†son √©talement autour de
l‚Äôesp√©rance. Pour une distribution normale, la variance d‚Äôune
population est aussi appel√©e variance, souvent pr√©sent√©e par
l‚Äô√©cart-type.

## Distribution binomiale

En tant que sc√©nario √† deux issues possibles, des tirages √† pile ou face
suivent une loi binomiale, comme toute variable bool√©enne prenant une
valeur vraie ou fausse. En biostatistiques, les cas communs sont la
pr√©sence/absence d‚Äôune esp√®ce, d‚Äôune maladie, d‚Äôun trait
phylog√©n√©tique, ainsi que les cat√©gories encod√©es. Lorsque l‚Äôop√©ration
ne comprend qu‚Äôun seul √©chantillon (i.e.¬†un seul tirage √† pile ou face),
il s‚Äôagit d‚Äôun cas particulier d‚Äôune loi binomiale que l‚Äôon nomme une
loi de *Bernouilli*.

Pour 25 tirages √† pile ou face ind√©pendants (i.e.¬†dont l‚Äôordre des
tirages ne compte pas), on peut dessiner une courbe de distribution dont
la somme des probabilit√©s est de 1. La fonction `dbinom` est une
fonctions de distribution de probabilit√©s. Les fonctions de distribution
de probabilit√©s discr√®tes sont appel√©es des fonctions de
    masse.

``` r
library("tidyverse")
```

    ## Warning: package 'tidyverse' was built under R version 3.5.1

    ## -- Attaching packages ---------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.1.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.8
    ## v tidyr   0.8.2     v stringr 1.3.1
    ## v readr   1.2.1     v forcats 0.3.0

    ## Warning: package 'tidyr' was built under R version 3.4.4

    ## Warning: package 'readr' was built under R version 3.4.4

    ## Warning: package 'dplyr' was built under R version 3.4.4

    ## -- Conflicts ------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
x <- 0:25
y <- dbinom(x = x, size = 25, prob = 0.5)
print(paste('La somme des probabilit√©s est de', sum(y)))
```

    ## [1] "La somme des probabilit√©s est de 1"

``` r
ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y), color = "grey50") +
  geom_point()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

## Distribution de Poisson

La loi de Poisson (avec un P majuscule, introduite par le math√©maticien
fran√ßais Sim√©on Denis Poisson et non pas l‚Äôanimal) d√©crit des
distributions discr√®tes de probabilit√© d‚Äôun nombre d‚Äô√©v√©nements se
produisant dans l‚Äôespace ou dans le temps. Les distributions de Poisson
d√©crive ce qui tient du d√©compte. Il peut s‚Äôagir du nombre de
grenouilles traversant une rue quotidiennement, du nombre de plants
d‚Äôascl√©piades se trouvant sur une terre cultiv√©e, ou du nombre
d‚Äô√©v√©nements de pr√©cipitation au mois de juin, etc. La distribution
de Poisson n‚Äôa qu‚Äôun seul param√®tre, \(\lambda\), qui d√©crit tant la
moyenne des d√©comptes.

Par exemple, en un mois de 30 jours, et une moyenne de 8 √©v√©nements de
pr√©cipitation pour ce mois, on obtient la distribution suivante.

``` r
x <- 1:30
y <- dpois(x, lambda = 8)
print(paste('La somme des probabilit√©s est de', sum(y)))
```

    ## [1] "La somme des probabilit√©s est de 0.999664536835124"

``` r
ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_segment(aes(x = x, xend = x, y = 0, yend = y), color = "grey50") +
  geom_point()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->

## Distribution uniforme

La distribution la plus simple est probablement la distribution
uniforme. Si la variable est discr√®te, chaque cat√©gorie est associ√© √†
une probabilit√© √©gale. Si la variable est continue, la probabilit√© est
directement proportionnelle √† la largeur de l‚Äôintervalle. On utilise
rarement la distribution uniforme en biostatistiques, sinon pour d√©crire
des *a priori* vagues pour l‚Äôanalyse bay√©sienne (ce sujet est trait√©
dans le document 5.1\_bayes.ipynb). Nous utilisons la fonction `dunif`.
√Ä la diff√©rence des distributions discr√®tes, les fonctions de
distribution de probabilit√©s continues sont appel√©es des fonctions de
densit√© d‚Äôune loi de probabilit√© (*probability density function*).

``` r
increment <- 0.01
x <- seq(-4, 4, by = increment)
y1 <- dunif(x, min = -3, max = 3)
y2 <- dunif(x, min = -2, max = 2)
y3 <- dunif(x, min = -1, max = 1)

print(paste('La somme des probabilit√©s est de', sum(y3 * increment)))
```

    ## [1] "La somme des probabilit√©s est de 1.005"

``` r
gg_unif <- data.frame(x, y1, y2, y3) %>% gather(variable, value, -x)

ggplot(data = gg_unif, mapping = aes(x = x, y = value)) +
  geom_line(aes(colour = variable))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

## Distribution normale

La plus r√©pendue de ces lois est probablement la loi normale, parfois
nomm√©e loi gaussienne et plus rarement loi laplacienne. Il s‚Äôagit de la
distribution classique en forme de cloche.

La loi normale est d√©crite par une moyenne, qui d√©signe la tendance
centrale, et une variance, qui d√©signe l‚Äô√©talement des probabilit√©s
autours de la moyenne. La racine carr√©e de la variance est l‚Äô√©cart-type.

Les distributions de mesures exclusivement positives (comme le poids ou
la taille) sont parfois avantageusement approxim√©es par une loi
**log-normale**, qui est une loi normale sur le logarithme des valeurs:
la moyenne d‚Äôune loi log-normale est la moyenne g√©om√©trique.

``` r
increment <- 0.01
x <- seq(-10, 10, by = increment)
y1 <- dnorm(x, mean = 0, sd = 1)
y2 <- dnorm(x, mean = 0, sd = 2)
y3 <- dnorm(x, mean = 0, sd = 3)

print(paste('La somme des probabilit√©s est de', sum(y3 * increment)))
```

    ## [1] "La somme des probabilit√©s est de 0.999147010743368"

``` r
gg_norm <- data.frame(x, y1, y2, y3) %>% gather(variable, value, -x)

ggplot(data = gg_norm, mapping = aes(x = x, y = value)) +
  geom_line(aes(colour = variable))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

Quelle est la probabilit√© d‚Äôobtenir le nombre 0 chez une observation
continue distribu√©e normalement dont la moyenne est 0 et l‚Äô√©cart-type
est de 1? R√©ponse: 0. La loi normale √©tant une distribution continue,
les probabilit√©s non-nulles ne peuvent √™tre calcul√©s que sur des
intervalles. Par exemple, la probabilit√© de retrouver une valeur dans
l‚Äôintervalle entre -1 et 2 est calcul√©e en soustraiyant la probabilit√©
cumul√©e √† -1 de la probabilit√© cumul√©e √† 2.

``` r
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

prob_between <- c(-1, 2)

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data.frame(x, y), aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

``` r
prob_norm_between <- pnorm(q = prob_between[2], mean = 0, sd = 1) - pnorm(q = prob_between[1], mean = 0, sd = 1)
print(paste("La probabilit√© d'obtenir un nombre entre", 
            prob_between[1], "et", 
            prob_between[2], "est d'environ", 
            round(prob_norm_between, 2) * 100, "%"))
```

    ## [1] "La probabilit√© d'obtenir un nombre entre -1 et 2 est d'environ 82 %"

La courbe normale peut √™tre utile pour √©valuer la distribution d‚Äôune
population. Par exemple, on peut calculer les limites de r√©gion sur la
courbe normale qui contient 95% des valeurs possibles en tranchant 2.5%
de part et d‚Äôautre de la moyenne. Il s‚Äôagit ainsi de l‚Äôintervalle de
confiance sur la d√©viation de la distribution.

``` r
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

alpha <- 0.05
prob_between <- c(qnorm(p = alpha/2, mean = 0, sd = 1),
                  qnorm(p = 1 - alpha/2, mean = 0, sd = 1))

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line() +
  geom_text(data = data.frame(x = prob_between,
                              y = c(0, 0),
                              labels = round(prob_between, 2)),
            mapping = aes(label = labels))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->

On pourrait aussi √™tre int√©ress√© √† l‚Äôintervalle de confiance sur la
moyenne. En effet, la moyenne suit aussi une distribution normale, dont
la tendance centrale est la moyenne de la distribution, et dont
l‚Äô√©cart-type est not√© *erreur standard*. On calcule cette erreur en
divisant la variance par le nombre d‚Äôobservation, ou en divisant
l‚Äô√©cart-type par la racine carr√©e du nombre d‚Äôobservations. Ainsi,
pour 10 √©chantillons:

``` r
increment <- 0.01
x <- seq(-5, 5, by = increment)
y <- dnorm(x, mean = 0, sd = 1)

alpha <- 0.05
prob_between <- c(qnorm(p = alpha/2, mean = 0, sd = 1) / sqrt(10),
                  qnorm(p = 1 - alpha/2, mean = 0, sd = 1) / sqrt(10))

gg_norm <- data.frame(x, y)
gg_auc <- gg_norm %>%
  filter(x > prob_between[1], x < prob_between[2]) %>%
  rbind(c(prob_between[2], 0)) %>%
  rbind(c(prob_between[1], 0))

ggplot(data = data.frame(x, y), mapping = aes(x, y)) +
  geom_polygon(data = gg_auc, fill = '#71ad50') + # #71ad50 est un code de couleur format hexad√©cimal
  geom_line() +
  geom_text(data = data.frame(x = prob_between,
                              y = c(0, 0),
                              labels = round(prob_between, 2)),
            mapping = aes(label = labels))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-8-1.png)<!-- -->

# Statistiques descriptives

On a vu comment g√©n√©rer des statistiques sommaires en R avec la fonction
`summary()`. Reprenons les donn√©es d‚Äôiris.

``` r
data("iris")
summary(iris)
```

    ##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
    ##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
    ##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
    ##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
    ##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
    ##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
    ##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
    ##        Species  
    ##  setosa    :50  
    ##  versicolor:50  
    ##  virginica :50  
    ##                 
    ##                 
    ## 

Pour pr√©cis√©ment effectuer une moyenne et un √©cart-type sur un vecteur,
passons par les fonctions `mean()` et `sd()`.

``` r
mean(iris$Sepal.Length)
```

    ## [1] 5.843333

``` r
sd(iris$Sepal.Length)
```

    ## [1] 0.8280661

Pour effectuer un sommaire de tableau pilot√© par une fonction, nous
passons par la gamme de fonctions `summarise()`, de dplyr. Dans ce cas,
avec `group_by()`, nous fragmentons le tableau par esp√®ce pour effectuer
un sommaire sur toutes les variables.

``` r
iris %>%
  group_by(Species) %>%
  summarise_all(mean)
```

    ## # A tibble: 3 x 5
    ##   Species    Sepal.Length Sepal.Width Petal.Length Petal.Width
    ##   <fct>             <dbl>       <dbl>        <dbl>       <dbl>
    ## 1 setosa             5.01        3.43         1.46       0.246
    ## 2 versicolor         5.94        2.77         4.26       1.33 
    ## 3 virginica          6.59        2.97         5.55       2.03

Vous pourriez √™tre int√©ress√© par les quartiles √† 25, 50 et 75%. Mais la
fonction `summarise()` n‚Äôautorise que les fonctions dont la sortie est
d‚Äôun seul objet, alors faisons sorte que l‚Äôobjet soit une liste -
lorsque l‚Äôon imbrique une fonction `funs`, le tableau √† ins√©rer dans la
fonction est indiqu√© par un `.`.

``` r
iris %>%
  group_by(Species) %>%
  summarise_all(funs(list(quantile(.))))
```

    ## # A tibble: 3 x 5
    ##   Species    Sepal.Length Sepal.Width Petal.Length Petal.Width
    ##   <fct>      <list>       <list>      <list>       <list>     
    ## 1 setosa     <dbl [5]>    <dbl [5]>   <dbl [5]>    <dbl [5]>  
    ## 2 versicolor <dbl [5]>    <dbl [5]>   <dbl [5]>    <dbl [5]>  
    ## 3 virginica  <dbl [5]>    <dbl [5]>   <dbl [5]>    <dbl [5]>

En mode programmation classique de R, on pourra g√©n√©rer les quartiles √†
la pi√®ce.

``` r
quantile(iris$Sepal.Length[iris$Species == 'setosa'])
```

    ##   0%  25%  50%  75% 100% 
    ##  4.3  4.8  5.0  5.2  5.8

``` r
quantile(iris$Sepal.Length[iris$Species == 'versicolor'])
```

    ##   0%  25%  50%  75% 100% 
    ##  4.9  5.6  5.9  6.3  7.0

``` r
quantile(iris$Sepal.Length[iris$Species == 'virginica'])
```

    ##    0%   25%   50%   75%  100% 
    ## 4.900 6.225 6.500 6.900 7.900

La fonction `table()` permettra d‚Äôobtenir des d√©comptes par cat√©gorie,
ici par plages de longueurs de s√©pales. Pour obtenir les proportions du
nombre total, il s‚Äôagit d‚Äôencapsuler le tableau crois√© dans la fonction
`prop.table()`.

``` r
tableau_croise <- table(iris$Species, 
                        cut(iris$Sepal.Length, breaks = quantile(iris$Sepal.Length)))
tableau_croise
```

    ##             
    ##              (4.3,5.1] (5.1,5.8] (5.8,6.4] (6.4,7.9]
    ##   setosa            35        14         0         0
    ##   versicolor         4        20        17         9
    ##   virginica          1         5        18        26

``` r
prop.table(tableau_croise)
```

    ##             
    ##                (4.3,5.1]   (5.1,5.8]   (5.8,6.4]   (6.4,7.9]
    ##   setosa     0.234899329 0.093959732 0.000000000 0.000000000
    ##   versicolor 0.026845638 0.134228188 0.114093960 0.060402685
    ##   virginica  0.006711409 0.033557047 0.120805369 0.174496644

# Tests d‚Äôhypoth√®ses √† un et deux √©chantillons

Un test d‚Äôhypoth√®se permet de d√©cider si une hypoth√®se est confirm√©e ou
rejet√©e √† un seuil de probabilit√© pr√©d√©termin√©.

Cette section est inspir√©e du chapitre 5 de
[Dalgaard, 2008](https://www.springer.com/us/book/9780387790534).

-----

### Information: l‚Äôhypoth√®se nulle

Les tests d‚Äôhypoth√®se √©value des *effets* statistiques (qui ne sont pas
n√©cessairement des effets de causalit√©). L‚Äôeffet √† √©valuer peut √™tre
celui d‚Äôun traitement, d‚Äôindicateurs m√©t√©orologiques
(e.g.¬†pr√©cipitations totales, degr√©-jour, etc.), de techniques de
gestion des paysages, etc. Une recherche est men√©e pour √©valuer
l‚Äôhypoth√®se que l‚Äôon retrouve des diff√©rences entre des unit√©s
exp√©rimentales. Par convention, l‚Äô**hypoth√®se nulle** (√©crite \(H_0\))
est l‚Äôhypoth√®se qu‚Äôil n‚Äôy ait pas d‚Äôeffet (c‚Äôest l‚Äôhypoth√®se de l‚Äôavocat
du diable üòà) √† l‚Äô√©chelle de la population (et non pas √† l‚Äô√©chelle de
l‚Äô√©chantillon). √Ä l‚Äôinverse, l‚Äô**hypoth√®se alternative** (√©crite
\(H_1\)) est l‚Äôhypoth√®se qu‚Äôil y ait un effet √† l‚Äô√©chelle de la
population.

-----

√Ä titre d‚Äôexercice en stats, on d√©bute souvent par en testant si deux
vecteurs de valeurs continues proviennent de populations √† moyennes
diff√©rentes ou si un vecteur de valeurs a √©t√© g√©n√©r√© √† partir d‚Äôune
population ayant une moyenne donner. Dans cette section, nous
utiliserons la fonction `t.test()` pour les tests de t et la fonction
`wilcox.test()` pour les tests de Wilcoxon (aussi appel√© de
Mann-Whitney).

## Test de t √† un seul √©chantillon

Nous devons assumer, pour ce test, que l‚Äô√©chantillon est recueillit
d‚Äôune population dont la distribution est normale,
\(\mathcal{N} \sim \left( \mu, \sigma^2 \right)\), et que chaque
√©chantillon est ind√©pendant l‚Äôun de l‚Äôautre. L‚Äôhypoth√®se nulle est
souvent celle de l‚Äôavocat du diable, c‚Äôest-√†-dire: ici, que
\(\mu = \bar{x}\). L‚Äôerreur standard sur la moyenne (ESM) de
l‚Äô√©chantillon, \(\bar{x}\) est calcul√©e comme suit.

\[ESM = \frac{s}{\sqrt{n}}\]

o√π \(s\) est l‚Äô√©cart-type de l‚Äô√©chantillon et \(n\) est le nombre
d‚Äô√©chantillons.

Pour tester l‚Äôintervalle de confiance de l‚Äô√©chantillon, on mutliplie
l‚ÄôESM par l‚Äôaire sous la courbe de densit√© couvrant une certaine
proportion de part et d‚Äôautre de l‚Äô√©chantillon. Pour un niveau de
confiance de 95%, on retranche 2.5% de part et d‚Äôautre.

``` r
set.seed(33746)
x <- rnorm(20, 16, 4)

level <-  0.95
alpha <- 1-level

x_bar <- mean(x)
s <- sd(x)
n <- length(x)

error <- qnorm(1 - alpha/2) * s / sqrt(n)
error
```

    ## [1] 1.483253

L‚Äôinterval de confiance est l‚Äôerreur de par et d‚Äôautre de la moyenne.

``` r
c(x_bar - error, x_bar + error)
```

    ## [1] 14.35630 17.32281

Si la moyenne de la population est de 16, un nombre qui se situe dans
l‚Äôintervalle de confiance on accepte l‚Äôhypoth√®se nulle au seuil 0.05.
Si le nombre d‚Äô√©chantillon est r√©duit (g√©n√©ralement \< 30), on passera
plut√¥t par une distribution de t, avec \(n-1\) degr√©s de libert√©.

``` r
error <- qt(1 - alpha/2, n-1) * s / sqrt(n)
c(x_bar - error, x_bar + error)
```

    ## [1] 14.25561 17.42351

Plus simplement, on pourra utiliser la fonction `t.test()` en sp√©cifiant
la moyenne de la population. Nous avons g√©n√©r√© 20 donn√©es avec une
moyenne de 16 et un √©cart-type de 4. Nous savons donc que la vraie
moyenne de l‚Äô√©chantillon est de 16. Mais disons que nous testons
l‚Äôhypoth√®se que ces donn√©es sont tir√©es d‚Äôune population dont la
moyenne est 18 (et implicitement que sont √©cart-type est de 4).

``` r
t.test(x, mu = 18)
```

    ## 
    ##  One Sample t-test
    ## 
    ## data:  x
    ## t = -2.8548, df = 19, p-value = 0.01014
    ## alternative hypothesis: true mean is not equal to 18
    ## 95 percent confidence interval:
    ##  14.25561 17.42351
    ## sample estimates:
    ## mean of x 
    ##  15.83956

La fonction retourne la valeur de t (*t-value*), le nombre de degr√©s de
libert√© (\(n-1 = 19\)), une description de l‚Äôhypoth√®se alternative
(`alternative hypothesis: true mean is not equal to 18`), ainsi que
l‚Äôintervalle de confiance au niveau de 95%. Le test contient aussi la
*p-value*. Bien que la *p-value* soit largement utilis√©e en science

-----

### Information: la *p-value*

La *p-value*, ou valeur-p ou p-valeur, est utilis√©e pour trancher si,
oui ou non, un r√©sultat est **significatif** (en langage scientifique,
le mot significatif ne devrait √™tre utilis√© *que* lorsque l‚Äôon r√©f√®re √†
un test d‚Äôhypoth√®se statistique). Vous retrouverez des *p-value* partout
en stats. Les *p-values* indiquent la confiance que l‚Äôhypoth√®se nulle
soit vraie, selon les donn√©es et le mod√®le statistique utilis√©es.

> La p-value est la probabilit√© que les donn√©es aient √©t√© g√©n√©r√©es pour
> obtenir un effet √©quivalent ou plus prononc√© si l‚Äôhypoth√®se nulle est
> vraie.

Une *p-value* √©lev√©e indique que le mod√®le appliqu√© √† vos donn√©es
concordent avec la conclusion que l‚Äôhypoth√®se nulle est vraie, et
inversement si la *p-value* est faible. Le seuil arbitraire utilis√©e en
√©cologie et en agriculture, comme dans plusieurs domaines, est 0.05.

Les six principes de l‚Äô[American Statistical
Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html)
guident l‚Äôinterpr√©tation des *p-values*. \[ma traduction\]

0.  Les *p-values* indique l‚Äôampleur de l‚Äôincompatibiilt√© des donn√©es
    avec le mod√®le statistique
1.  Les *p-values* nemesurent pas la probabilit√© que l‚Äôhypoth√®se √©tudi√©e
    soit vraie, ni la probabilit√© que les donn√©es ont √©t√© g√©n√©r√©es
    uniquement par la chance.
2.  Les conclusions scientifiques et d√©cisions d‚Äôaffaire ou politiques
    ne devraient pas √™tre bas√©es sur si une *p-value* atteint un seuil
    sp√©cifique.
3.  Une inf√©rence appropri√©e demande un rapport complet et transparent.
4.  Une *p-value*, ou une signification statistique, ne mesure pas
    l‚Äôampleur d‚Äôun effet ou l‚Äôimportance d‚Äôun r√©sultat.
5.  En tant que tel, une *p-value* n‚Äôoffre pas une bonne mesure des
    √©vidences d‚Äôun mod√®le ou d‚Äôune hypoth√®se.

Cet encadr√© est inspir√© d‚Äôun [billet de blogue de Jim
Frost](https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values)
et d‚Äôun [rapport de l‚ÄôAmerican Statistical
Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html).

-----

Dans le cas pr√©c√©dent, la *p-value* √©tait de 0.01014. Pour aider notre
interpr√©tation, prenons l‚Äôhypoth√®se alternative: `true mean is not equal
to 18`. L‚Äôhypoth√®se nulle √©tait bien que *la vraie moyenne est √©gale √†
18*. Ins√©rons la *p-value* dans la d√©finition: la probabilit√© que les
donn√©es aient √©t√© g√©n√©r√©es pour obtenir un effet √©quivalent ou plus
prononc√© si l‚Äôhypoth√®se nulle est vraie est de 0.01014. Il est donc tr√®s
peu probable que les donn√©es soient tir√©es d‚Äôun √©chantillon dont la
moyenne est de 18. Au seuil de significativit√© de 0.05, on rejette
l‚Äôhypoth√®se nulle et l‚Äôon conclu qu‚Äô√† ce seuil de confiance,
l‚Äô√©chantillon ne provient pas d‚Äôune population ayant une moyenne de
18.

-----

## Attention: mauvaises interpr√©tations des *p-values*

> ‚ÄúLa p-value n‚Äôa jamais √©t√© con√ßue comme substitut au raisonnement
> scientifique‚Äù [Ron Wasserstein, directeur de l‚ÄôAmerican Statistical
> Association](https://phys.org/news/2016-03-american-statistical-association-statement-significance.html)
> \[ma traduction\].

**Un r√©sultat montrant une p-value plus √©lev√©e que 0.05 est-il
pertinent?**

Lors d‚Äôune conf√©rence, Dr Evil ne pr√©sentent que les r√©sultats
significatifs de ses essais au seuil de 0.05. Certains essais ne sont
pas significatifs, mais bon, ceux-ci ne sont pas importants‚Ä¶ En √©cartant
ces r√©sultats, Dr Evil commet 3 erreurs:

1.  La *p-value* n‚Äôest pas un bon indicateur de l‚Äôimportance d‚Äôun test
    statistique. L‚Äôimportance d‚Äôune variable dans un mod√®le devrait √™tre
    √©valu√©e par la valeur de son coefficient. Son incertitude devrait
    √™tre √©valu√©e par sa variance. Une mani√®re d‚Äô√©valuer plus intuitive
    la variance est l‚Äô√©cart-type ou l‚Äôintervalle de confiance. √Ä un
    certain seuil d‚Äôintervalle de confiance, la p-value traduira la
    probabilit√© qu‚Äôun coefficient soit r√©ellement nul ait pu g√©n√©rer des
    donn√©es d√©montrant un coefficient √©gal ou sup√©rieur.
2.  Il est tout aussi important de savoir que le traitement fonctionne
    que de savoir qu‚Äôil ne fonctionne pas. Les r√©sultats d√©montrant des
    effets sont malheureusement davantage soumis aux journaux et
    davantage publi√©s que ceux ne d√©montrant pas d‚Äôeffets ([Decullier et
    al., 2005](https://doi.org/10.1136/bmj.38488.385995.8F)).
3.  Le seuil de 0.05 est arbitraire.

-----

-----

### Attention au *p-hacking*

Le *p-hacking* (ou *data dredging*) consiste √† manipuler les donn√©es et
les mod√®les pour faire en sorte d‚Äôobtenir des *p-values* favorables √†
l‚Äôhypoth√®se test√©e et, √©ventuellement, aux conclusions recherch√©es.
**√Ä √©viter dans tous les cas. Toujours. Toujours. Toujours.**

Vid√©o sugg√©r√©e (en anglais).

[![p-hacking](images/05_p-hacking.png)](https://youtu.be/0Rnq1NpHdmw)

-----

## Test de Wilcoxon √† un seul √©chantillon

Le test de t suppose que la distribution des donn√©es est normale‚Ä¶ ce qui
est rarement le cas, surtout lorsque les √©chantillons sont peu nombreux.
Le test de Wilcoxon ne demande aucune supposition sur la distribution:
c‚Äôest un test non-param√©trique bas√© sur le tri des valeurs.

``` r
wilcox.test(x, mu = 18)
```

    ## 
    ##  Wilcoxon signed rank test
    ## 
    ## data:  x
    ## V = 39, p-value = 0.01208
    ## alternative hypothesis: true location is not equal to 18

Le `V` est la somme des rangs positifs. Dans ce cas, la *p-value* est
semblable √† celle du test de t, et les m√™mes conclusions s‚Äôappliquent.

## Tests de t √† deux √©chantillons

Les tests √† un √©chantillon servent plut√¥t √† s‚Äôexercer: rarement en
aura-t-on besoin en recherche, o√π plus souvent, on voudra comparer les
moyennes de deux unit√©s exp√©rimentales. L‚Äôexp√©rience comprend donc deux
s√©ries de donn√©es continues, \(x_1\) et \(x_2\), issus de lois de
distribution normale \(\mathcal{N} \left( \mu_1, \sigma_1^2 \right)\) et
\(\mathcal{N} \left( \mu_2, \sigma_2^2 \right)\), et nous testons
l‚Äôhypoth√®se nulle que \(\mu_1 = \mu_2\). La statistique t est calcul√©e
comme suit.

\[t = \frac{\bar{x_1} - \bar{x_2}}{ESDM}\]

L‚ÄôESDM est l‚Äôerreur standard de la diff√©rence des moyennes:

\[ESDM = \sqrt{ESM_1^2 + ESM_2^2}\]

Si vous supposez que les variances sont identiques, l‚Äôerreur standard
(s) est calcul√©e pour les √©chantillons des deux groupes, puis ins√©r√©e
dans le calcul des ESM. La statistique t sera alors √©valu√©e √†
\(n_1 + n_2 - 2\) degr√©s de lbert√©. Si vous supposez que la variance est
diff√©rente (*proc√©dure de Welch*), vous calculez les ESM avec les
erreurs standards respectives, et la statistique t devient une
approximation de la distribution de t avec un nombre de degr√©s de
libert√© calcul√© √† partir des erreurs standards et du nombre
d‚Äô√©chantillon dans les groupes: cette proc√©dure est consid√©r√©e comme
plus prudente
([Dalgaard, 2008](https://www.springer.com/us/book/9780387790534), page
101).

Prenons les donn√©es d‚Äôiris pour l‚Äôexemple en excluant l‚Äôiris setosa
√©tant donn√©e que les tests de t se restreignent √† deux groupes. Nous
allons tester la longueur des p√©tales.

``` r
iris_pl <- iris %>% 
    filter(Species != "setosa") %>%
    select(Species, Petal.Length)
sample_n(iris_pl, 5)
```

    ##       Species Petal.Length
    ## 98  virginica          5.2
    ## 55  virginica          5.8
    ## 92  virginica          5.1
    ## 13 versicolor          4.0
    ## 46 versicolor          4.2

Dans la prochaine cellule, nous introduisons l‚Äô*interface-formule* de R,
o√π l‚Äôon retrouve typiquement le `~`, entre les variables de sortie √†
gauche et les variables d‚Äôentr√©e √† droite. Dans notre cas, la variable
de sortie est la variable test√©e, `Petal.Length`, qui varie en fonction
du groupe `Species`, qui est la variable d‚Äôentr√©e (variable explicative)
- nous verrons les types de variables plus en d√©tails dans la section
[Les mod√®les statistiques](#Les-mod%C3%A8les-statistiques), plus bas.

``` r
t.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = FALSE)
```

    ## 
    ##  Welch Two Sample t-test
    ## 
    ## data:  Petal.Length by Species
    ## t = -12.604, df = 95.57, p-value < 2.2e-16
    ## alternative hypothesis: true difference in means is not equal to 0
    ## 95 percent confidence interval:
    ##  -1.49549 -1.08851
    ## sample estimates:
    ## mean in group versicolor  mean in group virginica 
    ##                    4.260                    5.552

Nous obtenons une sortie similaire aux pr√©c√©dentes. L‚Äôintervalle de
confiance √† 95% exclu le z√©ro, ce qui est coh√©rent avec la p-value tr√®s
faible, qui nous indique le rejet de l‚Äôhypoth√®se nulle au seuil 0.05.
Les groupes ont donc des moyennes de longueurs de p√©tale
significativement diff√©rentes.

-----

### Enregistrer les r√©sultats d‚Äôun test

Il est possible d‚Äôenregistrer un test dans un objet.

``` r
tt_pl <- t.test(formula = Petal.Length ~ Species,
                data = iris_pl, var.equal = FALSE)
summary(tt_pl)
```

    ##             Length Class  Mode     
    ## statistic   1      -none- numeric  
    ## parameter   1      -none- numeric  
    ## p.value     1      -none- numeric  
    ## conf.int    2      -none- numeric  
    ## estimate    2      -none- numeric  
    ## null.value  1      -none- numeric  
    ## alternative 1      -none- character
    ## method      1      -none- character
    ## data.name   1      -none- character

``` r
str(tt_pl)
```

    ## List of 9
    ##  $ statistic  : Named num -12.6
    ##   ..- attr(*, "names")= chr "t"
    ##  $ parameter  : Named num 95.6
    ##   ..- attr(*, "names")= chr "df"
    ##  $ p.value    : num 4.9e-22
    ##  $ conf.int   : atomic [1:2] -1.5 -1.09
    ##   ..- attr(*, "conf.level")= num 0.95
    ##  $ estimate   : Named num [1:2] 4.26 5.55
    ##   ..- attr(*, "names")= chr [1:2] "mean in group versicolor" "mean in group virginica"
    ##  $ null.value : Named num 0
    ##   ..- attr(*, "names")= chr "difference in means"
    ##  $ alternative: chr "two.sided"
    ##  $ method     : chr "Welch Two Sample t-test"
    ##  $ data.name  : chr "Petal.Length by Species"
    ##  - attr(*, "class")= chr "htest"

-----

## Comparaison des variances

Pour comparer les variances, on a recours au test de F (F pour Fisher).

``` r
var.test(formula = Petal.Length ~ Species,
         data = iris_pl)
```

    ## 
    ##  F test to compare two variances
    ## 
    ## data:  Petal.Length by Species
    ## F = 0.72497, num df = 49, denom df = 49, p-value = 0.2637
    ## alternative hypothesis: true ratio of variances is not equal to 1
    ## 95 percent confidence interval:
    ##  0.411402 1.277530
    ## sample estimates:
    ## ratio of variances 
    ##          0.7249678

Il semble que l‚Äôon pourrait relancer le test de t sans la proc√©dure
Welch, avec `var.equal = TRUE`.

## Tests de Wilcoxon √† deux √©chantillons

Cela ressemble au test de t\!

``` r
wilcox.test(formula = Petal.Length ~ Species,
       data = iris_pl, var.equal = TRUE)
```

    ## 
    ##  Wilcoxon rank sum test with continuity correction
    ## 
    ## data:  Petal.Length by Species
    ## W = 44.5, p-value < 2.2e-16
    ## alternative hypothesis: true location shift is not equal to 0

## Les tests pair√©s

Les tests pair√©s sont utilis√©s lorsque deux √©chantillons proviennent
d‚Äôune m√™me unit√© exp√©rimentale: il s‚Äôagit en fait de tests sur la
diff√©rences entre deux observations.

``` r
set.seed(2555)

n <- 20
avant <- rnorm(n, 16, 4)
apres <- rnorm(n, 18, 3)
```

Il est important de sp√©cifier que le test est pair√©, la valeur par
d√©faut de `paired` √©tant `FALSE`.

``` r
t.test(avant, apres, paired = TRUE)
```

    ## 
    ##  Paired t-test
    ## 
    ## data:  avant and apres
    ## t = -1.5168, df = 19, p-value = 0.1458
    ## alternative hypothesis: true difference in means is not equal to 0
    ## 95 percent confidence interval:
    ##  -4.5804586  0.7311427
    ## sample estimates:
    ## mean of the differences 
    ##               -1.924658

L‚Äôhypoth√®se nulle qu‚Äôil n‚Äôy ait pas de diff√©rence entre l‚Äôavant et
l‚Äôapr√®s traitement est accept√©e au seuil 0.05.

**Exercice**. Effectuer un test de Wilcoxon pair√©.

# L‚Äôanalyse de variance

L‚Äôanalyse de variance consiste √† comparer des moyennes de plusieurs
groupe distribu√©s normalement et de m√™me variance. Cetteb section sera
√©labor√©e prochainement plus en profondeur. Consid√©rons-la pour le
moment comme une r√©gression sur une variable cat√©gorielle.

``` r
pl_aov <- aov(Petal.Length ~ Species, iris)
summary(pl_aov)
```

    ##              Df Sum Sq Mean Sq F value Pr(>F)    
    ## Species       2  437.1  218.55    1180 <2e-16 ***
    ## Residuals   147   27.2    0.19                   
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

La prochaine section, justement, est vou√©e aux mod√®les statistiques
explicatifs, qui incluent la r√©gression.

# Les mod√®les statistiques

La mod√©lisation statistique consiste √† lier de mani√®re explicite des
variables de sortie \(y\) (ou variables-r√©ponse ou variables
d√©pendantes) √† des variables explicatives \(x\) (ou variables
pr√©dictives / ind√©pendantes / covariables). Les variables-r√©ponse sont
mod√©ls√©es par une fonction des variables explicatives ou pr√©dictives.

Pourquoi garder les termes *explicatives* et *pr√©dictives*? Parce que
les mod√®les statistiques (bas√©s sur des donn√©es et non pas sur des
m√©canismes) sont de deux ordres. D‚Äôabord, les mod√®les **pr√©dictifs**
sont con√ßus pour pr√©dire de mani√®re fiable une ou plusieurs
variables-r√©ponse √† partir des informations contenues dans les
variables qui sont, dans ce cas, pr√©dictives. Ces mod√®les sont couverts
dans le chapitre 11 de ce manuel (en d√©veloppement). Lorsque l‚Äôon d√©sire
tester des hypoth√®ses pour √©valuer quelles variables expliquent la
r√©ponse, on parlera de mod√©lisation (et de variables) **explicatives**.
En inf√©rence statistique, on √©valuera les *corr√©lations* entre les
variables explicatives et les variables-r√©ponse. Un lien de corr√©lation
n‚Äôest pas un lien de causalit√©. L‚Äôinf√©rence causale peut en revanche
√™tre √©valu√©e par des [*mod√®les d‚Äô√©quations
structurelles*](https://www.amazon.com/Cause-Correlation-Biology-Structural-Equations/dp/1107442591),
sujet qui fera √©ventuellement partie de ce cours.

Cette section couvre la mod√©lisation explicative. Les variables qui
contribuent √† cr√©er les mod√®les peuvent √™tre de diff√©rentes natures et
distribu√©es selon diff√©rentes lois de probabilit√©. Alors que les mod√®les
lin√©aires simples (*lm*) impliquent une variable-r√©ponse distribu√©e de
mani√®re continue, les mod√®les lin√©aires g√©n√©ralis√©s peuvent aussi
expliquer des variables de sorties discr√®tes.

Dans les deux cas, on distinguera les variables fixes et les variables
al√©atoires. Les **variables fixes** sont des les variables test√©es lors
de l‚Äôexp√©rience: dose du traitement, esp√®ce/cultivar, m√©t√©o, etc. Les
**variables al√©atoires** sont les sources de variation qui g√©n√®rent du
bruit dans le mod√®le: les unit√©s exp√©rimentales ou le temps lors de
mesures r√©p√©t√©es. Les mod√®les incluant des effets fixes seulement sont
des mod√®les √† effets fixes. G√©n√©ralement, les mod√®les incluant des
variables al√©atoires incluent aussi des variables fixes: on parlera
alors de mod√®les mixtes. Nous couvrirons ces deux types de mod√®le.

## Mod√®les √† effets fixes

Les tests de t et de Wilcoxon, explor√©s pr√©c√©demment, sont des mod√®les
statistiques √† une seule variable. Nous avons vu dans
l‚Äô*interface-formule* qu‚Äôune variable-r√©ponse peut √™tre li√©e √† une
variable explicative avec le tilde `~`. En particulier, le test de t est
r√©gression lin√©aire univari√©e (√† une seule variable explicative) dont la
variable explicative comprend deux cat√©gories. De m√™me, l‚Äôanova est une
r√©gression lin√©aire univari√©e dont la variable explicative comprend
plusieurs cat√©gories. Or l‚Äôinterface-formule peut √™tre utilis√© dans
plusieurs circonstance, notamment pour ajouter plusieurs variables de
diff√©rents types: on parlera de r√©gression multivari√©e.

La plupart des mod√®les statistiques peuvent √™tre approxim√©s comme une
combinaison lin√©aire de variables: ce sont des mod√®les lin√©aires. Les
mod√®les non-lin√©aires impliquent des strat√©gies computationnelles
complexes qui rendent leur utilisation plus difficile √† manoeuvrer.

Un mod√®le lin√©aire univari√© prendra la forme
\(y = \beta_0 + \beta_1 x + \epsilon\), o√π \(\beta_0\) est l‚Äôintercept
et \(\beta_1\) est la pente et \(\epsilon\) est l‚Äôerreur.

Vous verrez parfois la notation \(\hat{y} = \beta_0 + \beta_1 x\). La
notation avec le chapeau \(\hat{y}\) exprime qu‚Äôil s‚Äôagit des valeurs
g√©n√©r√©es par le mod√®le. En fait, \(y = \hat{y} - \epsilon\).

### Mod√®le lin√©aire univari√© avec variable continue

Prenons les donn√©es
[`lasrosas.corn`](https://rdrr.io/cran/agridat/man/lasrosas.corn.html)
incluses dans le module `agridat`, o√π l‚Äôon retrouve le rendement d‚Äôune
production de ma√Øs √† dose d‚Äôazote variable, en Argentine.

``` r
library("agridat")
```

    ## Warning: package 'agridat' was built under R version 3.4.4

``` r
data("lasrosas.corn")
sample_n(lasrosas.corn, 10)
```

    ##      year       lat      long  yield nitro topo     bv rep nf
    ## 2172 2001 -33.05109 -63.84451  94.15  50.6    E 173.54  R1 N2
    ## 3066 2001 -33.04908 -63.84830  90.19  99.8    W  91.74  R3 N4
    ## 949  1999 -33.05165 -63.84257  73.60   0.0   LO 173.23  R2 N0
    ## 1909 2001 -33.05175 -63.84320 108.95  75.4   LO 163.38  R1 N3
    ## 2173 2001 -33.05111 -63.84444 101.67  50.6    E 174.00  R1 N2
    ## 2770 2001 -33.05139 -63.84244  98.74  50.6   LO 167.86  R2 N2
    ## 1737 1999 -33.05121 -63.84224  81.70  29.0   LO 166.59  R3 N1
    ## 2261 2001 -33.05088 -63.84491  50.59  39.0    E 179.56  R1 N1
    ## 1501 1999 -33.05103 -63.84404  61.44   0.0    E 166.84  R3 N0
    ## 2149 2001 -33.05052 -63.84613  46.06  50.6   HT 178.54  R1 N2

Ces donn√©es comprennent plusieurs variables. Prenons le rendement
(`yield`) comme variable de sortie et, pour le moment, ne retenons que
la dose d‚Äôazote (`nitro`) comme variable explicative: il s‚Äôagit d‚Äôune
r√©gression univari√©e. Les deux variables sont continuent. Explorons
d‚Äôabord le nuage de points de l‚Äôune et l‚Äôautre.

``` r
ggplot(data = lasrosas.corn, mapping = aes(x = nitro, y = yield)) +
    geom_point()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-30-1.png)<!-- -->

L‚Äôhypoth√®se nulle est que la dose d‚Äôazote n‚Äôaffecte pas le rendement,
c‚Äôest √† dire que le coefficient de pente et nul. Une autre hypoth√®se
est que l‚Äôintercept est nul: donc qu‚Äô√† dose de 0, rendement de 0. Un
mod√®le lin√©aire √† variable de sortie continue est cr√©√© avec la fonction
`lm()`, pour *linear model*.

``` r
modlin_1 <- lm(yield ~ nitro, data = lasrosas.corn)
summary(modlin_1)
```

    ## 
    ## Call:
    ## lm(formula = yield ~ nitro, data = lasrosas.corn)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -53.183 -15.341  -3.079  13.725  45.897 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 65.843213   0.608573 108.193  < 2e-16 ***
    ## nitro        0.061717   0.007868   7.845 5.75e-15 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 19.66 on 3441 degrees of freedom
    ## Multiple R-squared:  0.01757,    Adjusted R-squared:  0.01728 
    ## F-statistic: 61.54 on 1 and 3441 DF,  p-value: 5.754e-15

Le diagnostic du mod√®le comprend plusieurs informations. D‚Äôabord la
formule utilis√©e, affich√©e pour la tracabilit√©. Viens ensuite un aper√ßu
de la distribution des r√©sidus. La m√©diane devrait s‚Äôapprocher de la
moyenne des r√©sidus (qui est toujours de 0). Bien que le -3.079 peut
sembler important, il faut prendre en consid√©ration de l‚Äô√©chelle de y,
et ce -3.079 est exprim√© en terme de rendement, ici en quintaux
(i.e.¬†100 kg) par hectare. La distribution des r√©sidus m√©rite d‚Äô√™tre
davantage investigu√©e. Nous verrons cela un peu plus tard.

Les coefficients apparaissent ensuite. Les estim√©s sont les valeurs des
effets. R fournit aussi l‚Äôerreur standard associ√©e, la valeur de t ainsi
que la p-value (la probabilit√© d‚Äôobtenir cet effet ou un effet plus
extr√™me si en r√©alit√© il y avait absence d‚Äôeffet). L‚Äôintercept est bien
s√ªr plus √©lev√© que 0 (√† dose nulle, on obtient 65.8 quintaux par hectare
en moyenne). La pente de la variable `nitro` est de \~0.06: pour chaque
augmentation d‚Äôun kg/ha de dose, on a obtenu \~0.06 quintaux/ha de plus
de ma√Øs. Donc pour 100 kg/ha de N, on a obtenu un rendement moyen de 6
quintaux de plus que l‚Äôintercept. Soulignons que l‚Äôampleur du
coefficient est tr√®s important pour guider la fertilisation: ne
rapporter que la p-value, ou ne rapporter que le fait qu‚Äôelle est
inf√©rieure √† 0.05 (ce qui arrive souvent dans la litt√©rature), serait
tr√®s insuffisant pour l‚Äôinterpr√©tation des statistiques. La p-value nous
indique n√©anmoins qu‚Äôil serait tr√®s improbable qu‚Äôune telle pente ait
√©t√© g√©n√©r√©e alors que celle-ci est nulle en r√©alit√©. Les √©toiles √†
c√¥t√© des p-values indiquent l‚Äôampleur selon l‚Äô√©chelle `Signif. codes`
indiqu√©e en-dessous du tableau des coefficients.

Sous ce tableau, R offre d‚Äôautres statistiques. En outre, les R¬≤ et R¬≤
ajust√©s indiquent si la r√©gression passe effectivement par les points.
Le R¬≤ prend un maximum de 1 lorsque la droite passe exactement sur les
points.

Enfin, le test de F g√©n√®re une p-value indiquant la probabilit√© que les
coefficients de pente ait √©t√© g√©n√©r√©s si les vrais coefficients √©taient
nuls. Dans le cas d‚Äôune r√©gression univari√©e, cela r√©p√®te l‚Äôinformation
sur l‚Äôunique coefficient.

On pourra √©galement obtenir les intervalles de confiance avec la
fonction `confint()`.

``` r
confint(modlin_1, level = 0.95)
```

    ##                   2.5 %      97.5 %
    ## (Intercept) 64.65001137 67.03641474
    ## nitro        0.04629164  0.07714271

Ou soutirer l‚Äôinformation de diff√©rentes mani√®res, comme avec la
fonction `coefficients()`.

``` r
coefficients(modlin_1)
```

    ## (Intercept)       nitro 
    ## 65.84321305  0.06171718

√âgalement, on pourra ex√©cuter le mod√®le sur les donn√©es qui ont servi √†
le g√©n√©rer:

``` r
predict(modlin_1)[1:5]
```

    ##        1        2        3        4        5 
    ## 73.95902 73.95902 73.95902 73.95902 73.95902

Ou sur des donn√©es externes.

``` r
nouvelles_donnees <- data.frame(nitro = seq(from = 0, to = 100, by = 5))
predict(modlin_1, newdata = nouvelles_donnees)[1:5]
```

    ##        1        2        3        4        5 
    ## 65.84321 66.15180 66.46038 66.76897 67.07756

### Analyse des r√©sidus

Les r√©sidus sont les erreurs du mod√®le. C‚Äôest le vecteur \(\epsilon\),
qui est un d√©lage entre les donn√©es et le mod√®le. Le R¬≤ est un
indicateur de l‚Äôampleur du d√©calage, mais une r√©gression lin√©aire
explicative en bonne et due forme devrait √™tre acompagn√©e d‚Äôune analyse
des r√©sidus. On peut les calcul√©s par \(\epsilon = y - \hat{y}\), mais
aussi bien utiliser la fonction `residuals()`.

``` r
res_df <- data.frame(nitro = lasrosas.corn$nitro,
                     residus_lm = residuals(modlin_1), 
                     residus_calcul = lasrosas.corn$yield - predict(modlin_1))
sample_n(res_df, 10)
```

    ##      nitro  residus_lm residus_calcul
    ## 124   66.0 -18.5165468    -18.5165468
    ## 691   66.0  -7.5965468     -7.5965468
    ## 459   53.0  -2.6342234     -2.6342234
    ## 2783  39.0  26.5998170     26.5998170
    ## 2519  99.8 -20.7825873    -20.7825873
    ## 954    0.0  -0.1132131     -0.1132131
    ## 2039   0.0 -16.9032131    -16.9032131
    ## 651  131.5   2.6109781      2.6109781
    ## 2856  39.0  36.5598170     36.5598170
    ## 128   66.0 -20.2665468    -20.2665468

Dans une bonne r√©gression lin√©aire, on ne retrouvera pas de structure
identifiable dans les r√©sidus, c‚Äôest-√†-dire que les r√©sidus sont bien
distribu√©s de part et d‚Äôautre du mod√®le de r√©gression.

``` r
ggplot(res_df, aes(x = nitro, y = residus_lm)) +
  geom_point() +
  labs(x = "Dose N", y = "Residus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```

![](05_biostats_files/figure-gfm/unnamed-chunk-37-1.png)<!-- -->

Bien que le jugement soit subjectif, on peut dire confiamment qu‚Äôil n‚Äôy
a pas structure particuli√®re. En revanche, on pourrait g√©n√©rer un \(y\)
qui varie de mani√®re quadratique avec \(x\), un mod√®le lin√©aire montrera
une structure √©vidente.

``` r
set.seed(36164)
x <- 0:100
y <- 10 + x*1 + x^2 * 0.05 + rnorm(length(x), 0, 50)
modlin_2 <- lm(y ~ x)
ggplot(data.frame(x, residus = residuals(modlin_2)),
       aes(x = x, y = residus)) +
  geom_point() +
  labs(x = "x", y = "Residus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```

![](05_biostats_files/figure-gfm/unnamed-chunk-38-1.png)<!-- -->

De m√™me, les r√©sidus ne devraient pas cro√Ætre avec \(x\).

``` r
set.seed(3984)
x <- 0:100
y <-  10 + x + x * rnorm(length(x), 0, 2)
modlin_3 <- lm(y ~ x)
ggplot(data.frame(x, residus = residuals(modlin_3)),
       aes(x = x, y = residus)) +
  geom_point() +
  labs(x = "x", y = "Residus") +
  geom_hline(yintercept = 0, col = "red", size = 1)
```

![](05_biostats_files/figure-gfm/unnamed-chunk-39-1.png)<!-- -->

On pourra aussi inspecter les r√©sidus avec un graphique de leur
distribution. Reprenons notre mod√®le de rendement du ma√Øs.

``` r
ggplot(res_df, aes(x = residus_lm)) +
  geom_histogram(binwidth = 2, color = "white") +
  labs(x = "Residual")
```

![](05_biostats_files/figure-gfm/unnamed-chunk-40-1.png)<!-- -->

L‚Äôhistogramme devrait pr√©senter une distribution normale. Les tests de
nomalit√© comme le test de Shapiro-Wilk peuvent aider, mais ils sont
g√©n√©ralement tr√®s s√©v√®res.

``` r
shapiro.test(res_df$residus_lm)
```

    ## 
    ##  Shapiro-Wilk normality test
    ## 
    ## data:  res_df$residus_lm
    ## W = 0.94868, p-value < 2.2e-16

L‚Äôhypoth√®se nulle que la distribution est normale est rejet√©e au seuil
0.05. Dans notre cas, il est √©vident que la s√©v√©rit√© du test n‚Äôest pas
en cause, car les r√©sidus semble g√©n√©rer trois ensembles. Ceci indique
que les variables explicatives sont insuffisantes pour expliquer la
variabilit√© de la variable-r√©ponse.

### R√©gression multiple

Comme c‚Äôest le cas pour bien des ph√©nom√®nes en √©cologie, le rendement
d‚Äôune culture n‚Äôest certainement pas expliqu√© seulement par la dose
d‚Äôazote.

Lorsque l‚Äôon combine plusieurs variables explicatives, on cr√©e un mod√®le
de r√©gression multivari√©e, ou une r√©gression multiple. Bien que les
tendances puissent sembl√©es non-lin√©aires, l‚Äôajout de variables et le
calcul des coefficients associ√©s reste un probl√®me d‚Äôalg√®bre lin√©aire.

On pourra en effet g√©n√©raliser les mod√®les lin√©aires, univari√©s et
multivari√©s, de la mani√®re suivante.

\[ y = X \beta + \epsilon \]

o√π:

\(X\) est la matrice du mod√®le √† \(n\) observations et \(p\) variables.

\[ X = \left( \begin{matrix} 
1 & x_{11} & \cdots & x_{1p}  \\ 
1 & x_{21} & \cdots & x_{2p}  \\ 
\vdots & \vdots & \ddots & \vdots  \\ 
1 & x_{n1} & \cdots & x_{np}
\end{matrix} \right) \]

\(\beta\) est la matrice des \(p\) coefficients, \(\beta_0\) √©tant
l‚Äôintercept qui multiplie la premi√®re colonne de la matrice \(X\).

\[ \beta = \left( \begin{matrix} 
\beta_0  \\ 
\beta_1  \\ 
\vdots \\ 
\beta_p 
\end{matrix} \right) \]

\(\epsilon\) est l‚Äôerreur de chaque observation.

\[ \epsilon = \left( \begin{matrix} 
\epsilon_0  \\ 
\epsilon_1  \\ 
\vdots \\ 
\epsilon_n
\end{matrix} \right) \]

### Mod√®les lin√©aires univari√©s avec variable cat√©gorielle **nominale**

Une variable cat√©gorielle nominale (non ordonn√©e) utilis√©e √† elle seule
dans un mod√®le comme variable explicative, est un cas particulier de
r√©gression multiple. En effet, l‚Äô**encodage cat√©goriel** (ou
*dummyfication*) transforme une variable cat√©gorielle nominale en une
matrice de mod√®le comprenant une colonne d√©signant l‚Äôintercept (une
s√©rie de 1) d√©signant la cat√©gorie de r√©f√©rence, ainsi que des colonnes
pour chacune des autres cat√©gories d√©signant l‚Äôappartenance (1) ou la
non appartenance (0) de la cat√©gorie d√©sign√©e par la colonne.

#### L‚Äôencodage cat√©goriel

Une variable √† \(C\) cat√©gories pourra √™tre d√©clin√©e en \(C\) variables
dont chaque colonne d√©signe par un 1 l‚Äôappartenance au groupe de la
colonne et par un 0 la non-appartenance. Pour l‚Äôexemple, cr√©ons un
vecteur d√©signant le cultivar de pomme de
terre.

``` r
data <- data.frame(cultivar = c('Superior', 'Superior', 'Superior', 'Russet', 'Kenebec', 'Russet'))
model.matrix(~cultivar, data)
```

    ##   (Intercept) cultivarRusset cultivarSuperior
    ## 1           1              0                1
    ## 2           1              0                1
    ## 3           1              0                1
    ## 4           1              1                0
    ## 5           1              0                0
    ## 6           1              1                0
    ## attr(,"assign")
    ## [1] 0 1 1
    ## attr(,"contrasts")
    ## attr(,"contrasts")$cultivar
    ## [1] "contr.treatment"

Nous avons trois cat√©gories, encod√©es en trois colonnes. La premi√®re
colonne est un intercept et les deux autres d√©crivent l‚Äôabsence (0) ou
la pr√©sence (1) des cultivars Russet et Superior. Le cultivar Kenebec
est absent du tableau. En effet, en partant du principe que
l‚Äôappartenance √† une cat√©gorie est mutuellement exclusive,
c‚Äôest-√†-dire qu‚Äôun √©chantillon ne peut √™tre assign√© qu‚Äô√† une seule
cat√©gorie, on peut d√©duire une cat√©gorie √† partir de l‚Äôinformation sur
toutes les autres. Par exemple, si `cultivar_Russet` et
`cultivar_Superior` sont toutes deux √©gales √† \(0\), on concluera que
`cultivar_Kenebec` est n√©cessairement √©gal √† \(1\). Et si l‚Äôun d‚Äôentre
`cultivar_Russet` et `cultivar_Superior` est √©gal √† \(1\),
`cultivar_Kenebec` est n√©cessairement √©gal √† \(0\). L‚Äôinformation
contenue dans un nombre \(C\) de cat√©gorie peut √™tre encod√©e dans un
nombre \(C-1\) de colonnes. C‚Äôest pourquoi, dans une analyse
statistique, on d√©signera une cat√©gorie comme une r√©f√©rence, que l‚Äôon
d√©tecte lorsque toutes les autres cat√©gories sont encod√©es avec des
\(0\): cette r√©f√©rence sera incluse dans l‚Äôintercept. La cat√©gorie de
r√©f√©rence par d√©faut en R est celle la premi√®re cat√©gorie dans l‚Äôordre
aphab√©tique. On pourra modifier cette r√©f√©rence avec la fonction
`relevel()`.

``` r
data$cultivar <- relevel(data$cultivar, ref = "Superior")
model.matrix(~cultivar, data)
```

    ##   (Intercept) cultivarKenebec cultivarRusset
    ## 1           1               0              0
    ## 2           1               0              0
    ## 3           1               0              0
    ## 4           1               0              1
    ## 5           1               1              0
    ## 6           1               0              1
    ## attr(,"assign")
    ## [1] 0 1 1
    ## attr(,"contrasts")
    ## attr(,"contrasts")$cultivar
    ## [1] "contr.treatment"

Pour certains mod√®les, vous devrez vous assurer vous-m√™me de l‚Äôencodage
cat√©goriel. Pour d‚Äôautre, en particulier avec l‚Äô*interface par formule*
de R, ce sera fait automatiquement.

#### Exemple d‚Äôapplication

Prenons la topographie du terrain, qui peut prendre plusieurs niveaux.

``` r
levels(lasrosas.corn$topo)
```

    ## [1] "E"  "HT" "LO" "W"

Explorons le rendement selon la topographie.

``` r
ggplot(lasrosas.corn, aes(x = topo, y = yield)) +
    geom_boxplot()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-45-1.png)<!-- -->

Les diff√©rences sont √©videntes, et la mod√©lisation devrait montrer des
effets significatifs.

L‚Äôencodage cat√©goriel peut √™tre visualis√© en g√©n√©rant la matrice de
mod√®le avec la fonction `model.matrix()` et l‚Äôinterface-formule - sans
la variable-r√©ponse.

``` r
model.matrix(~ topo, data = lasrosas.corn) %>% 
    tbl_df() %>% # tbl_df pour transformer la matrice en tableau
    sample_n(10) 
```

    ## # A tibble: 10 x 4
    ##    `(Intercept)` topoHT topoLO topoW
    ##            <dbl>  <dbl>  <dbl> <dbl>
    ##  1             1      0      1     0
    ##  2             1      0      0     1
    ##  3             1      0      0     0
    ##  4             1      0      0     1
    ##  5             1      0      0     1
    ##  6             1      0      0     1
    ##  7             1      0      0     0
    ##  8             1      0      0     0
    ##  9             1      1      0     0
    ## 10             1      0      0     1

Dans le cas d‚Äôun mod√®le avec une variable cat√©gorielle nominale seule,
l‚Äôintercept repr√©sente la cat√©gorie de r√©f√©rence, ici `E`. Les autres
colonnes sp√©cifient l‚Äôappartenance (1) ou la non-appartenance (0) de la
cat√©gorie pour chaque observation.

Cette matrice de mod√®le utilis√©e pour la r√©gression donnera un
intercept, qui indiquera l‚Äôeffet de la cat√©gorie de r√©f√©rence, puis les
diff√©rences entre les cat√©gories subs√©quentes et la cat√©gorie de
r√©f√©rence.

``` r
modlin_4 <- lm(yield ~ topo, data = lasrosas.corn)
summary(modlin_4)
```

    ## 
    ## Call:
    ## lm(formula = yield ~ topo, data = lasrosas.corn)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -47.371 -11.933  -1.593  11.080  44.119 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  78.6653     0.5399 145.707   <2e-16 ***
    ## topoHT      -30.0526     0.7500 -40.069   <2e-16 ***
    ## topoLO        6.2832     0.7293   8.615   <2e-16 ***
    ## topoW       -11.8841     0.7039 -16.883   <2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 14.59 on 3439 degrees of freedom
    ## Multiple R-squared:  0.4596, Adjusted R-squared:  0.4591 
    ## F-statistic:   975 on 3 and 3439 DF,  p-value: < 2.2e-16

Le mod√®le lin√©aire est √©quivalent √† l‚Äôanova, mais les r√©sultats de `lm`
sont plus √©labor√©s.

``` r
summary(aov(yield ~ topo, data = lasrosas.corn))
```

    ##               Df Sum Sq Mean Sq F value Pr(>F)    
    ## topo           3 622351  207450     975 <2e-16 ***
    ## Residuals   3439 731746     213                   
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

L‚Äôanalyse de r√©sidus peut √™tre effectu√©e de la m√™me mani√®re.

### Mod√®les lin√©aires univari√©s avec variable cat√©gorielle **ordinale**

Bien que j‚Äôintroduise la r√©gression sur variable cat√©gorielle ordinale √†
la suite de la section sur les variables nominales, nous revenons dans
ce cas √† une r√©rgession simple, univari√©e. Voyons un cas √† 5 niveaux.

``` r
statut <- c("Totalement en d√©saccort", 
            "En d√©saccord",
            "Ni en accord, ni en d√©saccord",
            "En accord",
            "Totalement en accord")
statut_o <- factor(statut, levels = statut, ordered=TRUE)
model.matrix(~statut_o) # ou bien, sans passer par model.matrix, contr.poly(5) o√π 5 est le nombre de niveaux
```

    ##   (Intercept) statut_o.L statut_o.Q    statut_o.C statut_o^4
    ## 1           1 -0.6324555  0.5345225 -3.162278e-01  0.1195229
    ## 2           1 -0.3162278 -0.2672612  6.324555e-01 -0.4780914
    ## 3           1  0.0000000 -0.5345225 -4.095972e-16  0.7171372
    ## 4           1  0.3162278 -0.2672612 -6.324555e-01 -0.4780914
    ## 5           1  0.6324555  0.5345225  3.162278e-01  0.1195229
    ## attr(,"assign")
    ## [1] 0 1 1 1 1
    ## attr(,"contrasts")
    ## attr(,"contrasts")$statut_o
    ## [1] "contr.poly"

La matrice de mod√®le a 5 colonnes, soit le nombre de niveaux: un
intercept, puis 4 autres d√©signant diff√©rentes valeurs que peuvent
prendre les niveaux. Ces niveaux croient-ils lin√©airement? De mani√®re
quadratique, cubique ou plus loin dans des distributions polynomiales?

``` r
modmat_tidy <- data.frame(statut, model.matrix(~statut_o)[, -1]) %>%
    gather(variable, valeur, -statut)
modmat_tidy$statut <- factor(modmat_tidy$statut, 
                             levels = statut, 
                             ordered=TRUE)
ggplot(data = modmat_tidy, mapping = aes(x = statut, y = valeur)) +
    facet_wrap(. ~ variable) +
    geom_point() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-50-1.png)<!-- -->

R√®gle g√©n√©rale, pour les variables ordinales, on pr√©f√©rera une
distribution lin√©aire, et c‚Äôest l‚Äôoption par d√©faut de la fonction
`lm()`. L‚Äôutilisation d‚Äôune autre distribution peut √™tre effectu√©e √† la
mitaine en utilisant dans le mod√®le la colonne d√©sir√©e de la sortie de
la fonction `model.matrix()`.

### R√©gression multiple √† plusieurs variables

Reprenons le tableau de donn√©es du rendement de ma√Øs.

``` r
head(lasrosas.corn)
```

    ##   year       lat      long yield nitro topo     bv rep nf
    ## 1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5
    ## 2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5
    ## 3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5
    ## 4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5
    ## 5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5
    ## 6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5

Pour ajouter des variables au mod√®le dans l‚Äôinterface-formule, on
additionne les noms de colonne. La variable `lat` d√©signe la latitude,
la variable `long` d√©signe la latitude et la variable `bv` (*brightness
value*) d√©signe la teneur en mati√®re organique du sol (plus `bv` est
√©lev√©e, plus faible est la teneur en mati√®re organique).

``` r
modlin_5 <- lm(yield ~ lat + long + nitro + topo + bv,
               data = lasrosas.corn)
summary(modlin_5)
```

    ## 
    ## Call:
    ## lm(formula = yield ~ lat + long + nitro + topo + bv, data = lasrosas.corn)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.405 -11.071  -1.251  10.592  40.078 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  1.946e+05  3.309e+04   5.882 4.45e-09 ***
    ## lat          5.541e+03  4.555e+02  12.163  < 2e-16 ***
    ## long         1.776e+02  4.491e+02   0.395    0.693    
    ## nitro        6.867e-02  5.451e-03  12.597  < 2e-16 ***
    ## topoHT      -2.665e+01  1.087e+00 -24.520  < 2e-16 ***
    ## topoLO       5.565e+00  1.035e+00   5.378 8.03e-08 ***
    ## topoW       -1.465e+01  1.655e+00  -8.849  < 2e-16 ***
    ## bv          -5.089e-01  3.069e-02 -16.578  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.47 on 3435 degrees of freedom
    ## Multiple R-squared:  0.5397, Adjusted R-squared:  0.5387 
    ## F-statistic: 575.3 on 7 and 3435 DF,  p-value: < 2.2e-16

L‚Äôampleur des coefficients est relatif √† l‚Äô√©chelle de la variable. En
effet, un coefficient de 5541 sur la variable `lat` n‚Äôest pas comparable
au coefficient de la variable `bv`, de -0.5089, √©tant donn√© que les
variables ne sont pas exprim√©es avec la m√™me √©chelle. Pour les comparer
sur une m√™me base, on peut centrer (soustraire la moyenne) et r√©durie
(diviser par
l‚Äô√©cart-type).

``` r
scale_vec <- function(x) as.vector(scale(x)) # la fonction scale g√©n√®re une matrice: nous d√©sirons un vecteur

lasrosas.corn_sc <- lasrosas.corn %>%
    mutate_at(c("lat", "long", "nitro", "bv"), 
                 scale_vec)

modlin_5_sc <- lm(yield ~ lat + long + nitro + topo + bv,
               data = lasrosas.corn_sc)
summary(modlin_5_sc)
```

    ## 
    ## Call:
    ## lm(formula = yield ~ lat + long + nitro + topo + bv, data = lasrosas.corn_sc)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -48.405 -11.071  -1.251  10.592  40.078 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)  78.9114     0.6666 118.376  < 2e-16 ***
    ## lat           3.9201     0.3223  12.163  < 2e-16 ***
    ## long          0.3479     0.8796   0.395    0.693    
    ## nitro         2.9252     0.2322  12.597  < 2e-16 ***
    ## topoHT      -26.6487     1.0868 -24.520  < 2e-16 ***
    ## topoLO        5.5647     1.0347   5.378 8.03e-08 ***
    ## topoW       -14.6487     1.6555  -8.849  < 2e-16 ***
    ## bv           -4.9253     0.2971 -16.578  < 2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 13.47 on 3435 degrees of freedom
    ## Multiple R-squared:  0.5397, Adjusted R-squared:  0.5387 
    ## F-statistic: 575.3 on 7 and 3435 DF,  p-value: < 2.2e-16

Typiquement, les variables cat√©gorielles, qui ne sont pas mises √†
l‚Äô√©chelle, donneront des coefficients plus √©lev√©es, et devrons √™tre
√©valu√©es entre elles et non comparativement aux variables mises √†
l‚Äô√©chelle. Une mani√®re conviviale de repr√©senter des coefficients
consiste √† cr√©er un tableau (fonction `tibble()`) incluant les
coefficients ainsi que leurs intervalles de confiance, puis √† les porter
graphiquement.

``` r
intervals <- tibble(Estimate = coefficients(modlin_5_sc)[-1], # [-1] enlever l'intercept
                    LL = confint(modlin_5_sc)[-1, 1], # [-1, ] enlever la premi√®re ligne, celle de l'intercept
                    UL = confint(modlin_5_sc)[-1, 2],
                    variable = names(coefficients(modlin_5_sc)[-1])) 
intervals
```

    ## # A tibble: 7 x 4
    ##   Estimate     LL     UL variable
    ##      <dbl>  <dbl>  <dbl> <chr>   
    ## 1    3.92    3.29   4.55 lat     
    ## 2    0.348  -1.38   2.07 long    
    ## 3    2.93    2.47   3.38 nitro   
    ## 4  -26.6   -28.8  -24.5  topoHT  
    ## 5    5.56    3.54   7.59 topoLO  
    ## 6  -14.6   -17.9  -11.4  topoW   
    ## 7   -4.93   -5.51  -4.34 bv

``` r
ggplot(data = intervals, mapping = aes(x = Estimate, y = variable)) +
    geom_vline(xintercept = 0, lty = 2) +
    geom_segment(mapping = aes(x = LL, xend = UL, 
                               y = variable, yend = variable)) +
    geom_point() +
    labs(x = "Coefficient standardis√©", y = "")
```

![](05_biostats_files/figure-gfm/unnamed-chunk-55-1.png)<!-- -->

On y voit qu‚Äô√† l‚Äôexception de la variable `long`, tous les coefficients
sont diff√©rents de 0. Le coefficient `bv` est n√©gatif, indicant que plus
la valeur de `bv` est √©lev√© (donc plus le sol est pauvre en mati√®re
organique), plus le rendement est faible. Plus la latitude est √©lev√©e
(plus on se dirige vers le Nord de l‚ÄôArgentine), plus le rendement est
√©lev√©. La dose d‚Äôazote a aussi un effet statistique positif sur le
rendement.

Quant aux cat√©gories topographiques, elles sont toutes diff√©rentes de la
cat√©gorie `E`, ne croisant pas le z√©ro. De plus, les intervalles de
confiance ne se chevauchant pas, on peut conclure en une diff√©rence
significative d‚Äôune √† l‚Äôautre. Bien s√ªr, tout cela au seuil de confiance
de 0.05.

On pourra retrouver des cas o√π l‚Äôeffet combin√© de plusieurs variables
diff√®re de l‚Äôeffet des deux variables prises s√©par√©ment. Par exemple, on
pourrait √©valuer l‚Äôeffet de l‚Äôazote et celui de la topographie dans un
m√™me mod√®le, puis y ajouter une int√©raction entre l‚Äôazote et la
topographie, qui d√©finira des effets suppl√©mentaires de l‚Äôazote selon
chaque cat√©gorie topographique. C‚Äôest ce que l‚Äôon appelle une
int√©raction.

Dans l‚Äôinterface-formule, l‚Äôint√©raction entre l‚Äôazote et la topographie
est not√©e `nitro:topo`. Pour ajouter cette int√©raction, la formule
deviendra `yield ~ nitro + topo + nitro:topo`. Une approche √©quivalente
est d‚Äôutiliser le raccourci `yield ~ nitro*topo`.

``` r
modlin_5_sc <- lm(yield ~ nitro*topo,
               data = lasrosas.corn_sc)
summary(modlin_5_sc)
```

    ## 
    ## Call:
    ## lm(formula = yield ~ nitro * topo, data = lasrosas.corn_sc)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -47.984 -11.985  -1.388  10.339  40.636 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)   78.6999     0.5322 147.870  < 2e-16 ***
    ## nitro          1.8131     0.5351   3.388 0.000711 ***
    ## topoHT       -30.0052     0.7394 -40.578  < 2e-16 ***
    ## topoLO         6.2026     0.7190   8.627  < 2e-16 ***
    ## topoW        -11.9628     0.6939 -17.240  < 2e-16 ***
    ## nitro:topoHT   1.2553     0.7461   1.682 0.092565 .  
    ## nitro:topoLO   0.5695     0.7186   0.792 0.428141    
    ## nitro:topoW    0.7702     0.6944   1.109 0.267460    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 14.38 on 3435 degrees of freedom
    ## Multiple R-squared:  0.4756, Adjusted R-squared:  0.4746 
    ## F-statistic: 445.1 on 7 and 3435 DF,  p-value: < 2.2e-16

Les r√©sultats montre des effets de l‚Äôazote et des cat√©gories
topographiques, mais il y a davantage d‚Äôincertitude sur les
int√©ractions, indiquant que l‚Äôeffet statistique de l‚Äôazote est
sensiblement le m√™me ind√©pendamment des niveaux topographiques.

-----

### Attention √† ne pas surcharger le mod√®le

Il est possible d‚Äôajouter des int√©ractions doubles, triples, quadruples,
etc. Mais plus il y a d‚Äôint√©ractions, plus votre mod√®le comprendra de
variables et vos tests d‚Äôhypoth√®se perdront en puissance statistique.

-----

### Les mod√®les lin√©aires g√©n√©ralis√©s

Dans un mod√®le lin√©aire ordinaire, un changement constant dans les
variables explicatives r√©sulte en un changement constant de la
variable-r√©ponse. Cette supposition ne serait pas ad√©quate si la
variable-r√©ponse √©tait un d√©compte, si elle est bool√©enne ou si, de
mani√®re g√©n√©rale, la variable-r√©ponse ne suivait pas une distribution
continue. Ou, de mani√®re plus sp√©cifique, il n‚Äôy a pas moyen de
retrouver une distribution normale des r√©sidus? On pourra bien s√ªr
transformer les variables (sujet du chapitre 6, en d√©veloppement). Mais
il pourrait s‚Äôav√©rer impossible, ou tout simplement non souhaitable de
transformer les variables. Le mod√®le lin√©aire g√©n√©ralis√© (MLG, ou
*generalized linear model* - GLM) est une g√©n√©ralisation du mod√®le
lin√©aire ordinaire chez qui la variable-r√©ponse peut √™tre caract√©ris√©
par une distribution de Poisson, de Bernouilli, etc.

Prenons d‚Äôabord cas d‚Äôun d√©compte de vers fil-de-fer (`worms`) retrouv√©s
dans des parcelles sous diff√©rents traitements (`trt`). Les d√©comptes
sont typiquement distribu√© selon une loi de
    Poisson.

``` r
cochran.wireworms %>% ggplot(aes(x = worms)) + geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

![](05_biostats_files/figure-gfm/unnamed-chunk-57-1.png)<!-- -->

Explorons les d√©comptes selon les traitements.

``` r
cochran.wireworms %>% ggplot(aes(x = trt, y = worms)) + geom_boxplot()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-58-1.png)<!-- -->

Les traitements semble √† premi√®re vue avoir un effet comparativement au
contr√¥le. Lan√ßons un MLG avec la fonction `glm()`, et sp√©cifions que la
sortie est une distribution de Poisson.

``` r
modglm_1 <- glm(worms ~ trt, cochran.wireworms, family = "poisson")
summary(modglm_1)
```

    ## 
    ## Call:
    ## glm(formula = worms ~ trt, family = "poisson", data = cochran.wireworms)
    ## 
    ## Deviance Residuals: 
    ##     Min       1Q   Median       3Q      Max  
    ## -1.8279  -0.9455  -0.2862   0.6916   3.1888  
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(>|z|)    
    ## (Intercept)   0.1823     0.4082   0.447 0.655160    
    ## trtM          1.6422     0.4460   3.682 0.000231 ***
    ## trtN          1.7636     0.4418   3.991 6.57e-05 ***
    ## trtO          1.5755     0.4485   3.513 0.000443 ***
    ## trtP          1.3437     0.4584   2.931 0.003375 ** 
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for poisson family taken to be 1)
    ## 
    ##     Null deviance: 64.555  on 24  degrees of freedom
    ## Residual deviance: 38.026  on 20  degrees of freedom
    ## AIC: 125.64
    ## 
    ## Number of Fisher Scoring iterations: 5

Il est tr√®s probable (p-value de \~0.66) qu‚Äôun intercept de 0.18 ayant
une erreur standard de 0.4082 ait √©t√© g√©n√©r√© depuis une population dont
l‚Äôintercept est nul: autrement dit, le contr√¥le n‚Äôa probablement pas eu
d‚Äôeffet. Quant aux autres traitements, leurs effets sont tous
significatifs au seuil 0.05, mais peuvent-ils √™tre consid√©r√©s comme
√©quivalents?

``` r
intervals <- tibble(Estimate = coefficients(modglm_1), # [-1] enlever l'intercept
                    LL = confint(modglm_1)[, 1], # [-1, ] enlever la premi√®re ligne, celle de l'intercept
                    UL = confint(modglm_1)[, 2],
                    variable = names(coefficients(modglm_1))) 
```

    ## Waiting for profiling to be done...
    ## Waiting for profiling to be done...

``` r
intervals
```

    ## # A tibble: 5 x 4
    ##   Estimate     LL    UL variable   
    ##      <dbl>  <dbl> <dbl> <chr>      
    ## 1    0.182 -0.740 0.888 (Intercept)
    ## 2    1.64   0.840 2.62  trtM       
    ## 3    1.76   0.972 2.74  trtN       
    ## 4    1.58   0.766 2.56  trtO       
    ## 5    1.34   0.509 2.34  trtP

``` r
ggplot(data = intervals, mapping = aes(x = Estimate, y = variable)) +
    geom_vline(xintercept = 0, lty = 2) +
    geom_segment(mapping = aes(x = LL, xend = UL, 
                               y = variable, yend = variable)) +
    geom_point() +
    labs(x = "Coefficient", y = "")
```

![](05_biostats_files/figure-gfm/unnamed-chunk-61-1.png)<!-- -->

Les intervales de confiance se superposant, on ne peut pas conclure
qu‚Äôun traitement est li√© √† une r√©duction plus importante de vers qu‚Äôun
autre, au seuil 0.05.

Maintenant, √† d√©faut de trouver un tableau de donn√©es plus appropri√©,
prenons le tableau `mtcars`, qui rassemble des donn√©es sur des mod√®les
de voitures. La colonne `vs`, pour v-shaped, inscrit 0 si les pistons
sont droit et 1 s‚Äôils sont plac√©s en V dans le moteur. Peut-on expliquer
la forme des pistons selon le poids du v√©hicule
    (`wt`)?

``` r
mtcars %>% sample_n(6)
```

    ##                    mpg cyl  disp  hp drat    wt  qsec vs am gear carb
    ## Merc 450SLC       15.2   8 275.8 180 3.07 3.780 18.00  0  0    3    3
    ## Mazda RX4         21.0   6 160.0 110 3.90 2.620 16.46  0  1    4    4
    ## Honda Civic       30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
    ## Chrysler Imperial 14.7   8 440.0 230 3.23 5.345 17.42  0  0    3    4
    ## Mazda RX4 Wag     21.0   6 160.0 110 3.90 2.875 17.02  0  1    4    4
    ## AMC Javelin       15.2   8 304.0 150 3.15 3.435 17.30  0  0    3    2

``` r
mtcars %>% 
    ggplot(aes(x = wt, y = vs)) + geom_point()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-63-1.png)<!-- -->

Il semble y avoir une tendance: les v√©hicules plus lourds ont plut√¥t des
pistons droits (`vs = 0`). V√©rifions cela.

``` r
modglm_2 <- glm(vs ~ wt, data = mtcars, family = binomial)
summary(modglm_2)
```

    ## 
    ## Call:
    ## glm(formula = vs ~ wt, family = binomial, data = mtcars)
    ## 
    ## Deviance Residuals: 
    ##     Min       1Q   Median       3Q      Max  
    ## -1.9003  -0.7641  -0.1559   0.7223   1.5736  
    ## 
    ## Coefficients:
    ##             Estimate Std. Error z value Pr(>|z|)   
    ## (Intercept)   5.7147     2.3014   2.483  0.01302 * 
    ## wt           -1.9105     0.7279  -2.625  0.00867 **
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## (Dispersion parameter for binomial family taken to be 1)
    ## 
    ##     Null deviance: 43.860  on 31  degrees of freedom
    ## Residual deviance: 31.367  on 30  degrees of freedom
    ## AIC: 35.367
    ## 
    ## Number of Fisher Scoring iterations: 5

**Exercice**. Analyser les r√©sultats.

### Les mod√®les non-lin√©aires

La hauteur d‚Äôun arbre en fonction du temps n‚Äôest typiquement pas
lin√©aire. Elle tend √† cro√Ætre de plus en plus lentement jusqu‚Äô√† un
plateau. De m√™me, le rendement d‚Äôune culture trait√© avec des doses
croissantes de fertilisants tend √† atteindre un maximum, puis √† se
stabiliser.

Ces ph√©nom√®nes ne peuvent pas √™tre approxim√©s par des mod√®les lin√©aires.
Examinons les donn√©es du tableau `engelstad.nitro`.

``` r
engelstad.nitro %>% sample_n(10)
```

    ##          loc year nitro yield
    ## 38 Knoxville 1963    67  73.2
    ## 40 Knoxville 1963   201  91.2
    ## 21   Jackson 1965   134  60.5
    ## 35 Knoxville 1962   268  78.4
    ## 22   Jackson 1965   201  70.2
    ## 12   Jackson 1963   335  87.0
    ## 24   Jackson 1965   335  73.0
    ## 20   Jackson 1965    67  47.6
    ## 15   Jackson 1964   134  55.2
    ## 48 Knoxville 1964   335  84.5

``` r
engelstad.nitro %>%
    ggplot(aes(x = nitro, y = yield)) +
        facet_grid(year ~ loc) +
        geom_line() +
        geom_point()
```

![](05_biostats_files/figure-gfm/unnamed-chunk-66-1.png)<!-- -->

Le mod√®le de Mitscherlich pourrait √™tre utilis√©.

\[ y = A \left( 1 - e^{-R \left( E + x \right)} \right) \]

o√π \(y\) est le rendement, \(x\) est la dose, \(A\) est l‚Äôasymptote vers
laquelle la courbe converge √† dose croissante, \(E\) est l‚Äô√©quivalent de
dose fourni par l‚Äôenvironnement et \(R\) est le taux de r√©ponse.

Explorons la fonction.

``` r
mitscherlich_f <- function(x, A, E, R) {
    A * (1 - exp(-R*(E + x)))
}

x <- seq(0, 350, by = 5)
y <- mitscherlich_f(x, A = 75, E = 30, R = 0.02)

ggplot(tibble(x, y), aes(x, y)) +
    geom_point(data = engelstad.nitro, aes(x = nitro, y = yield)) +
    geom_line() + ylim(c(0, 100))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-67-1.png)<!-- -->

**Exercice**. Changez les param√®tres pour visualiser comment la courbe
r√©agit.

Nous pouvons d√©crire le mod√®le gr√¢ce √† l‚Äôinterface formule dans la
fonction `nls()`. Notez que les mod√®les non-lin√©aires demandent des
strat√©gies de calcul diff√©rentes de celles des mod√®les lin√©aires. En
tout temps, nous devons identifier des valeurs de d√©part raisonnables
pour les param√®tres dans l‚Äôargument `start`. Vous r√©ussirez rarement √†
obtenir une convergence du premier coup avec vos param√®tres de d√©part.
Le d√©fi est d‚Äôen trouver qui permettront au mod√®le de converger.
Parfois, le mod√®le ne convergera jamais. D‚Äôautres fois, il convergera
vers des solutions diff√©rentes selon les variables de d√©part choisies.
\<

``` r
#modnl_1 <- nls(yield ~ A * (1 - exp(-R*(E + nitro))),
#                data = engelstad.nitro,
#                start = list(A = 50, E = 10, R = 0.2))
```

Le mod√®le ne coverge pas. Essayons les valeurs prises plus haut, lors de
la cr√©ation du graphique, qui semblent bien s‚Äôajuster.

``` r
modnl_1 <-  nls(yield ~ A * (1 - exp(-R*(E + nitro))),
                data = engelstad.nitro,
                start = list(A = 75, E = 30, R = 0.02))
```

Bingo\! Voyons maintenant le sommaire.

``` r
summary(modnl_1)
```

    ## 
    ## Formula: yield ~ A * (1 - exp(-R * (E + nitro)))
    ## 
    ## Parameters:
    ##    Estimate Std. Error t value Pr(>|t|)    
    ## A 75.023427   3.331860  22.517   <2e-16 ***
    ## E 66.164110  27.251591   2.428   0.0184 *  
    ## R  0.012565   0.004881   2.574   0.0127 *  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 12.34 on 57 degrees of freedom
    ## 
    ## Number of iterations to convergence: 5 
    ## Achieved convergence tolerance: 8.067e-06

Les param√®tres sont significativement diff√©rents de z√©ro au seuil 0.05,
et donnent la courbe suivante.

``` r
x <- seq(0, 350, by = 5)
y <- mitscherlich_f(x,
                    A = coefficients(modnl_1)[1],
                    E = coefficients(modnl_1)[2],
                    R = coefficients(modnl_1)[3])

ggplot(tibble(x, y), aes(x, y)) +
    geom_point(data = engelstad.nitro, aes(x = nitro, y = yield)) +
    geom_line() + ylim(c(0, 100))
```

![](05_biostats_files/figure-gfm/unnamed-chunk-71-1.png)<!-- -->

Et les r√©sidus‚Ä¶

``` r
tibble(res = residuals(modnl_1)) %>%
    ggplot(aes(x = res)) + geom_histogram(bins = 20)
```

![](05_biostats_files/figure-gfm/unnamed-chunk-72-1.png)<!-- -->

``` r
tibble(nitro = engelstad.nitro$nitro, res = residuals(modnl_1)) %>%
    ggplot(aes(x = nitro, y = res)) + 
        geom_point() +
        geom_hline(yintercept = 0, colour = "red")
```

![](05_biostats_files/figure-gfm/unnamed-chunk-73-1.png)<!-- -->

Les r√©sidus ne sont pas distribu√©s normalement, mais semble bien
partag√©s de part et d‚Äôautre de la courbe.

## Mod√®les √† effets mixtes

Lorsque l‚Äôon combine des variables fixes (test√©es lors de l‚Äôexp√©rience)
et des variables al√©atoire (variation des unit√©s exp√©rimentales), on
obtient un mod√®le mixte. Les mod√®les mixtes peuvent √™tre univari√©s,
multivari√©s, lin√©aires ordinaires ou g√©n√©ralis√©s ou non lin√©aires.

√Ä la diff√©rence d‚Äôun effet fixe, un effet al√©atoire sera toujours
distribu√© normalement avec une moyenne de 0 et une certaine variance.
Dans un mod√®le lin√©aire o√π l‚Äôeffet al√©atoire est un d√©calage
d‚Äôintercept, cet effet s‚Äôadditionne aux effets fixes:

\[ y = X \beta + Z b + \epsilon \]

o√π:

\(Z\) est la matrice du mod√®le √† \(n\) observations et \(p\) variables
al√©atoires. Les variables al√©atoires sont souvent des variables
nominales qui subissent un encodage cat√©goriel.

\[ Z = \left( \begin{matrix} 
z_{11} & \cdots & z_{1p}  \\ 
z_{21} & \cdots & z_{2p}  \\ 
\vdots & \ddots & \vdots  \\ 
z_{n1} & \cdots & z_{np}
\end{matrix} \right) \]

\(b\) est la matrice des \(p\) coefficients al√©atoires.

\[ b = \left( \begin{matrix} 
b_0  \\ 
b_1  \\ 
\vdots \\ 
b_p 
\end{matrix} \right) \]

Le tableau `lasrosas.corn`, utilis√© pr√©c√©demment, contenait trois
r√©p√©titions effectu√©s au cours de deux ann√©es, 1999 et 2001. √âtant
donn√© que la r√©p√©tition R1 de 1999 n‚Äôa rien √† voir avec la r√©p√©tition R1
de 2001, on dit qu‚Äôelle est **embo√Æt√©e** dans l‚Äôann√©e.

Le module `nlme` nous aidera √† monter notre mod√®le mixte.

``` r
library("nlme")
```

    ## 
    ## Attaching package: 'nlme'

    ## The following object is masked from 'package:dplyr':
    ## 
    ##     collapse

``` r
mmodlin_1 <- lme(fixed = yield ~ lat + long + nitro + topo + bv,
                 random = ~ 1|year/rep,
                 data = lasrosas.corn)
```

√Ä ce stade vous devriez commencer √† √™tre familier avec l‚Äôinterface
formule et vous deviez saisir l‚Äôargument `fixed`, qui d√©signe l‚Äôeffet
fixe. L‚Äôeffet al√©atoire, `random`, suit un tilde `~`. √Ä gauche de la
barre verticale `|`, on place les variables d√©signant les effets
al√©atoire sur la pente. Nous n‚Äôavons pas couvert cet aspect, alors nous
le laissons √† `1`. √Ä droite, on retrouve un structure d‚Äôembo√Ætement
d√©signant l‚Äôeffet al√©atoire: le premier niveau est l‚Äôann√©e, dans
laquelle est embo√Æt√©e la r√©p√©tition.

``` r
summary(mmodlin_1)
```

    ## Linear mixed-effects model fit by REML
    ##  Data: lasrosas.corn 
    ##        AIC      BIC    logLik
    ##   26535.37 26602.93 -13256.69
    ## 
    ## Random effects:
    ##  Formula: ~1 | year
    ##         (Intercept)
    ## StdDev:    20.35425
    ## 
    ##  Formula: ~1 | rep %in% year
    ##         (Intercept) Residual
    ## StdDev:    11.17447 11.35617
    ## 
    ## Fixed effects: yield ~ lat + long + nitro + topo + bv 
    ##                  Value Std.Error   DF    t-value p-value
    ## (Intercept) -1379436.9  55894.55 3430 -24.679273   0.000
    ## lat           -25453.0   1016.53 3430 -25.039084   0.000
    ## long           -8432.3    466.05 3430 -18.092988   0.000
    ## nitro              0.0      0.00 3430   1.739757   0.082
    ## topoHT           -27.7      0.92 3430 -30.122438   0.000
    ## topoLO             6.8      0.88 3430   7.804733   0.000
    ## topoW            -16.7      1.40 3430 -11.944793   0.000
    ## bv                -0.5      0.03 3430 -19.242424   0.000
    ##  Correlation: 
    ##        (Intr) lat    long   nitro  topoHT topoLO topoW 
    ## lat     0.897                                          
    ## long    0.866  0.555                                   
    ## nitro   0.366  0.391  0.247                            
    ## topoHT  0.300 -0.017  0.582  0.024                     
    ## topoLO -0.334 -0.006 -0.621 -0.038 -0.358              
    ## topoW   0.403 -0.004  0.762  0.027  0.802 -0.545       
    ## bv     -0.121 -0.012 -0.214 -0.023 -0.467  0.346 -0.266
    ## 
    ## Standardized Within-Group Residuals:
    ##         Min          Q1         Med          Q3         Max 
    ## -4.32360269 -0.66781575 -0.07450856  0.61587533  3.96434001 
    ## 
    ## Number of Observations: 3443
    ## Number of Groups: 
    ##          year rep %in% year 
    ##             2             6

La sortie est semblable √† celle de la fonction `lm()`.

### Mod√®les mixtes non-lin√©aires

Le mod√®le non lin√©aire cr√©√© plus haut liait le rendement √† la dose
d‚Äôazote. Toutefois, les unit√©s exp√©rimentales (le site `loc` et
l‚Äôann√©e `year`) n‚Äô√©taient pas pris en consid√©ration. Nous allons
maintenant les consid√©rer.

Nous devons d√©cider la structure de l‚Äôeffet al√©atoire, et sur quelles
variables il doit √™tre appliqu√© - la d√©cision appartient √† l‚Äôanalyste.
Il me semble plus convenable de supposer que le site et l‚Äôann√©e
affectera le rendement maximum plut√¥t que l‚Äôenvironnement et le taux:
les effets al√©atoires seront donc affect√©s √† la variable `A`. Les effets
al√©atoires n‚Äôont pas de structure d‚Äôembo√Ætement. L‚Äôeffet de l‚Äôann√©e sur
A sera celui d‚Äôune pente et l‚Äôeffet de site sera celui de l‚Äôintercept.
La fonction que nous utiliserons est `nlme()`.

``` r
mm <- nlme(yield ~ A * (1 - exp(-R*(E + nitro))),
           data = engelstad.nitro, 
           start = c(A = 75, E = 30, R = 0.02), 
           fixed = list(A ~ 1, E ~ 1, R ~ 1), 
           random = A ~ year | loc)
summary(mm)
```

    ## Nonlinear mixed-effects model fit by maximum likelihood
    ##   Model: yield ~ A * (1 - exp(-R * (E + nitro))) 
    ##  Data: engelstad.nitro 
    ##        AIC     BIC    logLik
    ##   477.2286 491.889 -231.6143
    ## 
    ## Random effects:
    ##  Formula: A ~ year | loc
    ##  Structure: General positive-definite, Log-Cholesky parametrization
    ##               StdDev       Corr  
    ## A.(Intercept)  2.611534836 A.(In)
    ## A.year         0.003066832 -0.556
    ## Residual      11.152757999       
    ## 
    ## Fixed effects: list(A ~ 1, E ~ 1, R ~ 1) 
    ##                  Value Std.Error DF   t-value p-value
    ## A.(Intercept) 74.58222  4.722715 56 15.792234  0.0000
    ## E             65.56721 25.533993 56  2.567840  0.0129
    ## R              0.01308  0.004808 56  2.720215  0.0087
    ##  Correlation: 
    ##   A.(In) E     
    ## E  0.379       
    ## R -0.483 -0.934
    ## 
    ## Standardized Within-Group Residuals:
    ##         Min          Q1         Med          Q3         Max 
    ## -1.83373132 -0.89293033  0.07418165  0.68353577  1.82434347 
    ## 
    ## Number of Observations: 60
    ## Number of Groups: 2

Les mod√®les mixtes non lin√©aires peuvent devenir tr√®s complexes lorsque
les param√®tres, par exemple A, E et R, sont eux-m√™me affect√©s
lin√©airement par des variables (par exemple `A ~ topo`). Pour aller
plus loin, consultez [Parent et
al.¬†(2017)](https://doi.org/10.3389/fenvs.2017.00081) ainsi que les
[calculs associ√©s √†
l‚Äôarticle](https://github.com/essicolo/site-specific-multilevel-modeling-of-potato-response-to-nitrogen-fertilization).
Ou √©crivez-moi un courriel pour en discuter\!

**Note**. L‚Äôinterpr√©tation de p-values sur les mod√®les mixtes est
controvers√©e. √Ä ce sujet, ??? Bates a √©crit une longue lettre √† la
communaut√© de d√©veloppement du module `lme4`, une alternative √† `nlme`,
qui remet en cause l‚Äôutilisation des p-values,
[ici](https://stat.ethz.ch/pipermail/r-help/2006-May/094765.html). De
plus en plus, pour les mod√®les mixtes, on se tourne vers les
statistiques bay√©siennes, couvertes dans l‚Äôannexe de cette section
(`statitiques_bayes.ipynb`, en d√©veloppement). √Ä cet effet, le module
[`brms`](https://github.com/paul-buerkner/brms) automatise bien des
aspects de la mod√©lisation mixte bay√©sienne.

## Aller plus loin

### Statistiques g√©n√©rales:

  - [The analysis of biological
    data](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=the+analysis+of+biological+data&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=5&rq.st=1)

### Statistiques avec R

  - Disponibles en version √©lectronique √† la biblioth√®que de
    l‚ÄôUniversit√© Laval:
      - Introduction aux statistiques avec R: [Introductory statistics
        with
        R](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=Introductory+statistics+with+R&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=1&rq.st=0)
      - Approfondir les statistiques avec R: [The R Book, Second
        edition](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=the+r+book&rq.r.la=*&rq.r.loc=*&rq.r.pft=true&rq.r.ta=*&rq.r.td=*&rq.rows=15&rq.st=2)
      - Approfondir les mod√®les √† effets mixtes acec R: [Mixed Effects
        Models and Extensions in Ecology with
        R](https://ariane25.bibl.ulaval.ca/ariane/wicket/detail?c=ariane&m=S&rq.ct=PE&rq.fa=false&rq.r.esc=false&rq.r.l%5B0%5D.c=TI&rq.r.l%5B0%5D.ex=false&rq.r.l%5B0%5D.op=AND&rq.r.l%5B0%5D.v=Mixed+Effects+Models+and+Extensions+in+Ecology+with+R&rq.r.la=*&rq.r.loc=*&rq.r.pft=false&rq.r.ta=*&rq.r.td=*&rq.rows=2&rq.st=1)
  - [ModernDive](https://moderndive.com/index.html), un livre en ligne
    offrant une approche moderne avec le package `moderndive`.
