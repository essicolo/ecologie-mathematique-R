<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>8 Association, partitionnement et ordination | Analyse et modélisation d’agroécosystèmes</title>
  <meta name="description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="8 Association, partitionnement et ordination | Analyse et modélisation d’agroécosystèmes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Association, partitionnement et ordination | Analyse et modélisation d’agroécosystèmes" />
  
  <meta name="twitter:description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe." />
  

<meta name="author" content="Serge-Étienne Parent">


<meta name="date" content="2019-02-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapitre-explorer.html">
<link rel="next" href="chapitre-outliers.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#definitions"><i class="fa fa-check"></i><b>1.1</b> Définitions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#a-qui-sadresse-ce-manuel"><i class="fa fa-check"></i><b>1.2</b> À qui s’adresse ce manuel?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#les-logiciels-libres"><i class="fa fa-check"></i><b>1.3</b> Les logiciels libres</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#langage-de-programmation"><i class="fa fa-check"></i><b>1.4</b> Langage de programmation</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#r"><i class="fa fa-check"></i><b>1.4.1</b> R</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#pourquoi-pas-python"><i class="fa fa-check"></i><b>1.4.2</b> Pourquoi pas Python?</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#pourquoi-pas-matlab"><i class="fa fa-check"></i><b>1.4.3</b> Pourquoi pas Matlab?</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#et-sas"><i class="fa fa-check"></i><b>1.4.4</b> Et… SAS?</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#mais-pourquoi-pas-______"><i class="fa fa-check"></i><b>1.4.5</b> Mais pourquoi pas ______ ?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#contenu-du-manuel"><i class="fa fa-check"></i><b>1.5</b> Contenu du manuel</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#objectifs-generaux"><i class="fa fa-check"></i><b>1.6</b> Objectifs généraux</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#lectures-complementaires"><i class="fa fa-check"></i><b>1.7</b> Lectures complémentaires</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#ecologie-mathematique"><i class="fa fa-check"></i><b>1.7.1</b> Écologie mathématique</a></li>
<li class="chapter" data-level="1.7.2" data-path="index.html"><a href="index.html#programmation"><i class="fa fa-check"></i><b>1.7.2</b> Programmation</a></li>
<li class="chapter" data-level="1.7.3" data-path="index.html"><a href="index.html#divers"><i class="fa fa-check"></i><b>1.7.3</b> Divers</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#besoin-daide"><i class="fa fa-check"></i><b>1.8</b> Besoin d’aide?</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#a-propos-de-lauteur"><i class="fa fa-check"></i><b>1.9</b> À propos de l’auteur</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#un-cours-complementaire-a-dautres-cours"><i class="fa fa-check"></i><b>1.10</b> Un cours complémentaire à d’autres cours</a></li>
<li class="chapter" data-level="1.11" data-path="index.html"><a href="index.html#contribuer-au-manuel"><i class="fa fa-check"></i><b>1.11</b> Contribuer au manuel</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html"><i class="fa fa-check"></i><b>2</b> La science des données avec R</a><ul>
<li class="chapter" data-level="2.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#statistiques-ou-science-des-donnees"><i class="fa fa-check"></i><b>2.1</b> Statistiques ou Science des données?</a></li>
<li class="chapter" data-level="2.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#organiser-son-environnement-de-travail-en-r"><i class="fa fa-check"></i><b>2.2</b> Organiser son environnement de travail en R</a></li>
<li class="chapter" data-level="2.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#preparer-son-flux-de-travail"><i class="fa fa-check"></i><b>2.3</b> Préparer son flux de travail</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-classique"><i class="fa fa-check"></i><b>2.3.1</b> Installation classique</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#r-notebooks"><i class="fa fa-check"></i><b>2.3.2</b> R notebooks</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-avec-anaconda"><i class="fa fa-check"></i><b>2.3.3</b> Installation avec Anaconda</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#premiers-pas-avec-r"><i class="fa fa-check"></i><b>2.4</b> Premiers pas avec R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#types-de-donnees"><i class="fa fa-check"></i><b>2.4.1</b> Types de données</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-collections-de-donnees"><i class="fa fa-check"></i><b>2.4.2</b> Les collections de données</a></li>
<li class="chapter" data-level="2.4.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-fonctions"><i class="fa fa-check"></i><b>2.4.3</b> Les fonctions</a></li>
<li class="chapter" data-level="2.4.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-boucles"><i class="fa fa-check"></i><b>2.4.4</b> Les boucles</a></li>
<li class="chapter" data-level="2.4.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#conditions-if-else-if-else"><i class="fa fa-check"></i><b>2.4.5</b> Conditions: if, else if, else</a></li>
<li class="chapter" data-level="2.4.6" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installer-et-charger-un-module"><i class="fa fa-check"></i><b>2.4.6</b> Installer et charger un module</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#enfin"><i class="fa fa-check"></i><b>2.5</b> Enfin…</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html"><i class="fa fa-check"></i><b>3</b> Organisation des données et opérations sur des tableaux</a><ul>
<li class="chapter" data-level="3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#les-collections-de-donnees-1"><i class="fa fa-check"></i><b>3.1</b> Les collections de données</a></li>
<li class="chapter" data-level="3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#organiser-un-tableau-de-donnees"><i class="fa fa-check"></i><b>3.2</b> Organiser un tableau de données</a></li>
<li class="chapter" data-level="3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#formats-de-tableau"><i class="fa fa-check"></i><b>3.3</b> Formats de tableau</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#xls-ou-xlsx"><i class="fa fa-check"></i><b>3.3.1</b> <em>xls</em> ou <em>xlsx</em></a></li>
<li class="chapter" data-level="3.3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#csv"><i class="fa fa-check"></i><b>3.3.2</b> <em>csv</em></a></li>
<li class="chapter" data-level="3.3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#json"><i class="fa fa-check"></i><b>3.3.3</b> <em>json</em></a></li>
<li class="chapter" data-level="3.3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#sqlite"><i class="fa fa-check"></i><b>3.3.4</b> SQLite</a></li>
<li class="chapter" data-level="3.3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#suggestion"><i class="fa fa-check"></i><b>3.3.5</b> Suggestion</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#entreposer-ses-donnees"><i class="fa fa-check"></i><b>3.4</b> Entreposer ses données</a></li>
<li class="chapter" data-level="3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#manipuler-des-donnees-en-mode-tidyverse"><i class="fa fa-check"></i><b>3.5</b> Manipuler des données en mode tidyverse</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#importer-vos-donnees-dans-voter-session-de-travail"><i class="fa fa-check"></i><b>3.5.1</b> Importer vos données dans voter session de travail</a></li>
<li class="chapter" data-level="3.5.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#comment-selectionner-et-filtrer-des-donnees"><i class="fa fa-check"></i><b>3.5.2</b> Comment sélectionner et filtrer des données?</a></li>
<li class="chapter" data-level="3.5.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#le-format-long-et-le-format-large"><i class="fa fa-check"></i><b>3.5.3</b> Le format long et le format large</a></li>
<li class="chapter" data-level="3.5.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#combiner-des-tableaux"><i class="fa fa-check"></i><b>3.5.4</b> Combiner des tableaux</a></li>
<li class="chapter" data-level="3.5.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#operations-sur-les-tableaux"><i class="fa fa-check"></i><b>3.5.5</b> Opérations sur les tableaux</a></li>
<li class="chapter" data-level="3.5.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exemple-difficile"><i class="fa fa-check"></i><b>3.5.6</b> Exemple (difficile)</a></li>
<li class="chapter" data-level="3.5.7" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exporter-un-tableau"><i class="fa fa-check"></i><b>3.5.7</b> Exporter un tableau</a></li>
<li class="chapter" data-level="3.5.8" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#aller-plus-loin-dans-le-tidyverse"><i class="fa fa-check"></i><b>3.5.8</b> Aller plus loin dans le tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#references"><i class="fa fa-check"></i><b>3.6</b> Références</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html"><i class="fa fa-check"></i><b>4</b> Visualisation</a><ul>
<li class="chapter" data-level="4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#pourquoi-explorer-graphiquement"><i class="fa fa-check"></i><b>4.1</b> Pourquoi explorer graphiquement?</a></li>
<li class="chapter" data-level="4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publier-un-graphique"><i class="fa fa-check"></i><b>4.2</b> Publier un graphique</a><ul>
<li class="chapter" data-level="4.2.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#cinq-qualites-dun-bon-graphique"><i class="fa fa-check"></i><b>4.2.1</b> Cinq qualités d’un bon graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-le-type-de-graphique-le-plus-approprie"><i class="fa fa-check"></i><b>4.3</b> Choisir le type de graphique le plus approprié</a></li>
<li class="chapter" data-level="4.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-son-outils-de-visualisation"><i class="fa fa-check"></i><b>4.4</b> Choisir son outils de visualisation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-imperative"><i class="fa fa-check"></i><b>4.4.1</b> Approche impérative</a></li>
<li class="chapter" data-level="4.4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-declarative"><i class="fa fa-check"></i><b>4.4.2</b> Approche déclarative</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visualisation-en-r"><i class="fa fa-check"></i><b>4.5</b> Visualisation en R</a></li>
<li class="chapter" data-level="4.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#module-de-base-pour-les-graphiques"><i class="fa fa-check"></i><b>4.6</b> Module de base pour les graphiques</a></li>
<li class="chapter" data-level="4.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#la-grammaire-graphique-ggplot2"><i class="fa fa-check"></i><b>4.7</b> La grammaire graphique ggplot2</a></li>
<li class="chapter" data-level="4.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#mon-premier-ggplot"><i class="fa fa-check"></i><b>4.8</b> Mon premier ggplot</a><ul>
<li class="chapter" data-level="4.8.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#plusieurs-sources-de-donnees"><i class="fa fa-check"></i><b>4.8.1</b> Plusieurs sources de données</a></li>
<li class="chapter" data-level="4.8.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-avec-style"><i class="fa fa-check"></i><b>4.8.2</b> Exporter avec style</a></li>
<li class="chapter" data-level="4.8.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#nuages-de-points"><i class="fa fa-check"></i><b>4.8.3</b> Nuages de points</a></li>
<li class="chapter" data-level="4.8.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#diagrammes-en-lignes"><i class="fa fa-check"></i><b>4.8.4</b> Diagrammes en lignes</a></li>
<li class="chapter" data-level="4.8.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-histogrammes"><i class="fa fa-check"></i><b>4.8.5</b> Les histogrammes</a></li>
<li class="chapter" data-level="4.8.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#boxplots"><i class="fa fa-check"></i><b>4.8.6</b> Boxplots</a></li>
<li class="chapter" data-level="4.8.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-diagrammes-en-barre"><i class="fa fa-check"></i><b>4.8.7</b> Les diagrammes en barre</a></li>
<li class="chapter" data-level="4.8.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-un-graphique"><i class="fa fa-check"></i><b>4.8.8</b> Exporter un graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-graphiques-comme-outil-dexploration-des-donnees"><i class="fa fa-check"></i><b>4.9</b> Les graphiques comme outil d’exploration des données</a><ul>
<li class="chapter" data-level="4.9.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-graphiques-interactifs"><i class="fa fa-check"></i><b>4.9.1</b> Des graphiques interactifs!</a></li>
<li class="chapter" data-level="4.9.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-extensions-de-ggplot2"><i class="fa fa-check"></i><b>4.9.2</b> Des extensions de ggplot2</a></li>
<li class="chapter" data-level="4.9.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#aller-plus-loin-avec-ggplot2"><i class="fa fa-check"></i><b>4.9.3</b> Aller plus loin avec ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-les-bonnes-couleurs"><i class="fa fa-check"></i><b>4.10</b> Choisir les bonnes couleurs</a></li>
<li class="chapter" data-level="4.11" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#regles-particulieres"><i class="fa fa-check"></i><b>4.11</b> Règles particulières</a><ul>
<li class="chapter" data-level="4.11.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#ne-tronquez-pas-inutilement-laxe-des-y"><i class="fa fa-check"></i><b>4.11.1</b> Ne tronquez pas inutilement l’axe des <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="4.11.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#utilisez-un-encrage-proportionnel"><i class="fa fa-check"></i><b>4.11.2</b> Utilisez un encrage proportionnel</a></li>
<li class="chapter" data-level="4.11.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publiez-vos-donnees"><i class="fa fa-check"></i><b>4.11.3</b> Publiez vos données</a></li>
<li class="chapter" data-level="4.11.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visitez-www.junkcharts.typepad.com-de-temps-a-autre"><i class="fa fa-check"></i><b>4.11.4</b> Visitez www.junkcharts.typepad.com de temps à autre</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html"><i class="fa fa-check"></i><b>5</b> Biostatistiques</a><ul>
<li class="chapter" data-level="5.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#populations-et-echantillons"><i class="fa fa-check"></i><b>5.1</b> Populations et échantillons</a></li>
<li class="chapter" data-level="5.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-variables"><i class="fa fa-check"></i><b>5.2</b> Les variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-quantitatives"><i class="fa fa-check"></i><b>5.2.1</b> Variables quantitatives</a></li>
<li class="chapter" data-level="5.2.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-qualitatives"><i class="fa fa-check"></i><b>5.2.2</b> Variables qualitatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-probabilites"><i class="fa fa-check"></i><b>5.3</b> Les probabilités</a></li>
<li class="chapter" data-level="5.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-distributions"><i class="fa fa-check"></i><b>5.4</b> Les distributions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-binomiale"><i class="fa fa-check"></i><b>5.4.1</b> Distribution binomiale</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-de-poisson"><i class="fa fa-check"></i><b>5.4.2</b> Distribution de Poisson</a></li>
<li class="chapter" data-level="5.4.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-uniforme"><i class="fa fa-check"></i><b>5.4.3</b> Distribution uniforme</a></li>
<li class="chapter" data-level="5.4.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-normale"><i class="fa fa-check"></i><b>5.4.4</b> Distribution normale</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#statistiques-descriptives"><i class="fa fa-check"></i><b>5.5</b> Statistiques descriptives</a></li>
<li class="chapter" data-level="5.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-dhypotheses-a-un-et-deux-echantillons"><i class="fa fa-check"></i><b>5.6</b> Tests d’hypothèses à un et deux échantillons</a><ul>
<li class="chapter" data-level="5.6.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-t-a-un-seul-echantillon"><i class="fa fa-check"></i><b>5.6.1</b> Test de t à un seul échantillon</a></li>
<li class="chapter" data-level="5.6.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#attention-mauvaises-interpretations-des-p-values"><i class="fa fa-check"></i><b>5.6.2</b> Attention: mauvaises interprétations des <em>p-values</em></a></li>
<li class="chapter" data-level="5.6.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-wilcoxon-a-un-seul-echantillon"><i class="fa fa-check"></i><b>5.6.3</b> Test de Wilcoxon à un seul échantillon</a></li>
<li class="chapter" data-level="5.6.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-t-a-deux-echantillons"><i class="fa fa-check"></i><b>5.6.4</b> Tests de t à deux échantillons</a></li>
<li class="chapter" data-level="5.6.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#comparaison-des-variances"><i class="fa fa-check"></i><b>5.6.5</b> Comparaison des variances</a></li>
<li class="chapter" data-level="5.6.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-wilcoxon-a-deux-echantillons"><i class="fa fa-check"></i><b>5.6.6</b> Tests de Wilcoxon à deux échantillons</a></li>
<li class="chapter" data-level="5.6.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-tests-paires"><i class="fa fa-check"></i><b>5.6.7</b> Les tests pairés</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#lanalyse-de-variance"><i class="fa fa-check"></i><b>5.7</b> L’analyse de variance</a></li>
<li class="chapter" data-level="5.8" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-modeles-statistiques"><i class="fa fa-check"></i><b>5.8</b> Les modèles statistiques</a><ul>
<li class="chapter" data-level="5.8.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modeles-a-effets-fixes"><i class="fa fa-check"></i><b>5.8.1</b> Modèles à effets fixes</a></li>
<li class="chapter" data-level="5.8.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modeles-a-effets-mixtes"><i class="fa fa-check"></i><b>5.8.2</b> Modèles à effets mixtes</a></li>
<li class="chapter" data-level="5.8.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#aller-plus-loin"><i class="fa fa-check"></i><b>5.8.3</b> Aller plus loin</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html"><i class="fa fa-check"></i><b>6</b> Introduction à l’analyse bayésienne en écologie</a><ul>
<li class="chapter" data-level="6.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#quest-ce-que-cest"><i class="fa fa-check"></i><b>6.1</b> Qu’est-ce que c’est?</a></li>
<li class="chapter" data-level="6.2" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pourquoi-lutiliser"><i class="fa fa-check"></i><b>6.2</b> Pourquoi l’utiliser?</a></li>
<li class="chapter" data-level="6.3" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#comment-lutiliser"><i class="fa fa-check"></i><b>6.3</b> Comment l’utiliser?</a></li>
<li class="chapter" data-level="6.4" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#faucons-pelerins"><i class="fa fa-check"></i><b>6.4</b> Faucons pélerins</a></li>
<li class="chapter" data-level="6.5" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#statistiques-dune-population"><i class="fa fa-check"></i><b>6.5</b> Statistiques d’une population</a><ul>
<li class="chapter" data-level="6.5.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#greta"><i class="fa fa-check"></i><b>6.5.1</b> greta</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#test-de-t-difference-entre-des-groupes"><i class="fa fa-check"></i><b>6.6</b> Test de t: Différence entre des groupes</a></li>
<li class="chapter" data-level="6.7" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pour-aller-plus-loin"><i class="fa fa-check"></i><b>6.7</b> Pour aller plus loin</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html"><i class="fa fa-check"></i><b>7</b> Explorer R</a><ul>
<li class="chapter" data-level="7.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-sur-le-web"><i class="fa fa-check"></i><b>7.1</b> R sur le web</a><ul>
<li class="chapter" data-level="7.1.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#github"><i class="fa fa-check"></i><b>7.1.1</b> GitHub</a></li>
<li class="chapter" data-level="7.1.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#twitter"><i class="fa fa-check"></i><b>7.1.2</b> Twitter</a></li>
<li class="chapter" data-level="7.1.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#nouvelles"><i class="fa fa-check"></i><b>7.1.3</b> Nouvelles</a></li>
<li class="chapter" data-level="7.1.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#des-questions"><i class="fa fa-check"></i><b>7.1.4</b> Des questions?</a></li>
<li class="chapter" data-level="7.1.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#participer"><i class="fa fa-check"></i><b>7.1.5</b> Participer</a></li>
<li class="chapter" data-level="7.1.6" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#mise-en-garde"><i class="fa fa-check"></i><b>7.1.6</b> Mise en garde</a></li>
<li class="chapter" data-level="7.1.7" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#prendre-tout-ca-en-note"><i class="fa fa-check"></i><b>7.1.7</b> Prendre tout ça en note</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-en-chaire-et-en-os"><i class="fa fa-check"></i><b>7.2</b> R en chaire et en os</a></li>
<li class="chapter" data-level="7.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#quelques-outils-en-ecologie-mathematique-avec-r"><i class="fa fa-check"></i><b>7.3</b> Quelques outils en écologie mathématique avec R</a><ul>
<li class="chapter" data-level="7.3.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#pretraitement-des-donnees"><i class="fa fa-check"></i><b>7.3.1</b> Prétraitement des données</a></li>
<li class="chapter" data-level="7.3.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#acquerir-des-donnees-meteo"><i class="fa fa-check"></i><b>7.3.2</b> Acquérir des données météo</a></li>
<li class="chapter" data-level="7.3.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#pedometrie-avec-r"><i class="fa fa-check"></i><b>7.3.3</b> Pédométrie avec R</a></li>
<li class="chapter" data-level="7.3.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#meta-analyses-en-r"><i class="fa fa-check"></i><b>7.3.4</b> Méta-analyses en R</a></li>
<li class="chapter" data-level="7.3.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#creer-des-applications-avec-r"><i class="fa fa-check"></i><b>7.3.5</b> Créer des applications avec R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html"><i class="fa fa-check"></i><b>8</b> Association, partitionnement et ordination</a><ul>
<li class="chapter" data-level="8.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#espaces-danalyse"><i class="fa fa-check"></i><b>8.1</b> Espaces d’analyse</a><ul>
<li class="chapter" data-level="8.1.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#abondance-et-occurence"><i class="fa fa-check"></i><b>8.1.1</b> Abondance et occurence</a></li>
<li class="chapter" data-level="8.1.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#environnement"><i class="fa fa-check"></i><b>8.1.2</b> Environnement</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#analyse-dassociation"><i class="fa fa-check"></i><b>8.2</b> Analyse d’association</a><ul>
<li class="chapter" data-level="8.2.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#association-entre-objets-mode-q"><i class="fa fa-check"></i><b>8.2.1</b> Association entre objets (mode Q)</a></li>
<li class="chapter" data-level="8.2.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#associations-entre-variables-mode-r"><i class="fa fa-check"></i><b>8.2.2</b> Associations entre variables (mode R)</a></li>
<li class="chapter" data-level="8.2.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-les-associations"><i class="fa fa-check"></i><b>8.2.3</b> Conclusion sur les associations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement"><i class="fa fa-check"></i><b>8.3</b> Partitionnement</a><ul>
<li class="chapter" data-level="8.3.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#evaluation-dun-partitionnement"><i class="fa fa-check"></i><b>8.3.1</b> Évaluation d’un partitionnement</a></li>
<li class="chapter" data-level="8.3.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-non-hierarchique"><i class="fa fa-check"></i><b>8.3.2</b> Partitionnement non hiérarchique</a></li>
<li class="chapter" data-level="8.3.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hierarchique"><i class="fa fa-check"></i><b>8.3.3</b> Partitionnement hiérarchique</a></li>
<li class="chapter" data-level="8.3.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hierarchique-basee-sur-la-densite-des-points"><i class="fa fa-check"></i><b>8.3.4</b> Partitionnement hiérarchique basée sur la densité des points</a></li>
<li class="chapter" data-level="8.3.5" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-le-partitionnement"><i class="fa fa-check"></i><b>8.3.5</b> Conclusion sur le partitionnement</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination"><i class="fa fa-check"></i><b>8.4</b> Ordination</a><ul>
<li class="chapter" data-level="8.4.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-non-contraignante"><i class="fa fa-check"></i><b>8.4.1</b> Ordination non contraignante</a></li>
<li class="chapter" data-level="8.4.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-contraignante"><i class="fa fa-check"></i><b>8.4.2</b> Ordination contraignante</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html"><i class="fa fa-check"></i><b>9</b> Détection de valeurs aberrantes et imputation</a></li>
<li class="chapter" data-level="10" data-path="chapitre-temps.html"><a href="chapitre-temps.html"><i class="fa fa-check"></i><b>10</b> Les séries temporelles</a></li>
<li class="chapter" data-level="11" data-path="chapitre-git.html"><a href="chapitre-git.html"><i class="fa fa-check"></i><b>11</b> Science ouverte et suivi de version</a></li>
<li class="chapter" data-level="12" data-path="chapitre-ml.html"><a href="chapitre-ml.html"><i class="fa fa-check"></i><b>12</b> Autoapprentissage</a><ul>
<li class="chapter" data-level="12.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#objectifs"><i class="fa fa-check"></i><b>12.1</b> Objectifs</a></li>
<li class="chapter" data-level="12.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lexique"><i class="fa fa-check"></i><b>12.2</b> Lexique</a></li>
<li class="chapter" data-level="12.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#demarche"><i class="fa fa-check"></i><b>12.3</b> Démarche</a><ul>
<li class="chapter" data-level="12.3.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#pretraitement"><i class="fa fa-check"></i><b>12.3.1</b> Prétraitement</a></li>
<li class="chapter" data-level="12.3.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#entrainement-et-test"><i class="fa fa-check"></i><b>12.3.2</b> Entraînement et test</a></li>
<li class="chapter" data-level="12.3.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#sousapprentissage-et-surapprentissage"><i class="fa fa-check"></i><b>12.3.3</b> Sousapprentissage et surapprentissage</a></li>
<li class="chapter" data-level="12.3.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#validation-croisee"><i class="fa fa-check"></i><b>12.3.4</b> Validation croisée</a></li>
<li class="chapter" data-level="12.3.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#choix-de-lalgorithme-dapprentissage"><i class="fa fa-check"></i><b>12.3.5</b> Choix de l’algorithme d’apprentissage</a></li>
<li class="chapter" data-level="12.3.6" data-path="chapitre-ml.html"><a href="chapitre-ml.html#deploiement"><i class="fa fa-check"></i><b>12.3.6</b> Déploiement</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#algorithmes"><i class="fa fa-check"></i><b>12.4</b> Algorithmes</a></li>
<li class="chapter" data-level="12.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lautoapprentissage-en-r"><i class="fa fa-check"></i><b>12.5</b> L’autoapprentissage en R</a></li>
<li class="chapter" data-level="12.6" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-k-plus-proches-voisins"><i class="fa fa-check"></i><b>12.6</b> Les <em>k</em> plus proches voisins</a><ul>
<li class="chapter" data-level="12.6.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#exemple-dapplication-1"><i class="fa fa-check"></i><b>12.6.1</b> Exemple d’application</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-arbres-decisionnels"><i class="fa fa-check"></i><b>12.7</b> Les arbres décisionnels</a></li>
<li class="chapter" data-level="12.8" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-reseaux-neuronaux"><i class="fa fa-check"></i><b>12.8</b> Les réseaux neuronaux</a><ul>
<li class="chapter" data-level="12.8.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-reseaux-neuronaux-sur-r-avec-neuralnet"><i class="fa fa-check"></i><b>12.8.1</b> Les réseaux neuronaux sur R avec neuralnet</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens"><i class="fa fa-check"></i><b>12.9</b> Les processus gaussiens</a><ul>
<li class="chapter" data-level="12.9.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#un-approche-intuitive"><i class="fa fa-check"></i><b>12.9.1</b> Un approche intuitive</a></li>
<li class="chapter" data-level="12.9.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens-en-r"><i class="fa fa-check"></i><b>12.9.2</b> Les processus gaussiens en <code>R</code></a></li>
<li class="chapter" data-level="12.9.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#application-pratique"><i class="fa fa-check"></i><b>12.9.3</b> Application pratique</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapitre-geo.html"><a href="chapitre-geo.html"><i class="fa fa-check"></i><b>13</b> Les données spatiales</a></li>
<li class="chapter" data-level="14" data-path="chapitre-ode.html"><a href="chapitre-ode.html"><i class="fa fa-check"></i><b>14</b> Modélisation déterministe</a><ul>
<li class="chapter" data-level="14.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#equations-differentielles"><i class="fa fa-check"></i><b>14.1</b> Équations différentielles</a></li>
<li class="chapter" data-level="14.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#les-equations-differentielles-ordinaires-en-modelisation-ecologique"><i class="fa fa-check"></i><b>14.2</b> Les équations différentielles ordinaires en modélisation écologique</a><ul>
<li class="chapter" data-level="14.2.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#evolution-dune-seule-population-en-fonction-du-temps"><i class="fa fa-check"></i><b>14.2.1</b> Évolution d’une seule population en fonction du temps</a></li>
<li class="chapter" data-level="14.2.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#population-exploitee"><i class="fa fa-check"></i><b>14.2.2</b> Population exploitée</a></li>
<li class="chapter" data-level="14.2.3" data-path="chapitre-ode.html"><a href="chapitre-ode.html#interactions-biologiques"><i class="fa fa-check"></i><b>14.2.3</b> Interactions biologiques</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="chapitre-ode.html"><a href="chapitre-ode.html#les-equations-differentielles-partielles-en-modelisation-ecologique"><i class="fa fa-check"></i><b>14.3</b> Les équations différentielles partielles en modélisation écologique</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse et modélisation d’agroécosystèmes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapitre-ordination" class="section level1">
<h1><span class="header-section-number">8</span> Association, partitionnement et ordination</h1>
<hr />
<p>️ <strong>Objectifs spécifiques</strong>:</p>
<p>À la fin de ce chapitre, vous</p>
<ul>
<li>serez en mesure d’effectuer des calculs permettant de mesurer des différence entre des observations, des groupes d’observation ou des variables observées</li>
<li>serez en mesure d’effection des analyses de partitionnement hiérarchiques et non-hiérarchiques</li>
<li>serez en mesure d’effectuer des calculs d’ordination à l’aide des techniques de réduction d’axe communes: analyse en composante principale, analyse discriminante linéaire, l’analyse de correspondance, l’analyse factorielle, l’analyse en coordonnées principales et l’analyse de redondance.</li>
</ul>
<hr />
<p>Les données écologiques incluent généralement plusieurs variables qui doivent être analysées conjointement. Les techniques pour l’analyse multivariée de données écologiques ont grandi en nombre et en complexité, laissant émerger l’écologie numérique, un nouveau domaine d’étude scientifique initié par Pierre Legendre et Louis Legendre dont l’ouvrage <em>Numerical Ecology</em>, aujourd’hui à sa troisième édition, reste un incontournable pour qui s’intéresse aux mathématiques sous-jacentes au domaine. Pour la rédaction de ces notes, c’est toutefois le livre <em>Numerical ecology with R</em>, écrit par Borcard et al. (2011) pour offrir un guide à qui voudrait une approche plus appliquée.</p>
<p>L’écologie numérique sera effleurée dans ce chapitre, qui introduit à trois concepts.</p>
<ol style="list-style-type: decimal">
<li>Les <strong>associations</strong> permettent de quantifier la ressemblance ou la différence entre deux observation (échantillons) ou variables (descripteurs). Lorsque l’on a plus de deux variables ou plus de deux site, nous obtenons des matrices d’association.</li>
<li>Le <strong>partitionnement</strong> permet de regrouper des observations ou des variables selon des métriques d’association.</li>
<li>L’<strong>ordination</strong> vise par l’intermédiaire de techniques de réduction d’axe à mettre de l’ordre dans des données dont le nombre élevé de variables peut amener à des difficultés d’appréciation et d’interprétaion.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>## ✔ ggplot2 3.1.0     ✔ purrr   0.3.0
## ✔ tibble  2.0.1     ✔ dplyr   0.8.0
## ✔ tidyr   0.8.2     ✔ stringr 1.4.0
## ✔ readr   1.3.1     ✔ forcats 0.3.0</code></pre>
<pre><code>## ── Conflicts ────────────────────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<div id="espaces-danalyse" class="section level2">
<h2><span class="header-section-number">8.1</span> Espaces d’analyse</h2>
<div id="abondance-et-occurence" class="section level3">
<h3><span class="header-section-number">8.1.1</span> Abondance et occurence</h3>
<p>L’abondance est le décompte d’espèces observées, tandis que l’occurence est la présence ou l’absence d’une espèce. Le tableau suivant contient des données d’abondance.</p>
<pre class="sourceCode r"><code class="sourceCode r">abundance &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="st">&#39;Bruant familier&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>),
                    <span class="st">&#39;Citelle à poitrine rousse&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Colibri à gorge rubis&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Geai bleu&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Bruant chanteur&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">2</span>),
                    <span class="st">&#39;Chardonneret&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">9</span>, <span class="dv">6</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Bruant à gorge blanche&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Mésange à tête noire&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">20</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>),
                    <span class="st">&#39;Jaseur boréal&#39;</span> =<span class="st"> </span><span class="kw">c</span>(<span class="dv">66</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>))</code></pre>
<p>Ce tableau peut être rapidement transformé en données d’occurence, qui ne comprennent que l’information booléenne de présence (noté 1) et d’absence (noté 0).</p>
<pre class="sourceCode r"><code class="sourceCode r">occurence &lt;-<span class="st"> </span>abundance <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute_all</span>(<span class="kw">funs</span>(<span class="kw">if_else</span>(. <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>)))</code></pre>
<pre><code>## Warning: funs() is soft deprecated as of dplyr 0.8.0
## please use list() instead
## 
## # Before:
## funs(name = f(.)
## 
## # After: 
## list(name = ~f(.))
## This warning is displayed once per session.</code></pre>
<p>L’<strong>espace des espèces</strong> (ou des variables ou descripteurs) est celui où les espèces forment les axes et où les sites sont positionnés dans cet espace. Il s’agit d’une perspective en <em>mode R</em>, qui permet principalement d’identifier quels espèces se retrouvent plus courrament ensemble.</p>
<pre class="sourceCode r"><code class="sourceCode r">abundance <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="st">&quot;Bruant chanteur&quot;</span>, <span class="st">&quot;Chardonneret&quot;</span>, <span class="st">&quot;Mésange à tête noire&quot;</span>)</code></pre>
<pre><code>## # A tibble: 4 x 3
##   `Bruant chanteur` Chardonneret `Mésange à tête noire`
##               &lt;dbl&gt;        &lt;dbl&gt;                  &lt;dbl&gt;
## 1                 1            0                     20
## 2                 0            9                      1
## 3                 5            6                      1
## 4                 2            0                      0</code></pre>
<p>Dans l’<strong>espace des sites</strong> (ou les échantillons ou objets), on transpose la matrice d’abondance. On passe ici en <em>mode Q</em>, où chaque point est une espèce, et où l’on peut observer quels échantillons sont similaires.</p>
<pre class="sourceCode r"><code class="sourceCode r">abundance <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>.[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), ] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">t</span>(.)</code></pre>
<pre><code>##                           [,1] [,2] [,3]
## Bruant familier              1    0    0
## Citelle à poitrine rousse    1    0    0
## Colibri à gorge rubis        0    1    0
## Geai bleu                    3    2    0
## Bruant chanteur              1    0    5
## Chardonneret                 0    9    6
## Bruant à gorge blanche       1    0    0
## Mésange à tête noire        20    1    1
## Jaseur boréal               66    0    0</code></pre>
</div>
<div id="environnement" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Environnement</h3>
<p>L’<strong>espace de l’environnement</strong> comprend souvent un autre tableau contenant l’information sur l’environnement où se trouve les espèces: les coordonnées et l’élévation, la pente, le pH du sol, la pluviométrie, etc.</p>
</div>
</div>
<div id="analyse-dassociation" class="section level2">
<h2><span class="header-section-number">8.2</span> Analyse d’association</h2>
<p>Nous utiliserons le terme <em>association</em> come une <strong>mesure pour quantifier la ressemblance ou la différence entre deux objets (échantillons) ou variables (descripteurs)</strong>.</p>
<p>Alors que la corrélation et la covariance sont des mesures d’association entre des variables (analyse en <em>mode R</em>), la <strong>similarité</strong> et la <strong>distance</strong> sont deux types de une mesure d’association entre des objets (analyse en <em>mode Q</em>). Une distance de 0 est mesurée chez deux objets identiques. La distance augmente au fur et à mesure que les objets sont dissociés. Une similarité ayant une valeur de 0 indique aucune association, tandis qu’une valeur de 1 indique une association parfaite. À l’opposé, la dissimilarité est égale à 1-similarité.</p>
<p>La distance peut être liée à la similarité par la relation:</p>
<p><span class="math display">\[distance=\sqrt{1-similarité}\]</span></p>
<p>ou</p>
<p><span class="math display">\[distance=\sqrt{dissimilarité}\]</span></p>
<p>La racine carrée permet, pour certains indices de similarité, d’obtenir des propriétés euclédiennes. Pour plus de détails, voyez le tableau 7.2 de <a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre (2012)</a>.</p>
<p>Les matrices d’association sont généralement présentées comme des matrices carrées, dont les dimensions sont égales au nombre d’objets (<em>mode Q</em>) ou de vrariables (<em>mode R</em>) dans le tableau. Chaque élément (“cellule”) de la matrice est un indice d’association entre un objet (ou une variable) et un autre. Ainsi, la diagonale de la matrice est un vecteur nul (distance ou dissimilarité) ou unitaire (similarité), car elle correspond à l’association entre un objet et lui-même.</p>
<p>Puisque l’association entre A et B est la même qu’entre B et A, et puisque la diagonale retourne une valeur convenue, il est possible d’exprimer une matrice d’association en mode “compact”, sous forme de vecteur. Le vecteur d’association entre des objets A, B et C contiendra toute l’information nécessaire en un vecteur de trois chiffres, <code>[AB, AC, BC]</code>, plutôt qu’une matrice de dimension <span class="math inline">\(3 \times 3\)</span>. L’impact sur la mémoire vive peut être considérable pour les calculs comprenant de nombreuses dimensions.</p>
<p>En R, les calculs de similarité et de distances peuvent être effectués avec le module vegan. La fonction <code>vegdist</code> permet de calculer les indices d’association en forme carrée.</p>
<p>Nous verons plus tard les méthodes de mesure de similarité et de distance plus loin. Pour l’instant, utilisons la méthode de <em>Jaccard</em> pour une démonstration sur des données d’occurence.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;vegan&quot;</span>)</code></pre>
<pre><code>## Loading required package: permute</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## This is vegan 2.5-4</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">vegdist</span>(occurence, <span class="dt">method =</span> <span class="st">&quot;jaccard&quot;</span>,
        <span class="dt">diag =</span> <span class="ot">TRUE</span>, <span class="dt">upper =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>##           1         2         3         4
## 1 0.0000000 0.7777778 0.7500000 0.7142857
## 2 0.7777778 0.0000000 0.6000000 1.0000000
## 3 0.7500000 0.6000000 0.0000000 0.7500000
## 4 0.7142857 1.0000000 0.7500000 0.0000000</code></pre>
<p>Remarquez que <code>vegdist</code> retourne une matrice dont la diagonale est de 0 (on l’affiche en spécifiant <code>diag = TRUE</code>). La diagonale est l’association d’un objet avec lui-même. Or la similarité d’un objet avec lui-même devrait être de 1! En fait, par convention <code>vegdist</code> retourne des dissimilarités, non pas des similarités. La matrice de distance serait donc calculée en extrayant la racine carrée des éléments de la matrice de dissimilarité:</p>
<pre class="sourceCode r"><code class="sourceCode r">dissimilarity &lt;-<span class="st"> </span><span class="kw">vegdist</span>(occurence, <span class="dt">method =</span> <span class="st">&quot;jaccard&quot;</span>,
                         <span class="dt">diag =</span> <span class="ot">TRUE</span>, <span class="dt">upper =</span> <span class="ot">TRUE</span>)
distance &lt;-<span class="st"> </span><span class="kw">sqrt</span>(dissimilarity)
distance</code></pre>
<pre><code>##           1         2         3         4
## 1 0.0000000 0.8819171 0.8660254 0.8451543
## 2 0.8819171 0.0000000 0.7745967 1.0000000
## 3 0.8660254 0.7745967 0.0000000 0.8660254
## 4 0.8451543 1.0000000 0.8660254 0.0000000</code></pre>
<p>Dans le chapitre sur l’analyse compositionnelle, nous avons abordé les significations différentes que peuvent prendre le zéro. L’information fournie par un zéro peut être différente selon les circonstances. Dans le cas d’une variable continue, un zéro signifie généralement une mesure sous le seuil de détection. Deux tissus dont la concentration en cuivre est nulle ont une afinité sous la perspective de la concentration en cuivre. Dans le cas de mesures d’abondance (décompte) ou d’occurence (présence-absence), on pourra décrire comme similaires deux niches écologiques où l’on retrouve une espèce en particulier. Mais deux sites où l’on de retouve pas d’ours polaires ne correspondent pas nécessairement à des niches similaires! En effet, il peut exister de nombreuses raisons écologiques et méthodologiques pour lesquelles l’espèces ou les espèces n’ont pas été observées. C’est le problème des <strong>double-zéros</strong> (espèces non observées à deux sites), problème qui est amplifié avec les grilles comprenant des espèces rares.</p>
<p>La ressemblance entre des objets comprenant des données continues devrait être calculée grâce à des indicateurs <em>symétriques</em>. Inversement, les affinités entre les objets décrits par des données d’abondance ou d’occurence susceptibles de générer des problèmes de double-zéros devraient être évaluées grâce à des indicateurs <em>asymétriques</em>. Un défi supplémentaire arrive lorsque les données sont de type mixte.</p>
<p>Nous utiliserons la convention de <code>scipy</code> et nous calculerons la dissimilarité, non pas la similarité. Les mesures de dissimilarité sont calculées sur des données d’abondance ou des données d’occurence. Notons qu’il existe beaucoup de confusion dans la littérature sur la manière de nommer les dissimilarités (ce qui n’est pas le cas des distances, dont les noms sont reconnus). Dans les sections suivantes, nous noterons la dissimilarité avec un <span class="math inline">\(d\)</span> minuscule et la distance avec un <span class="math inline">\(D\)</span> majuscule.</p>
<div id="association-entre-objets-mode-q" class="section level3">
<h3><span class="header-section-number">8.2.1</span> Association entre objets (mode Q)</h3>
<div id="objets-abondance" class="section level4">
<h4><span class="header-section-number">8.2.1.1</span> Objets: Abondance</h4>
<p>La <strong>dissimilarité de Bray-Curtis</strong> est asymétrique. Elle est aussi appelée l’indice de Steinhaus, de Czekanowski ou de Sørensen. Il est important de s’assurer de bien s’entendre la méthode à laquelle on fait référence. L’équation enlève toute ambiguité. La dissimilarité de Bray-Curtis entre les points A et B est calculée comme suit.</p>
<p><span class="math display">\[d_{AB} =  \frac {\sum \left| A_{i} - B_{i} \right| }{\sum \left(A_{i}+B_{i}\right)}\]</span></p>
<p>Utilisons <code>vegdist</code> pour générer les matrices d’association. Le format “liste” de R est pratique pour enregistrer la collection d’objets, dont les matrice d’association que nous allons créer dans cette section.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund &lt;-<span class="st"> </span><span class="kw">list</span>()
associations_abund[[<span class="st">&#39;BrayCurtis&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">vegdist</span>(abundance, <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>)
associations_abund[[<span class="st">&#39;BrayCurtis&#39;</span>]]</code></pre>
<pre><code>##           1         2         3
## 2 0.9433962                    
## 3 0.9619048 0.4400000          
## 4 0.9591837 1.0000000 0.7647059</code></pre>
<p>La dissimilarité de Bray-Curtis est souvent utilisée dans la littérature. Toutefois, la version originale de Bray-Curtis n’est pas tout à fait métrique (semimétrique). Conséquemment, la <strong>dissimilarité de Ruzicka</strong> (une variante de la dissimilarité de Jaccard pour les données d’abondance) est métrique, et devrait probablement être préféré à Bary-Curtis (<a href="http://ocw.um.es/ciencias/geobotanica/otros-recursos-1/documentos/vegantutorial.pdf">Oksanen, 2006</a>).</p>
<p><span class="math display">\[d_{AB, Ruzicka} =  \frac { 2 \times d_{AB, Bray-Curtis} }{1 + d_{AB, Bray-Curtis}}\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund[[<span class="st">&#39;Ruzicka&#39;</span>]] &lt;-<span class="st"> </span>associations_abund[[<span class="st">&#39;BrayCurtis&#39;</span>]] <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>associations_abund[[<span class="st">&#39;BrayCurtis&#39;</span>]])</code></pre>
<p>La <strong>dissimilarité de Kulczynski</strong> (aussi écrit Kulsinski) est asymétrique et semimétrique, tout comme celle de Bray-Curtis. Elle est calculée comme suit.</p>
<p><span class="math display">\[d_{AB} = 1-\frac{1}{2} \times \left[ \frac{\sum min(A_i, B_i)}{\sum A_i} + \frac{\sum min(A_i, B_i)}{\sum B_i} \right]\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund[[<span class="st">&#39;Kulczynski&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">vegdist</span>(abundance, <span class="dt">method =</span> <span class="st">&quot;kulczynski&quot;</span>)</code></pre>
<p>Une approche commune pour mesurer l’association entre sites décrits par des données d’abondance est la <strong>distance de Hellinger</strong>. Notez qu’il s’agit ici d’une distance, non pas d’une dissimilarité. Pour l’obtenir, on doit d’abord diviser chaque donnée d’abondance par l’abondance totale pour chaque site pour obtenir les espèces en tant que proportions, puis on extrait la racine carrée de chaque élément. Enfin, on calcule la distance euclidienne entre les proportions de chaque site. Pour rappel, une distance euclidienne est la généralisation en plusieurs dimensions du théorème de Pythagore, <span class="math inline">\(c = \sqrt{a^2 + b^2}\)</span>.</p>
<p><span class="math display">\[D_{AB} = \sqrt {\sum \left( \frac{A_i}{\sum A_i} - \frac{B_i}{\sum B_i} \right)^2}\]</span></p>
<table style="width:93%;">
<colgroup>
<col width="26%" />
<col width="66%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">😱 <strong>Attention</strong></td>
<td>La distance d’Hellinger hérite des biais liées aux données compositionnelles. Elle peut être substitiée par une matrice de distances d’Aitchison.</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund[[<span class="st">&#39;Hellinger&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(abundance, <span class="dt">method=</span><span class="st">&quot;hellinger&quot;</span>))</code></pre>
<p>Toute comme la distance d’Hellinger, la <strong>distance de chord</strong> est calculée par une distance euclidienne sur des données d’abondance transformées de sorte que chaque ligne ait une longueur (norme) de 1.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund[[<span class="st">&#39;Chord&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(abundance, <span class="dt">method=</span><span class="st">&quot;normalize&quot;</span>))</code></pre>
<p>La <strong>métrique du chi-carré</strong>, ou <span class="math inline">\(\chi\)</span>-carré, ou chi-square, donne davantage de poids aux espèces rares qu’aux espèces communes. Son utilisation est recommandée lorsque les espèces rares sont de bons indicateurs de conditions écologiques particulières (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>, p. 308).</p>
<p><span class="math display">\[  d_{AB} = \sqrt{\sum _j \frac{1}{\sum y_j} \left( \frac{A_j}{\sum A} - \frac{B_j}{\sum B} \right)^2 }  \]</span></p>
<p>La métrique peut être transformée en distance en la multipliant par la racine carrée de la somme totale des espèces dans la matric d’abondance (<span class="math inline">\(X\)</span>).</p>
<p><span class="math display">\[ D_{AB} = \sqrt{\sum X} \times d_{AB} \]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund[[<span class="st">&#39;ChiSquare&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(abundance, <span class="dt">method=</span><span class="st">&quot;chi.square&quot;</span>))</code></pre>
<p>Une mannière visuellement plus intéressante de présenter une matrice d’association est un graphique de type <em>heatmap</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_abund_df &lt;-<span class="st"> </span><span class="kw">list</span>()

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(associations_abund)) {
  associations_abund_df[[i]] &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">as.matrix</span>(associations_abund[[i]]))
  <span class="kw">colnames</span>(associations_abund_df[[i]]) &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_abund_df[[i]])
  associations_abund_df[[i]]<span class="op">$</span>row &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_abund_df[[i]])
  associations_abund_df[[i]] &lt;-<span class="st"> </span>associations_abund_df[[i]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(<span class="dt">key=</span>row)
  associations_abund_df[[i]]<span class="op">$</span>column =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">4</span>)
  associations_abund_df[[i]]<span class="op">$</span>dist &lt;-<span class="st"> </span><span class="kw">names</span>(associations_abund)[i]
}
associations_abund_df &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, associations_abund_df)

<span class="kw">ggplot</span>(associations_abund_df, <span class="kw">aes</span>(<span class="dt">x=</span>row, <span class="dt">y=</span>column)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>dist, <span class="dt">nrow =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(value, <span class="dv">2</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_gradient2</span>(<span class="dt">low =</span> <span class="st">&quot;#00ccff&quot;</span>, <span class="dt">mid =</span> <span class="st">&quot;#aad400&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;#ff0066&quot;</span>, <span class="dt">midpoint =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Site&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Site&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p>Peu importe le type d’association utilisée, les <em>heatmaps</em> montrent les mêmes tendances. Les assocaitions de dissimilarité (Bray-Curtis, Kulczynski et Ruzicka) s’étalent de 0 à 1, tandis que les distances (Chi-Square, Chord et Hellinger) partent de zéro, mais n’ont pas de limite supérieure. On note les plus grandes différences entre les sites 2 et 4, tandis que les sites 2 et 3 sont les plus semblables pour toutes les mesures d’association à l’exception de la dissimilarité de Kulczynski.</p>
</div>
<div id="objets-occurence-presence-absence" class="section level4">
<h4><span class="header-section-number">8.2.1.2</span> Objets: Occurence (présence-absence)</h4>
<p>Des indices d’association différents devraient être utilisés lorsque des données sont compilées sous forme booléenne. En général, les tableaux de données d’occurence seront compilés avec des 1 (présence) et des 0 (absence).</p>
<p>La <strong>similarité de Jaccard</strong> entre le site A et le site B est la proportion de double 1 (présences de 1 dans A et B) parmi les espèces. La dissimilarié est la proportion complémentaire (comprenant [1, 0], [0, 1] et [0, 0]). La distance de Jaccard est la racine carrée de la dissimilarité.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_occ &lt;-<span class="st"> </span><span class="kw">list</span>()
associations_occ[[<span class="st">&#39;Jaccard&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">vegdist</span>(occurence, <span class="dt">method =</span> <span class="st">&quot;jaccard&quot;</span>)</code></pre>
<p>Les <strong>distances d’Hellinger, de chord et de chi-carré</strong> sont aussi appropriées pour les calculs de distances sur des tableaux d’occurence.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_occ[[<span class="st">&#39;Hellinger&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(occurence, <span class="dt">method=</span><span class="st">&quot;hellinger&quot;</span>))
associations_occ[[<span class="st">&#39;Chord&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(occurence, <span class="dt">method=</span><span class="st">&quot;normalize&quot;</span>))
associations_occ[[<span class="st">&#39;ChiSquare&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">decostand</span>(occurence, <span class="dt">method=</span><span class="st">&quot;chi.square&quot;</span>))</code></pre>
<p>Graphiquement,</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_occ_df &lt;-<span class="st"> </span><span class="kw">list</span>()

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(associations_occ)) {
  associations_occ_df[[i]] &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">as.matrix</span>(associations_occ[[i]]))
  <span class="kw">colnames</span>(associations_occ_df[[i]]) &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_occ_df[[i]])
  associations_occ_df[[i]]<span class="op">$</span>row &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_occ_df[[i]])
  associations_occ_df[[i]] &lt;-<span class="st"> </span>associations_occ_df[[i]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(<span class="dt">key=</span>row)
  associations_occ_df[[i]]<span class="op">$</span>column =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dv">4</span>)
  associations_occ_df[[i]]<span class="op">$</span>dist &lt;-<span class="st"> </span><span class="kw">names</span>(associations_occ)[i]
}
associations_occ_df &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, associations_occ_df)

<span class="kw">ggplot</span>(associations_occ_df, <span class="kw">aes</span>(<span class="dt">x=</span>row, <span class="dt">y=</span>column)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>dist) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">round</span>(value, <span class="dv">2</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_gradient2</span>(<span class="dt">low =</span> <span class="st">&quot;#00ccff&quot;</span>, <span class="dt">mid =</span> <span class="st">&quot;#aad400&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;#ff0066&quot;</span>, <span class="dt">midpoint =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Site&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Site&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>Il est attendu que les matrices d’association sur l’occurence sont semblables à celles sur l’abondance. Dans ce cas-ci, la distance d’Hellinger donne des résultats semblables à la dissimilarité de Jaccard.</p>
</div>
<div id="objets-donnees-quantitatives" class="section level4">
<h4><span class="header-section-number">8.2.1.3</span> Objets: Données quantitatives</h4>
<p>Les données quantitative en écologie peuvent décrire l’état de l’environnement: le climat, l’hydrologie, l’hydrogéochimie, la pédologie, etc. En règle générale, les coordonnées des sites ne sot pas des variables environnementales, à que l’on soupçonne la coordonnée elle-même d’être responsable d’effets sur notre système: mais il s’agira la plupart du temps d’effets confondants (par exemple, on peut mesurer un effet de lattitude sur le rendement des agrumes, mais il s’agira probablement avant tout d’effets dus aux conditions climatiques, qui elles changent en fonction de la lattitude). D’autre types de données quantitative pouvant être appréhendées par des distances sont les traits phénologiques, les ionomes, les génomes, etc.</p>
<p>La <strong>distance euclidienne</strong> est la racine carrée de la somme des carrés des distances sur tous les axes. Il s’agit d’une application multidimensionnelle du théorème de Pythagore. La <strong>distance d’Aitchison</strong>, couverte dans le chapitre 6, est une distance euclidienne calculée sur des données compositionnelles préalablement transformées. La distance euclidienne est sensible aux unités utilisés: utiliser des milimètres plutôt que des mètres enflera la distance euclidienne. Il est recommandé de porter une attention particulière aux unités, et de standardiser les données au besoin (par exemple, en centrant la moyenne à zéro et en fixant l’écart-type à 1).</p>
<p>On pourrait, par exemple, mesurer la distance entre des observations des dimensions de différentes espèces d’iris. Ce tableau est inclu dans R par défaut.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(iris)
iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">5</span>)</code></pre>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
## 1          5.5         4.2          1.4         0.2     setosa
## 2          4.9         2.5          4.5         1.7  virginica
## 3          6.0         2.2          4.0         1.0 versicolor
## 4          5.7         2.8          4.5         1.3 versicolor
## 5          7.2         3.0          5.8         1.6  virginica</code></pre>
<p>Les mesures du tableau sont en centimètres. Pour éviter de donner davantage de poids aux longueur des sépales et en même temps de négliger la largeur des pétales, nous allons standardiser le tableau.</p>
<pre class="sourceCode r"><code class="sourceCode r">iris_sc &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale</span>(.)<span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>(.) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> iris<span class="op">$</span>Species) 
iris_sc</code></pre>
<pre><code>## # A tibble: 150 x 5
##    Sepal.Length Sepal.Width Petal.Length Petal.Width Species
##           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  
##  1       -0.898      1.02          -1.34       -1.31 setosa 
##  2       -1.14      -0.132         -1.34       -1.31 setosa 
##  3       -1.38       0.327         -1.39       -1.31 setosa 
##  4       -1.50       0.0979        -1.28       -1.31 setosa 
##  5       -1.02       1.25          -1.34       -1.31 setosa 
##  6       -0.535      1.93          -1.17       -1.05 setosa 
##  7       -1.50       0.786         -1.34       -1.18 setosa 
##  8       -1.02       0.786         -1.28       -1.31 setosa 
##  9       -1.74      -0.361         -1.34       -1.31 setosa 
## 10       -1.14       0.0979        -1.28       -1.44 setosa 
## # … with 140 more rows</code></pre>
<p>Pour les comparaisons des dimensions, prenons la moyenne des dimensions (mises à l’échelle) par espèce.</p>
<pre class="sourceCode r"><code class="sourceCode r">iris_means &lt;-<span class="st"> </span>iris_sc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(Species) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_all</span>(mean) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Species)
iris_means</code></pre>
<pre><code>## # A tibble: 3 x 4
##   Sepal.Length Sepal.Width Petal.Length Petal.Width
##          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;
## 1       -1.01        0.850       -1.30       -1.25 
## 2        0.112      -0.659        0.284       0.166
## 3        0.899      -0.191        1.02        1.08</code></pre>
<p>Nous pouvons utiliser la distance euclidienne, commune en géométrie, pour comparer les espèces. La distance euclidienne est calculée comme suit.</p>
<p><span class="math display">\[ \mathcal{E} = \sqrt{\Sigma_i \left( A_i - B_i \right) ^2 } \]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">associations_cont =<span class="st"> </span><span class="kw">list</span>()
associations_cont[[<span class="st">&#39;Euclidean&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">dist</span>(iris_sc <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species), <span class="dt">method=</span><span class="st">&quot;euclidean&quot;</span>)</code></pre>
<p>La <strong>distance de Mahalanobis</strong> est semblable à la distance euclidienne, mais qui tient compte de la covariance de la matrice des objets. Cette covariance peut être utilisée pour décrire la structure d’un nuage de points. La figure suivante montre deux points verts qui se trouvent aux extrêmes d’un nuage de point. Ces points ont des distances euclidiennes par rapport au centre différentes: les lignes d’équidistance euclédienne sont tracées en rose. Toutefois, les deux points ont un distance de Mahalanobis égale à partir du centre.</p>
<img src="images/07_eucl-maha.png" width=400>
<p style="text-align: center">
Source: <a href="https://www.intechopen.com/books/soil-fertility/nutrient-balance-as-paradigm-of-plant-and-soil-chemometricsnutrient-balance-as-paradigm-of-soil-and-">Parent et al. (2012)</a>.
</p>
<p>La diastance de Mahalanobis se calcule comme suit.</p>
<p><span class="math display">\[\mathcal{M} = \sqrt{(A - B)^T S^{-1} (A-B)}\]</span></p>
<p>Notez qu’il s’agit d’une généralisation de la distance euclidienne, qui équivaut à une distance de Mahalanobis dont la matrice de covariance est une matrice identité.</p>
<p>La distance de Mahalanobis permet de représenter des distances dans un espace fortement corrélé. Elle est courramment utilisée pour détecter les valeurs aberrantes selon des critères de distance à partir du centre d’un jeu de données multivariées.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_cont[[<span class="st">&#39;Mahalanobis&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">vegdist</span>(iris_sc <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species), <span class="st">&#39;mahalanobis&#39;</span>)</code></pre>
<p>La <strong>distance de Manhattan</strong> porte aussi le nom de distance de cityblock ou de taxi. C’est la distance que vous devrez parcourir pour vous rendre du point A au point B à Manhattan, c’est-à-dire selon une séquence de tronçons perpendiculaires.</p>
<p><span class="math display">\[ D_{AB} = \sum _i \left| A_i - B_i \right| \]</span></p>
<p>La distance de Manhattan est appropriée lorsque les gradients (changements d’un état à l’autre ou d’une région à l’autre) ne permettent pas des changements simultanés. Mieux vaut standardiser les variables pour éviter qu’une dimension soit prépondérante.</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_cont[[<span class="st">&#39;Manhattan&#39;</span>]] &lt;-<span class="st"> </span><span class="kw">vegdist</span>(iris_sc <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species), <span class="st">&#39;manhattan&#39;</span>)</code></pre>
<p>Graphiquement</p>
<pre class="sourceCode r"><code class="sourceCode r">associations_cont_df &lt;-<span class="st"> </span><span class="kw">list</span>()

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(associations_cont)) {
  associations_cont_df[[i]] &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">as.matrix</span>(associations_cont[[i]]))
  <span class="kw">colnames</span>(associations_cont_df[[i]]) &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_cont_df[[i]])
  associations_cont_df[[i]]<span class="op">$</span>row &lt;-<span class="st"> </span><span class="kw">rownames</span>(associations_cont_df[[i]])
  associations_cont_df[[i]] &lt;-<span class="st"> </span>associations_cont_df[[i]] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gather</span>(<span class="dt">key=</span>row)
  associations_cont_df[[i]]<span class="op">$</span>column =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(iris), <span class="kw">nrow</span>(iris))
  associations_cont_df[[i]]<span class="op">$</span>dist &lt;-<span class="st"> </span><span class="kw">names</span>(associations_cont)[i]
}
associations_cont_df &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, associations_cont_df)

<span class="kw">ggplot</span>(associations_cont_df, <span class="kw">aes</span>(<span class="dt">x=</span>row, <span class="dt">y=</span>column)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(. <span class="op">~</span><span class="st"> </span>dist) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> value), <span class="dt">colour =</span> <span class="ot">NA</span>) <span class="op">+</span>
<span class="st">  </span><span class="co">#geom_text(aes(label = round(value, 2))) +</span>
<span class="st">  </span><span class="kw">scale_fill_gradient2</span>(<span class="dt">low =</span> <span class="st">&quot;#00ccff&quot;</span>, <span class="dt">mid =</span> <span class="st">&quot;#aad400&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;#ff0066&quot;</span>, <span class="dt">midpoint =</span> <span class="dv">5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Site&quot;</span>, <span class="dt">y=</span><span class="st">&quot;Site&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Le tableau <code>iris</code> est ordonné par espèce. Les distances euclidienne et de Manhattan permettent aisément de distinguer les espèces selon les dimensions des pétales et des sépales. Toutefois, l’utilsation de la covariance avec la distance de Mahalanobis crée des distinction moins tranchées.</p>
</div>
<div id="objets-donnees-mixtes" class="section level4">
<h4><span class="header-section-number">8.2.1.4</span> Objets: Données mixtes</h4>
<p>Les données catégorielles ordinales peuvent être transformées en données continues par gradations linéaires ou quadratiques. Les données catégorielles nominales, quant à elles, peuvent être <em>dummyfiées</em> en données similaires à des occurences. Attention toutefois: contrairement à la régression linéaire qui demande d’exclure une catégorie, la <em>dummyfication</em> doit inclure toutes les catégories. Le comportement par défaut de la fonction <code>pandas.get_dummies</code> est de garder toutes les catégories. La <strong>similarité de Gower</strong> a été développée pour mesurer des associations entre des objets dont les données sont mixtes: booléennes, catégorielles et continues. La similarité de Gower est calculée en additionnant les distances calculées par colonne, individuellement. Si la colonne est booléenne, on utilise les distances de Jaccard (qui exclue les double-zéro) de manière univariée: une variable à la fois. Pour les variables continues, on utilise la distance de Manhattan divisée par la plage de valeurs de la variable (pour fin de standardisation). Puisqu’elle hérite de la particularité de la distance de Manhattan et de la similarité de Jaccard univariée, la <strong>similarité de Gower</strong> reste une combinaison linéaire de distances univariées.</p>
<pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">ID =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">8</span>,
            <span class="dt">age =</span> <span class="kw">c</span>(<span class="dv">21</span>, <span class="dv">21</span>, <span class="dv">19</span>, <span class="dv">30</span>, <span class="dv">21</span>, <span class="dv">21</span>, <span class="dv">19</span>, <span class="dv">30</span>),
            <span class="dt">gender =</span> <span class="kw">c</span>(<span class="st">&#39;M&#39;</span>,<span class="st">&#39;M&#39;</span>,<span class="st">&#39;N&#39;</span>,<span class="st">&#39;M&#39;</span>,<span class="st">&#39;F&#39;</span>,<span class="st">&#39;F&#39;</span>,<span class="st">&#39;F&#39;</span>,<span class="st">&#39;F&#39;</span>),
            <span class="dt">civil_status =</span> <span class="kw">c</span>(<span class="st">&#39;MARRIED&#39;</span>,<span class="st">&#39;SINGLE&#39;</span>,<span class="st">&#39;SINGLE&#39;</span>,<span class="st">&#39;SINGLE&#39;</span>,<span class="st">&#39;MARRIED&#39;</span>,<span class="st">&#39;SINGLE&#39;</span>,<span class="st">&#39;WIDOW&#39;</span>,<span class="st">&#39;DIVORCED&#39;</span>),
            <span class="dt">salary =</span> <span class="kw">c</span>(<span class="fl">3000.0</span>,<span class="fl">1200.0</span> ,<span class="fl">32000.0</span>,<span class="fl">1800.0</span> ,<span class="fl">2900.0</span> ,<span class="fl">1100.0</span> ,<span class="fl">10000.0</span>,<span class="fl">1500.0</span>),
            <span class="dt">children =</span> <span class="kw">c</span>(<span class="ot">TRUE</span>, <span class="ot">FALSE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">TRUE</span>, <span class="ot">FALSE</span>, <span class="ot">TRUE</span>),
            <span class="dt">available_credit =</span> <span class="kw">c</span>(<span class="dv">2200</span>,<span class="dv">100</span>,<span class="dv">22000</span>,<span class="dv">1100</span>,<span class="dv">2000</span>,<span class="dv">100</span>,<span class="dv">6000</span>,<span class="dv">2200</span>))
X</code></pre>
<pre><code>## # A tibble: 8 x 7
##      ID   age gender civil_status salary children available_credit
##   &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt; &lt;lgl&gt;               &lt;dbl&gt;
## 1     1    21 M      MARRIED        3000 TRUE                 2200
## 2     2    21 M      SINGLE         1200 FALSE                 100
## 3     3    19 N      SINGLE        32000 TRUE                22000
## 4     4    30 M      SINGLE         1800 TRUE                 1100
## 5     5    21 F      MARRIED        2900 TRUE                 2000
## 6     6    21 F      SINGLE         1100 TRUE                  100
## 7     7    19 F      WIDOW         10000 FALSE                6000
## 8     8    30 F      DIVORCED       1500 TRUE                 2200</code></pre>
<p>Il faut préalablement <em>dummifier</em> les variables catégorielles nominales.</p>
<pre class="sourceCode r"><code class="sourceCode r">X_dum &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>., X[, <span class="dv">-1</span>])
X_dum</code></pre>
<pre><code>##   age genderF genderM genderN civil_statusMARRIED civil_statusSINGLE
## 1  21       0       1       0                   1                  0
## 2  21       0       1       0                   0                  1
## 3  19       0       0       1                   0                  1
## 4  30       0       1       0                   0                  1
## 5  21       1       0       0                   1                  0
## 6  21       1       0       0                   0                  1
## 7  19       1       0       0                   0                  0
## 8  30       1       0       0                   0                  0
##   civil_statusWIDOW salary childrenTRUE available_credit
## 1                 0   3000            1             2200
## 2                 0   1200            0              100
## 3                 0  32000            1            22000
## 4                 0   1800            1             1100
## 5                 0   2900            1             2000
## 6                 0   1100            1              100
## 7                 1  10000            0             6000
## 8                 0   1500            1             2200
## attr(,&quot;assign&quot;)
##  [1] 1 2 2 2 3 3 3 4 5 6
## attr(,&quot;contrasts&quot;)
## attr(,&quot;contrasts&quot;)$gender
## [1] &quot;contr.treatment&quot;
## 
## attr(,&quot;contrasts&quot;)$civil_status
## [1] &quot;contr.treatment&quot;
## 
## attr(,&quot;contrasts&quot;)$children
## [1] &quot;contr.treatment&quot;</code></pre>
<p>Calculons la dissimilarité de Gower (cette fois le graphique est fait avec <code>pheatmap</code>).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;pheatmap&quot;</span>)
d_gow &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">vegdist</span>(X_dum, <span class="st">&#39;gower&#39;</span>))
<span class="kw">colnames</span>(d_gow) &lt;-<span class="st"> </span><span class="kw">rownames</span>(d_gow) &lt;-<span class="st"> </span>X<span class="op">$</span>ID
<span class="kw">pheatmap</span>(d_gow)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p>Les dendrogrammes apparaissants sur les axes du graphique sont issus d’un processus de partitionnement basé sur la distance, que nous verrons plus loin dans ce chapiter. Les profils des clients 4 et 7, ainsi que ceux des clients 3 et 7 diffèrent le plus. Les profils 3 et 4 sont néanmoins plutôt différents.</p>
</div>
</div>
<div id="associations-entre-variables-mode-r" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Associations entre variables (mode R)</h3>
<p>Il existe de nombreuses approches pour mesurer les associations entre variables. La plus connue est la corrélation. Mais les données d’abondance et d’occurence demandent des approches différentes.</p>
<div id="variables-abondance" class="section level4">
<h4><span class="header-section-number">8.2.2.1</span> Variables: Abondance</h4>
<p>La distance du chi-carré est suggérée par <a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">abundance_r &lt;-<span class="st"> </span><span class="kw">t</span>(abundance)
D_chisq_R &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">dist</span>(<span class="kw">decostand</span>(abundance_r, <span class="dt">method=</span><span class="st">&quot;chi.square&quot;</span>)))
<span class="kw">pheatmap</span>(D_chisq_R, <span class="dt">display_numbers =</span> <span class="kw">round</span>(D_chisq_R, <span class="dv">2</span>))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>Des coabondances sont notables pour la mésange à tête noire, le jaseur boréal, la citelle à poitrine rousse et le bruant à gorge blanche (tache bleu au centre).</p>
</div>
<div id="variables-occurence" class="section level4">
<h4><span class="header-section-number">8.2.2.2</span> Variables: Occurence</h4>
<p>La dissimilarité de Jaccard peut être utilisée.</p>
<pre class="sourceCode r"><code class="sourceCode r">occurence_r &lt;-<span class="st"> </span><span class="kw">t</span>(occurence)
D_jacc_R &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">vegdist</span>(occurence_r, <span class="dt">method =</span> <span class="st">&quot;jaccard&quot;</span>))
<span class="kw">pheatmap</span>(D_jacc_R, <span class="dt">display_numbers =</span> <span class="kw">round</span>(D_jacc_R, <span class="dv">2</span>))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p>Des cooccurences sont notables pour le jaseur boréal, la citelle à poitrine rousse et le bruant à gorge blanche (tache bleu au centre).</p>
</div>
<div id="variables-quantites" class="section level4">
<h4><span class="header-section-number">8.2.2.3</span> Variables: Quantités</h4>
<p>La matrice des corrélations de Pearson peut être utilisée pour les données continues. Quant aux variables ordinales, elles devraient idéalement être liées linéairement ou quadratiquement. Si ce n’est pas le cas, c’est-à-dire que les catégories sont ordonnées par rang seulement, vous pourrez avoir recours aux coefficients de corrélation de Spearman ou de Kendall.</p>
<pre class="sourceCode r"><code class="sourceCode r">iris_cor &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Species) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">cor</span>(.)
<span class="kw">pheatmap</span>(iris_cor, <span class="dt">cluster_rows =</span> <span class="ot">FALSE</span>, <span class="dt">cluster_cols =</span> <span class="ot">FALSE</span>,
         <span class="dt">display_numbers =</span> <span class="kw">round</span>(iris_cor, <span class="dv">2</span>))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
</div>
<div id="conclusion-sur-les-associations" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Conclusion sur les associations</h3>
<p>Il n’existe pas de règle claire pour déterminer quelle technique d’association utiliser. Cela dépend en premier lieu de vos données. Vous sélectionnerez votre méthode d’association selon le type de données que vous abordez, la question à laquelle vous désirez répondre ainsi l’expérience dans la littérature comme celle de vos collègues scientifiques. S’il n’existe pas de règle clair, c’est qu’il existe des dizaines de méthodes différentes, et la plupart d’entre elles vous donneront une perspective juste et valide. Il faut néanmoins faire attention pour éviter de sélectionner les méthodes qui ne sont pas appropriées.</p>
</div>
</div>
<div id="partitionnement" class="section level2">
<h2><span class="header-section-number">8.3</span> Partitionnement</h2>
<p>Les données suivantes ont été générées par <a href="https://github.com/scikit-learn-contrib/hdbscan/blob/master/notebooks/clusterable_data.npy">Leland McInnes</a> (Tutte institute of mathematics, Ottawa). Êtes-vous en mesure d’identifier des groupes? Combien en trouvez-vous?</p>
<pre class="sourceCode r"><code class="sourceCode r">df_mcinnes &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/clusterable_data.csv&quot;</span>, <span class="dt">col_names =</span> <span class="kw">c</span>(<span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>), <span class="dt">skip =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   x = col_double(),
##   y = col_double()
## )</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(df_mcinnes, <span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>En 2D, l’oeil humain peut facilement détecter les groupes. En 3D, c’est toujours possible, mais au-delà de 3D, le partitionnement cognitive devient rapidement maladroite. Les algorithmes sont alors d’une aide précieuse. Mais ils transportent en pratique tout un baggage de limitations. Quel est le critère d’association entre les groupes? Combien de groupe devrions-nous créer? Comment distinguer une donnée trop bruitée pour être classifiée?</p>
<p>Le partitionnement de données (<em>clustering</em> en anglais), et inversement leur regroupement, permet de créer des ensembles selon des critères d’association. On suppose donc que Le partitionnement permet de créer des groupes selon l’information que l’on fait émerger des données. Il est conséquemment entendu que les données ne sont pas catégorisées à priori: <strong>il ne s’agit pas de prédire la catégorie d’un objet, mais bien de créer des catégories à partir des objets</strong> par exemple selon leurs dimensions, leurs couleurs, leurs signature chimique, leurs comportements, leurs gènes, etc.</p>
<p>Plusieurs méthodes sont aujourd’hui offertes aux analystes pour partitionner leurs données. Dans le cadre de ce manuel, nous couvrirons ici deux grandes tendances dans les algorithmes.</p>
<ol style="list-style-type: decimal">
<li><p><em>Méthodes hiérarchique et non hiérarchiques</em>. Dans un partitionnement hiérarchique, l’ensemble des objets forme un groupe, comprenant des sous-regroupements, des sous-sous-regroupements, etc., dont les objets forment l’ultime partitionnement. On pourra alors identifier comment se décline un partitionnement. À l’inverse, un partitionnement non-hiérarchique des algorhitmes permettent de créer les groupes non hiérarchisés les plus différents que possible.</p></li>
<li><p><em>Membership exclusif ou flou</em>. Certaines techniques attribuent à chaque une classe unique: l’appartenance sera indiquée par un 1 et la non appartenance par un 0. D’autres techniques vont attribuer un membership flou où le degré d’appartenance est une variable continue de 0 à 1. Parmi les méthodes floues, on retrouve les méthodes probabilistes.</p></li>
</ol>
<div id="evaluation-dun-partitionnement" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Évaluation d’un partitionnement</h3>
<p>Le choix d’une technique de partitionnement parmi de nombreuses disponibles, ainsi que le choix des paramètres gouvernant chacune d’entre elles, est avant tout basé sur ce que l’on désire définir comme étant un groupe, ainsi que la manière d’interpréter les groupes. En outre, <strong>le nombre de groupe à départager est <em>toujours</em> une décision de l’analyste</strong>. Néanmoins, on peut se fier <a href="http://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation">des indicateurs de performance de partitionnement</a>. Parmis ceux-ci, retenons le score <a href="https://rdrr.io/cran/cluster/man/silhouette.html">silouhette</a> ainsi que l’<a href="https://www.tandfonline.com/doi/abs/10.1080/03610927408827101">indice de Calinski-Harabaz</a>.</p>
<div id="score-silouhette" class="section level4">
<h4><span class="header-section-number">8.3.1.1</span> Score silouhette</h4>
<p>En anglais, le <em>h</em> dans silouhette se trouve après le <em>l</em>: on parle donc de <em>silhouette coefficient</em> pour désigner le score de chacun des objets dans le partitionnement. Pour chaque objet, on calcule la distance moyenne qui le sépare des autres points de son groupe (<span class="math inline">\(a\)</span>) ainsi que la distance moyenne qui le sépare des points du groupe le plus rapproché.</p>
<p><span class="math display">\[s = \frac{b-a}{max \left(a, b \right)}\]</span></p>
<p>Un coefficient de -1 indique le pire classement, tandis qu’un coefficient de 1 indique le meilleur classement. La moyenne des coefficients silouhette est le score silouhette.</p>
</div>
<div id="indice-de-calinski-harabaz" class="section level4">
<h4><span class="header-section-number">8.3.1.2</span> Indice de Calinski-Harabaz</h4>
<p>L’indice de Calinski-Harabaz est proportionnel au ratio des dispersions intra-groupe et la moyenne des dispersions inter-groupes. Plus l’indice est élevé, mieux les groupes sont définis. La mathématique est décrite <a href="http://scikit-learn.org/stable/modules/clustering.html#calinski-harabaz-index">dans la documentation de scikit-learn</a>, un module d’analyse et autoapprentissage sur Python.</p>
<p><strong>Note</strong>. Les coefficients silouhette et l’indice de Calinski-Harabaz sont plus appropriés pour les formes de groupes convexes (cercles, sphères, hypersphères) que pour les formes irrégulières (notamment celles obtenues par la DBSCAN, discutée ci-desssous).</p>
</div>
</div>
<div id="partitionnement-non-hierarchique" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Partitionnement non hiérarchique</h3>
<p>Il peut arriver que vous n’ayez pas besoin de comprendre la structure d’agglomération des objets (ou variables). Plusieurs techniques de partitionnement non hiérarchique <a href="http://scikit-learn.org/stable/modules/clustering.html">sont disponibles dans le module scikit-learn</a>. On s’intéressera en particulier à celles-ci.</p>
<p><strong>Kmeans</strong>. L’objectif des kmeans est de minimiser la distance euclédienne entre un nombre prédéfini de <em>k</em> groupes exclusifs.</p>
<ol style="list-style-type: decimal">
<li>L’algorhitme commence par placer une nombre <em>k</em> de centroides au hasard dans l’espace d’un nombre <em>p</em> de variables (vous devez fixer <em>k</em>, et <em>p</em> est le nombre de colonnes de vos données).</li>
<li>Ensuite, chaque objet est étiquetté comme appartenant au groupe du centroid le plus près.</li>
<li>La position du centroide est déplacée à la moyenne de chaque groupe.</li>
<li>Recommencer à partir de l’étape 2 jusqu’à ce que l’assignation des objets aux groupes ne change plus.</li>
</ol>
<img src="https://media.giphy.com/media/12vVAGkaqHUqCQ/giphy.gif" />
<center>
Source: <a href="https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/">David Sheehan</a>
</center>
<p>La technique des kmeans suppose que les groupes ont des distributions multinormales - représentées par des cercles en 2D, des sphères en 3D, des hypersphères en plus de 3D. Cette limitation est problématique lorsque les groupes se présentent sous des formes irrégulières, comme celles du nuage de points de Leland McInnes, présenté plus haut. De plus, la technique classique des kmeans est basée sur des distances euclidiennes: l’utilisation des kmeans n’est appropriée pour les données comprenant beaucoup de zéros, comme les données d’abondance, qui devraient préalablement être transformées en variables centrées et réduites (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>). La technique des <strong>mixtures gaussiennes</strong> (<a href="https://www.stat.washington.edu/mclust/"><em>gaussian mixtures</em></a>) est une généralisation des kmeans permettant d’intégrer la covariance des groupes. Les groupes ne sont plus des hyper-sphères, mais des hyper-ellipsoïdes.</p>
<p><strong>DBSCAN</strong>. La technique DBSCAN (* <strong>D</strong>ensity-<strong>B</strong>ased <strong>S</strong>patial <strong>C</strong>lustering of <strong>A</strong>pplications with <strong>N</strong>oise<em>) sousentend que les groupes sont composés de zones où l’on retrouve plus de points (zones denses) séparées par des zones de faible densité. Pour lancer l’algorithme, nous devons spécifier une mesure d’association critique (distance ou dissimilarité) </em>d* ainsi qu’un nombre de point critique <em>k</em> dans le voisinage de cette distance.</p>
<ol style="list-style-type: decimal">
<li>L’algorithme comme étiqueter chaque point selon l’une de ces catégories:</li>
</ol>
<ul>
<li><em>Noyau</em>: le point a au moins <em>k</em> points dans son voisinage, c’est-à-dire à une distance inférieure ou égale à <em>d</em>.</li>
<li><em>Bordure</em>: le point a moins de <em>k</em> points dans son voisinage, mais l’un de des points voisins est un <em>noyau</em>.</li>
<li><em>Bruit</em>: le cas échéant. Ces points sont considérés comme des outliers.</li>
</ul>
<p><img src="images/07_dbscan_1.svg" width=600></p>
<ol start="2" style="list-style-type: decimal">
<li>Les noyaux distancés de <em>d</em> ou moins sont connectés entre eux en englobant les bordures.</li>
</ol>
<p><img src="images/07_dbscan_2.svg" width=600></p>
<p>Le nombre de groupes est prescrit par l’algorithme DBSCAN, qui permet du coup de détecter des données trop bruitées pour être classées.</p>
<p><a href="https://doi.org/10.1145/2666310.2666417">Damiani et al. (2014)</a> a développé une approche utilisant la technique DBSCAN pour partitionner des zones d’escale pour les flux de populations migratoires.</p>
<div id="application" class="section level4">
<h4><span class="header-section-number">8.3.2.1</span> Application</h4>
<p>Nous pouvons utilisé la fonction <code>kmeans</code> de R. Toutefois, puisque l’on désire ici effectuer des tests de partitionnement pour plusieurs nombres de groupes, nous utiliserons <code>cascadeKM</code>, du module vegan. Notez que de nombreux paramètres par défaut sont utilisés dans les exécutions ci-dessous. Ces notes de cours ne forment pas un travail de recherche scientifique. Lors de travaux de recherche, l’utilsation d’un argument ou d’un autre dans une fonction doit être justifié: qu’un paramètre soit utilisé par défaut dans une fonction n’est a priori pas une justification convainquante.</p>
<p>Pour les kmeans, on doit fixer le nombre de groupes. Le graphique des données de Leland McInnes montrent 6 groupes. Toutefois, il est rare que l’on puisse visualiser des démarquations aussi tranchées que celles de l’exemple, qui plus est dans des cas où l’on doit traiter de plus de deux dimensions. Je vais donc lancer le partitionnement en boucle pour plusieurs nombres de groupes, de 3 à 10 et pour chaque groupe, évaluer le score silouhette et de Calinski-Habaraz. J’utilise un argument random_state pour m’assurer que les groupes seront les mêmes à chaque fois que la cellule sera lancée.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;vegan&quot;</span>)
mcinnes_kmeans &lt;-<span class="st"> </span><span class="kw">cascadeKM</span>(df_mcinnes, <span class="dt">inf.gr =</span> <span class="dv">3</span>, <span class="dt">sup.gr =</span> <span class="dv">10</span>, <span class="dt">criterion =</span> <span class="st">&quot;calinski&quot;</span>)
<span class="kw">str</span>(mcinnes_kmeans)</code></pre>
<pre><code>## List of 4
##  $ partition: int [1:2309, 1:8] 2 2 2 2 2 2 2 2 2 2 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:2309] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr [1:8] &quot;3 groups&quot; &quot;4 groups&quot; &quot;5 groups&quot; &quot;6 groups&quot; ...
##  $ results  : num [1:2, 1:8] 85.1 2164.5 61.4 2294.6 51.4 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:2] &quot;SSE&quot; &quot;calinski&quot;
##   .. ..$ : chr [1:8] &quot;3 groups&quot; &quot;4 groups&quot; &quot;5 groups&quot; &quot;6 groups&quot; ...
##  $ criterion: chr &quot;calinski&quot;
##  $ size     : int [1:10, 1:8] 561 1243 505 NA NA NA NA NA NA NA ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr [1:10] &quot;Group 1&quot; &quot;Group 2&quot; &quot;Group 3&quot; &quot;Group 4&quot; ...
##   .. ..$ : chr [1:8] &quot;3 groups&quot; &quot;4 groups&quot; &quot;5 groups&quot; &quot;6 groups&quot; ...
##  - attr(*, &quot;class&quot;)= chr &quot;cascadeKM&quot;</code></pre>
<p>L’objet <code>mcinnes_kmeans</code>, de type <code>cascadeKM</code>, peut être visualisé directement avec la fonction <code>plot</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mcinnes_kmeans)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>On obtient un maximum de Calinski à 4 groupes, qui correspons à la deuxième simulation effectuée de 3 à 10.</p>
<p>Examinons les scoers silouhette (module: cluster).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;cluster&quot;</span>)
asw &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(mcinnes_kmeans<span class="op">$</span>partition)) {
  mcinnes_kmeans_silhouette &lt;-<span class="st"> </span><span class="kw">silhouette</span>(mcinnes_kmeans<span class="op">$</span>partition[, i], <span class="dt">dist =</span> <span class="kw">vegdist</span>(df_mcinnes, <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>))
  asw[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(mcinnes_kmeans_silhouette)<span class="op">$</span>avg.width
}
<span class="kw">plot</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">10</span>, asw, <span class="dt">type =</span> <span class="st">&#39;b&#39;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p>Le score silouhette maximum est à 3 groupes. La forme des groupes n’étant pas convexe, il fallait s’attendre à ce que indicateurs maximaux pour les deux indicateurs soient différents. C’est d’ailleurs souvent le cas. Cet exemple supporte que le choix du nombre de groupe à départager repose sur l’analyste, non pas uniquement sur les indicateurs de performance. Choisissons 6 groupes, puisque que c’est visuellement ce que l’on devrait chercher pour ce cas d’étude.</p>
<pre class="sourceCode r"><code class="sourceCode r">kmeans_group &lt;-<span class="st"> </span>mcinnes_kmeans<span class="op">$</span>partition[, <span class="dv">4</span>]
mcinnes_kmeans<span class="op">$</span>partition <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">3</span>)</code></pre>
<pre><code>##   3 groups 4 groups 5 groups 6 groups 7 groups 8 groups 9 groups 10 groups
## 1        2        3        2        4        4        6        7         5
## 2        2        3        3        1        4        4        7         5
## 3        2        4        2        4        6        6        2         1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">df_mcinnes <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">kmeans_group =</span> kmeans_group) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># ajouter une colonne de regoupement</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(kmeans_group))) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_fixed</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>L’algorithme kmeans est loin d’être statisfaisant. Cela est attendu, puisque les kmeans recherchent des distribution gaussiennes sur des groupes vraisemblablement non-gaussiens.</p>
<p>Nous pouvons créer un graphique silouhette pour nos 6 groupes. Notez qu’à cause d’un bogue, il n’est pas possible de présenter les données clairement lorsqu’elles sont nombreuses.</p>
<pre class="sourceCode r"><code class="sourceCode r">sil &lt;-<span class="st"> </span><span class="kw">silhouette</span>(mcinnes_kmeans<span class="op">$</span>partition[, <span class="dv">6</span>],
                  <span class="dt">dist =</span> <span class="kw">vegdist</span>(df_mcinnes[, ], <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>))
sil &lt;-<span class="st"> </span><span class="kw">sortSilhouette</span>(sil)
<span class="kw">plot</span>(sil, <span class="dt">col =</span> <span class="st">&#39;black&#39;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-36-1.png" width="768" /></p>
<p>La technique <strong>DBSCAN</strong> n’est pas basée sur le nombre de groupe, mais sur la densité des points. L’argument <code>x</code> ne constitue pas les données, mais une matrice d’association. L’argument minPts spécifie le nombre minimal de points qui l’on doit retrouver à une distance critique d* pour la formation des *noyaux et la propagation des groupes, spécifiée dans l’argument eps. La distance d peut être estimée en prenant une fraction de la moyenne, mais on aura volontiers recours à sont bon jugement.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;dbscan&quot;</span>)
mcinnes_dbscan &lt;-<span class="st"> </span><span class="kw">dbscan</span>(<span class="dt">x =</span> <span class="kw">vegdist</span>(df_mcinnes[, ], <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>),
                         <span class="dt">eps =</span> <span class="fl">0.03</span>, <span class="dt">minPts =</span> <span class="dv">10</span>)
dbscan_group &lt;-<span class="st"> </span>mcinnes_dbscan<span class="op">$</span>cluster
<span class="kw">unique</span>(dbscan_group)</code></pre>
<pre><code>## [1] 1 0 2 6 3 4 5</code></pre>
<p>Les paramètres spécifiés donnent 5 groupes (<code>1, 2, ..., 5</code>) et des points trop bruités pour être classifiés (étiquetés <code>0</code>). Voyons comment les groupes ont été formés.</p>
<pre class="sourceCode r"><code class="sourceCode r">df_mcinnes <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dbscan_group =</span> dbscan_group) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># ajouter une colonne de regoupement</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(dbscan_group))) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_fixed</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p>Le partitionnement semble plus conforme à ce que l’on recherche. Néanmoins, DBSCAN cré quelques petits groupes indésirables (groupe 6, en rose) ainsi qu’un grand groupe (violet) qui auraient lieu d’être partitionné. Ces défaut pourraient être réglés en jouant sur les paramètres <code>eps</code> et <code>minPts</code>.</p>
</div>
</div>
<div id="partitionnement-hierarchique" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Partitionnement hiérarchique</h3>
<p>Les techniques de partitionnement hiérarchique sont basées sur les matrices d’association. La technique pour mesurer l’association (entre objets ou variables) déterminera en grande partie le paritionnement des données. Les partitionnements hiérarchiques ont l’avantage de pouvoir être représentés sous forme de dendrogramme (ou arbre) de partition. Un tel dendrogramme présente des sous-groupes qui se joignent en groupes jusqu’à former un seul ensemble.</p>
<p>Le partitionnement hiérarchique est abondamment utilisé en phylogénie, pour étudier les relations de parenté entre organismes vivants, populations d’organismes et espèces. La phénétique, branche empirique de la phylogénèse interspécifique, fait usage du partitionnement hiérarchique à partir d’associations génétiques entre unités taxonomiques. On retrouve de nombreuses ressources académiques en phylogénétique ainsi que des outils pour <a href="https://www.springer.com/us/book/9781461495413">R</a> et <a href="https://academic.oup.com/bioinformatics/article/26/12/1569/287181/DendroPy-a-Python-library-for-phylogenetic">Python</a>. Toutefois, la phylogénétique en particulier ne fait pas partie de la présente ittération de ce manuel.</p>
<div id="techniques-de-partitionnement-hierarchique" class="section level4">
<h4><span class="header-section-number">8.3.3.1</span> Techniques de partitionnement hiérarchique</h4>
<p>Le partitionnement hiérarchique est typiquement effectué avec une des quatres méthodes suivantes, dont chacune possède ses particularités, mais sont toutes agglomératives: à chaque étape d’agglomération, on fusionne les deux groupes ayant le plus d’affinité sur la base des deux sous-groupes les plus rapprochés.</p>
<p><strong>Single link</strong> (<code>single</code>). Les groupes sont agglomérés sur la base des deux points parmi les groupes, qui sont les plus proches.</p>
<p><strong>Complete link</strong> (<code>complete</code>). À la différence de la méthode <em>single</em>, on considère comme critère d’agglomération les éléments les plus éloignés de chaque groupe.</p>
<p><strong>Agglomération centrale</strong>. Il s’agit d’une fammille de méthode basées sur les différences entre les tendances centrales des objets ou des groupes.</p>
<ul>
<li><strong>Average</strong> (<code>average</code>). Appelée UPGMA (Unweighted Pair-Group Method unsing Average), les groupes sont agglomérés selon un centre calculés par la moyenne et le nombre d’objet pondère l’agglomération (le poids des groupes est retiré). Cette technique est historiquement utilisée en bioinformatique pour partitionner des groupes phylogénétiques (<a href="https://www.cabdirect.org/cabdirect/abstract/19730310919">Sneath et Sokal, 1973</a>).</li>
<li><strong>Weighted</strong> (<code>weighted</code>). La version de average, mais non pondérée (WPGMA).</li>
<li><strong>Centroid</strong> (<code>centroid</code>). Tout comme average, mais le centroïde (centre géométrique) est utilisé au lieu de la moyenne. Accronyme: UPGMC.</li>
<li><strong>Median</strong> (<code>median</code>). Appelée WPGMC. Devinez! ;)</li>
</ul>
<p><strong>Ward</strong> (<code>ward</code>). L’optimisation vise à minimiser les sommes des carrés par regroupement.</p>
</div>
<div id="quel-outil-de-partitionnement-hierarchique-utiliser" class="section level4">
<h4><span class="header-section-number">8.3.3.2</span> Quel outil de partitionnement hiérarchique utiliser?</h4>
<p>Alors que le choix de la matrice d’association dépend des données et de leur contexte, la technique de partitionnement hiérarchique peut, quant à elle, être basée sur un critère numérique. Il en existe plusieurs, mais le critère recommandé pour le choix d’une technique de partitionnement hiérarchique est la <strong>corrélation cophénétique</strong>. La distance cophénétique est la distance à laquelle deux objets ou deux sous-groupes deviennent membres d’un même groupe. La corrélation cophénétique est la corrélation de Pearson entre le vecteur d’association des objets et le vecteur de distances cophénétiques.</p>
</div>
<div id="application-1" class="section level4">
<h4><span class="header-section-number">8.3.3.3</span> Application</h4>
<p>Les techniques de partitionnement hiérarchique présentées ci-dessus sont disponibles dans le module <code>stats</code> de R, qui est chargé automatiquement lors de l’ouversture de R. Nous allons classifier les dimensions des iris grâce à la distance de Manhattan.</p>
<pre class="sourceCode r"><code class="sourceCode r">mcinnes_hclust_distmat &lt;-<span class="st"> </span><span class="kw">vegdist</span>(df_mcinnes, <span class="dt">method =</span> <span class="st">&quot;manhattan&quot;</span>)

clustering_methods &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;single&#39;</span>, <span class="st">&#39;complete&#39;</span>, <span class="st">&#39;average&#39;</span>, <span class="st">&#39;centroid&#39;</span>, <span class="st">&#39;ward&#39;</span>)

clust_l &lt;-<span class="st"> </span><span class="kw">list</span>()
coph_corr_l &lt;-<span class="st"> </span><span class="kw">c</span>()

<span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(clustering_methods)) {
  clust_l[[i]] &lt;-<span class="st"> </span><span class="kw">hclust</span>(mcinnes_hclust_distmat, <span class="dt">method =</span> clustering_methods[i])
  coph_corr_l[i] &lt;-<span class="st"> </span><span class="kw">cor</span>(mcinnes_hclust_distmat, <span class="kw">cophenetic</span>(clust_l[[i]]))
}</code></pre>
<pre><code>## The &quot;ward&quot; method has been renamed to &quot;ward.D&quot;; note new &quot;ward.D2&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(clustering_methods, <span class="dt">coph_corr =</span> coph_corr_l) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> clustering_methods, <span class="dt">y =</span> coph_corr)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>La méthode <code>average</code> retourne la corrélation la plus élevée. Pour plus de flexibilité, enchâssons le nom de la méthode dans une variable. Ainsi, en chageant le nom de cette variable, le reste du code sera conséquent.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(clust_l) &lt;-<span class="st"> </span>clustering_methods
best_method &lt;-<span class="st"> &quot;average&quot;</span></code></pre>
<p>Le partitionnement hiérarchique peut être visualisé par un dendrogramme.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(clust_l[[best_method]])</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-41-1.png" width="1440" /></p>
</div>
<div id="combien-de-groupes-utiliser" class="section level4">
<h4><span class="header-section-number">8.3.3.4</span> Combien de groupes utiliser?</h4>
<p>La longueur des lignes verticales est la distance séparant les groupes enfants. Bien que la sélection du nombre de groupe soit avant tout basée sur les besoins du problème, nous pouvons nous appuyer sur certains outils. La hauteur totale peut servir de critère pour définir un nombre de groupes adéquat. On pourra sélectionner le nombre de groupe où la hauteur se stabilise en fonction du nombre de groupe. On pourra aussi utiliser le <em>graphique silhouette</em>, comprenant une collection de <em>largeurs de silouhette</em>, représentant le degré d’appartenance à son groupe. La fonction <code>sklearn.metrics.silhouette_score</code>, du module scikit-learn, s’en occupe.</p>
<pre class="sourceCode r"><code class="sourceCode r">asw &lt;-<span class="st"> </span><span class="kw">c</span>()
num_groups &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">:</span><span class="dv">10</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(num_groups)) {
  sil &lt;-<span class="st"> </span><span class="kw">silhouette</span>(<span class="kw">cutree</span>(clust_l[[best_method]], <span class="dt">k =</span> num_groups[i]), mcinnes_hclust_distmat)
  asw[i] &lt;-<span class="st"> </span><span class="kw">summary</span>(sil)<span class="op">$</span>avg.width
}

<span class="kw">plot</span>(num_groups, asw, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<p>Le nombre optimal de groupes serait de 5. Coupons le dendrorgamme à la hauteur correspondant à 5 groupes avec la fonction <code>cutree</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">k_opt &lt;-<span class="st"> </span>num_groups[<span class="kw">which.max</span>(asw)]
hclust_group &lt;-<span class="st"> </span><span class="kw">cutree</span>(clust_l[[best_method]], <span class="dt">k =</span> k_opt)
<span class="kw">plot</span>(clust_l[[best_method]])
<span class="kw">rect.hclust</span>(clust_l[[best_method]], <span class="dt">k =</span> k_opt)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-43-1.png" width="1440" /></p>
<p>La classification hiérarchique, uniquement basée sur la distance, peut être inappropriée pour définir des formes complexes.</p>
<pre class="sourceCode r"><code class="sourceCode r">df_mcinnes <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">hclust_group =</span> hclust_group) <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># ajouter une colonne de regoupement</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> <span class="kw">factor</span>(hclust_group))) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_fixed</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
</div>
</div>
<div id="partitionnement-hierarchique-basee-sur-la-densite-des-points" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Partitionnement hiérarchique basée sur la densité des points</h3>
<p>La tecchinque HDBSCAN, dont l’algorithme est relativement récent (<a href="https://link.springer.com/chapter/10.1007%2F978-3-642-37456-2_14">Campello et al., 2013</a>), permet une partitionnement hiérarchique sur le même principe des zones de densité de la technique DBSCAN. Le HDBSCAN a été utilisée pour partitionner les lieux d’escale d’oiseaux migrateurs en Chine (<a href="https://www.jstage.jst.go.jp/article/dsj/12/0/12_WDS-027/_article">Xu et al., 2013</a>).</p>
<p>Avec DBSCAN, un rayon est fixé dans une métrique appropriée. Pour chaque point, on compte le nombre de point voisins, c’est à dire le nombre de point se situant à une distance (ou une dissimilarité) égale ou inférieure au rayon fixé. Avec HDBSCAN, on spécifie le nombre de points devant être recouverts et on calcule le rayon nécessaire pour les recouvrir. Ainsi, chaque point est associé à un rayon critique que l’on nommera <span class="math inline">\(d_{noyau}\)</span>. La métrique initiale est ensuite altérée: on remplace les associations entre deux objets A et B par la valeur maximale entre cette association, le rayon critique de A et le rayon critique de B. Cette nouvelle distance est appelée la <em>distance d’atteinte mutuelle</em>: elle accentue les distances pour les points se trouvant dans des zones peu denses. On applique par la suite un algorithme semblable à la partition hiérarchique <em>single link</em>: En s’élargissant, les rayons se superposent, chaque superposition de rayon forment graduellement des groupes qui s’agglomèrent ainsi de manière hiérarchique. Au lieu d’effectuer une tranche à une hauteur donnée dans un dendrogramme de partitionnement, la technique HDBSCAN se base sur un dendrogramme condensé qui discarte les sous-groupes comprenant moins de <em>n</em> objets (<span class="math inline">\(n_{gr min}\)</span>). Dans nouveau dendrogramme, on recherche des groupes qui occupent bien l’espace d’analyse. Pour ce faitre, on utilise l’inverse de la distance pour créer un indicateur de <em>persistance</em> (semblable à la similarité), <span class="math inline">\(\lambda\)</span>. Pour chaque groupe hiérarchique dans le dendrogramme condensé, on peut calculer la persistance où le groupe prend naissance. De plus, pour chaque objet d’un groupe, on peut aussi calculer une distance à laquelle il quitte le groupe. La <em>stabilité</em> d’un groupe est la domme des différences de persistance entre la persistance à la naissance et les persistances des objets. On descend dans le dendrogramme. Si la somme des stabilité des groupes enfants est plus grande que la stabilité du groupe parent, on accepte la division. Sinon, le parent forme le groupe. La <a href="http://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html">documentation du module <code>hdbscan</code></a> pour Python offre une description intuitive et plus exhaustive des principes et algorithme de HDBSCAN.</p>
<div id="parametres" class="section level4">
<h4><span class="header-section-number">8.3.4.1</span> Paramètres</h4>
<p>Outre la métrique d’association dont nous avons discuté, HDBSCAN demande d’être nourri avec <a href="https://www.rdocumentation.org/packages/dbscan/versions/1.1-3/topics/hdbscan">quelques paramètres importants</a>. En particulier, le <strong>nombre minimum d’objets par groupe</strong>, <span class="math inline">\(n_{gr min}\)</span> dépend de la quantité de données que vous avez à votre disposition, ainsi que de la quantité d’objets que vous jugez suffisante pour créer des groupes. Nous utiliserons l’implémentation de HDBSCAN du module dbscan. Si vous désirez davantage d’options, vous préférerez probablement l’<a href="https://www.rdocumentation.org/packages/largeVis/versions/0.2.1.1/topics/hdbscan">implémentation du module largeVis</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mcinnes_hdbscan &lt;-<span class="st"> </span><span class="kw">hdbscan</span>(<span class="dt">x =</span> <span class="kw">vegdist</span>(df_mcinnes, <span class="dt">method =</span> <span class="st">&quot;euclidean&quot;</span>),
                           <span class="dt">minPts =</span> <span class="dv">20</span>,
                           <span class="dt">gen_hdbscan_tree =</span> <span class="ot">TRUE</span>,
                           <span class="dt">gen_simplified_tree =</span> <span class="ot">FALSE</span>)
hdbscan_group &lt;-<span class="st"> </span>mcinnes_hdbscan<span class="op">$</span>cluster
<span class="kw">unique</span>(hdbscan_group)</code></pre>
<pre><code>## [1] 6 0 4 3 5 1 2</code></pre>
<p>Nous avons 6 groupes, numérotés de 1 à 6, ainsi que des étiquettes identifiant des objets désignés comme étant du bruit de fond, numéroté 0. Le dendrogramme non condensé peu être produit.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mcinnes_hdbscan<span class="op">$</span>hdbscan_tree)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>Difficile d’y voir clair avec autant d’objets. L’objet <code>mcinnes_hdbscan</code> a un nombre minimum d’objets par groupe de 20. Ce qui permet de présenter le dendrogramme de manière condensée.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mcinnes_hdbscan)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-47-1.png" width="1440" /></p>
<p>Enfin, un aperçu des stratégies de partitionnement utilisés jusqu’ici.</p>
<pre class="sourceCode r"><code class="sourceCode r">clustering_group &lt;-<span class="st"> </span>df_mcinnes <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(kmeans_group,
         hclust_group,
         dbscan_group,
         hdbscan_group) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(<span class="op">-</span>x, <span class="op">-</span>y, <span class="dt">key =</span> <span class="st">&quot;method&quot;</span>, <span class="dt">value =</span> <span class="st">&quot;cluster&quot;</span>)</code></pre>
<pre><code>## Warning: attributes are not identical across measure variables;
## they will be dropped</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">clustering_group<span class="op">$</span>cluster &lt;-<span class="st"> </span><span class="kw">factor</span>(clustering_group<span class="op">$</span>cluster)
clustering_group <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">colour =</span> cluster)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>method, <span class="dt">ncol =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_equal</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-48-1.png" width="768" /></p>
<p>Clairement, le partitionnement avec HDBSCAN donne les meilleurs résultats.</p>
</div>
</div>
<div id="conclusion-sur-le-partitionnement" class="section level3">
<h3><span class="header-section-number">8.3.5</span> Conclusion sur le partitionnement</h3>
<p>Au chapitre 4, nous avons vu avec le jeu de données “datasaurus” que la visualisation peut permettre de détecter des structures en segmentant les données selon des groupes.</p>
<p><img src="images/07_datasaurus_mix.png" width=400></p>
<p><img src="images/07_datasaurus_facet.png"></p>
<p>Or, si les données n’étaient pas étiquetées, leur structure serait indétectable avec les algorithmes disponibles actuellement. Le partitionnement permet d’explorer des données, de détecter des tendances et de dégager des groupes permettant la prise de décision.</p>
<p>Plusieurs techniques de partitionnement ont été présentées. Le choix de la technique sera déterminante sur la manière dont les groupes seront partitionnés. La définition d’un groupe variant d’un cas à l’autre, il n’existe pas de règle pour prescrire une méthode ou une autre. La partitionnement hiérarchique a l’avantage de permetre de visualiser comment les groupes s’agglomèrent. Parmi les méthodes de partitionnement hiérarchique disponibles, les méthodes basées sur la densité permettent une grande flexibilité, ainsi qu’une détection d’observations ne faisant partie d’aucun goupe.</p>
</div>
</div>
<div id="ordination" class="section level2">
<h2><span class="header-section-number">8.4</span> Ordination</h2>
<p>En écologie, biologie, agronommie comme en foresterie, la plupart des tableaux de données comprennent de nombreuses variables: pH, nutriments, climat, espèces ou cultivars, etc. L’ordination vise à mettre de l’ordre dans des données dont le nombre élevé de variables peut amener à des difficultés d’appréciation et d’interprétaion (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>). Plus précisément, le terme ordination est utilisé en écologie pour désigner les techniques de réduction d’axe. L’analyse en composante principale est probablement la plus connue de ces techniques. Mais de nombreuses techniques d’ordination ont été développées au cours des dernières années, chacune ayant ses domaines d’application.</p>
<p>Les techniques de réduction d’axe permettent de dégager l’information la plus importante en projetant une synthèse des relations entre les observations et entre les variables. Les techniques ne supposant aucune structure <em>a priori</em> sont dites <em>non-contraignantes</em>: elles ne comprennent pas de tests statistiques. À l’inverse, les ordinations contraignantes lient des variables descriptives avec une ou plusieurs variables prédictives.</p>
<p>La référence en la matière est indiscutablement (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>). Cette section en couvrira quelques unes et vous guidera vers la technique la plus appropriée pour vos données.</p>
<div id="ordination-non-contraignante" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Ordination non contraignante</h3>
<p>Cette section couvrira l’<strong>analyse en composantes principales</strong> (ACP), l’<strong>analyse de correspondance</strong> (AC), <strong>l’analyse factorielle</strong> (AF) ainsi que l’<strong>analyse en coordonnées principales</strong> (ACoP).</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Méthode</th>
<th>Distance préservée</th>
<th>Variables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Analyse en composantes principales (ACP)</td>
<td>Distance euclidienne</td>
<td>Données quantitatives, relations linéaires (attention aux double-zéros)</td>
</tr>
<tr class="even">
<td>Analyse de correspondance (AC)</td>
<td>Distance de <span class="math inline">\(\chi^2\)</span></td>
<td>Données non-négatives, dimentionnellement homogènes ou binaires, abondance ou occurence</td>
</tr>
<tr class="odd">
<td>Positionnement multidimensionnel (PoMd)</td>
<td>Toute mesure de dissimilarité</td>
<td>Données quantitatives, qualitatives nominales/ordinales ou mixtes</td>
</tr>
</tbody>
</table>
<p>Source: Adapté de (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>, chapitre 9)</p>
<div id="analyse-en-composantes-principales" class="section level4">
<h4><span class="header-section-number">8.4.1.1</span> Analyse en composantes principales</h4>
<p>L’objectif d’une ACP est de représenter les données dans un nombre réduit de dimensions représentant le plus possible la variation d’un tableau de données: elle permet de projetter les données dans un espace où les variables sont combinées en axes orthogonaux dont le premier axe capte le maximum de variance. L’ACP peut par exemple être utilisée pour analyser des corrélations entre variables ou dégager l’information la plus pertinente d’un tableau de données météo ou de signal en un nombre plus retreint de variables.</p>
<p>L’ACP effectue est une rotation des axes à partir du centre (moyenne) du nuage de points effectuée de manière à ce que le premier axe définisse la direction où l’on retrouve la variance maximale. Ce premier axe est une combinaison linéaire des variables et forme la première composante principale. Une fois cet axe définit, on trouve de deuxième axe, orthogonal au premier, où l’on retouve la variance maximale - cet axe forme la deuxième composante principale, et ainsi de suite jusqu’à ce que le nombre d’axe corresponde au nombre de variables. Les projections des observations sur ces axes principaux sont appelés les <strong>scores</strong>. Les projections des variables sur les axes principaux sont les <strong>vecteurs propres</strong> (<em>eigenvectors</em>, ou <em>loadings</em>). La variance des composantes principales diminue de la première à la dernière, et peut être calculée comme une proportion de la variance totale: c’est le <strong>pourcentage d’inertie</strong>. Par convention, on utilise les <strong>valeurs propres</strong> (<em>eigenvalues</em>) pour mesurer l’importance des axes. Si la première composante principale a une inertie de 50% et la deuxième a une intertie de 30%, la représentation en 2D des projection représentera 80% de la variance du nuage de points.</p>
<p>L’hétérogénéité des échelles de mesure peut avoir une grande importance sur les résultats d’une ACP (les données doivent être dimensionnellement homogènes). En effet, la hauteur d’un ceriser aura une variance plus grande que le diamètre d’une cerise exprimé dans les mêmes unités, et cette dernière aura plus de variance que la teneur en cuivre d’une feuille. Il est conséquemment avisé de mettre les données à l’échelle en centrant la moyenne à zéro et l’écart-type à 1 avant de procéder à une ACP.</p>
<p>L’ACP a été conçue pour projetter en un nombre moindre de dimensions des observations dont les distributions sont multinormales. Bien que l’ACP soit une technique robuste, il est préférable de transformer préalablement les variables dont la distribution est particulièrement asymétriques (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012, p. 450</a>). Le cas échéant, les valeurs extrêmes pourraient faire dévier les vecteurs propres et biaiser l’analyse. En particulier, les données ACP menées sur des données compositionnelles sont réputées pour générer des analyses biaisées (<a href="http://sp.lyellcollection.org/content/specpubgsl/264/1/1.full.pdf">Pawlowsky-Glahn and Egozcue, 2006</a>). Le test de Mardia (<a href="https://journal.r-project.org/archive/2014-2/korkmaz-goksuluk-zararsiz.pdf">Korkmaz, 2014</a>) peut être utilisé pour tester la multinormalité. Une distribution multinormale devrait générer des scores en forme d’hypersphère (en forme de cercle sur un biplot: voir plus loin).</p>
<div id="vecteurs-propres-et-valeurs-propres" class="section level5">
<h5><span class="header-section-number">8.4.1.1.1</span> Vecteurs propres et valeurs propres</h5>
<p>Une matrice carrée (comme une matrice de covariance <span class="math inline">\(\Sigma\)</span>) multipliée par un vecteur propre <span class="math inline">\(e\)</span> est égale aux valeurs propres <span class="math inline">\(\lambda\)</span> multipliées par les vecteurs propres <span class="math inline">\(e\)</span>.</p>
<p><span class="math display">\[ \Sigma e = \lambda e \]</span></p>
<p>De manière intuitive, les vecteurs propres indiquent l’orientation de la covariance, et les valeurs propres indique la longueur associée à cette direction. L’ACP est basée sur le calcul des vecteurs propres et des valeurs propres de la matrice de covariance des variables. Pour d’abord obtenir les valeurs propres <span class="math inline">\(\lambda\)</span>, il faut résoudre l’équation</p>
<p><span class="math display">\[ det(cov(X) - \lambda I) = 0 \]</span>,</p>
<p>où <span class="math inline">\(det\)</span> est l’opération permettant de calculer le déterminant, <span class="math inline">\(cov\)</span> est l’opération pour calculer la covariance, <span class="math inline">\(X\)</span> est la matrice de données, <span class="math inline">\(\lambda\)</span> sont les valeurs propres et <span class="math inline">\(I\)</span> est une matrice d’identité.</p>
<p>Pour <span class="math inline">\(p\)</span> variables dans votre tableau <span class="math inline">\(X\)</span>, vous obtiendrex <span class="math inline">\(p\)</span> valeurs propres. Ensuite, on trouve les vecteurs propres en résolvant l’équation $ e = e $.</p>
<p>Bien qu’il soit possible d’<a href="https://www.youtube.com/watch?v=2fCBE7DWgd0&amp;list=PLBv09BD7ez_5_yapAg86Od6JeeypkS4YM">effectuer cette opération à la main</a> pour des cas très simples, vous aurez avantage à utiliser un langage de programmation.</p>
<p>Chargeons les données d’iris, puis isolons seulement les deux dimensions des sépales l’espèce <em>setosa</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>)
setosa_sepal &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(Species <span class="op">==</span><span class="st"> &quot;setosa&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;Sepal&quot;</span>))
setosa_sepal</code></pre>
<pre><code>##    Sepal.Length Sepal.Width
## 1           5.1         3.5
## 2           4.9         3.0
## 3           4.7         3.2
## 4           4.6         3.1
## 5           5.0         3.6
## 6           5.4         3.9
## 7           4.6         3.4
## 8           5.0         3.4
## 9           4.4         2.9
## 10          4.9         3.1
## 11          5.4         3.7
## 12          4.8         3.4
## 13          4.8         3.0
## 14          4.3         3.0
## 15          5.8         4.0
## 16          5.7         4.4
## 17          5.4         3.9
## 18          5.1         3.5
## 19          5.7         3.8
## 20          5.1         3.8
## 21          5.4         3.4
## 22          5.1         3.7
## 23          4.6         3.6
## 24          5.1         3.3
## 25          4.8         3.4
## 26          5.0         3.0
## 27          5.0         3.4
## 28          5.2         3.5
## 29          5.2         3.4
## 30          4.7         3.2
## 31          4.8         3.1
## 32          5.4         3.4
## 33          5.2         4.1
## 34          5.5         4.2
## 35          4.9         3.1
## 36          5.0         3.2
## 37          5.5         3.5
## 38          4.9         3.6
## 39          4.4         3.0
## 40          5.1         3.4
## 41          5.0         3.5
## 42          4.5         2.3
## 43          4.4         3.2
## 44          5.0         3.5
## 45          5.1         3.8
## 46          4.8         3.0
## 47          5.1         3.8
## 48          4.6         3.2
## 49          5.3         3.7
## 50          5.0         3.3</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;MVN&quot;</span>)</code></pre>
<pre><code>## sROC 0.1-2 loaded</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">setosa_sepal_mvn &lt;-<span class="st"> </span><span class="kw">mvn</span>(setosa_sepal, <span class="dt">mvnTest =</span> <span class="st">&quot;mardia&quot;</span>)
setosa_sepal_mvn<span class="op">$</span>multivariateNormality</code></pre>
<pre><code>##              Test          Statistic           p value Result
## 1 Mardia Skewness  0.759503524380438 0.943793240544741    YES
## 2 Mardia Kurtosis 0.0934600553610254 0.925538081956867    YES
## 3             MVN               &lt;NA&gt;              &lt;NA&gt;    YES</code></pre>
<p>Pour considérer la distribution comme multinormale, la p-value de la distortion (<code>Mardia Skewness</code>) <strong>et</strong> la statistique de Kurtosis (<code>Mardia Kurtosis</code>) doit être égale ou plus élevée que 0.05 (<a href="https://www.rdocumentation.org/packages/MVN/versions/5.6/topics/mvn">Kormaz, 2019, fiche d’aide de la fonction <code>mvn</code> de R</a>). C’est bien le cas pour les données du tableau <code>setosa_sepal</code>.</p>
<p>Retirons de la matrice de covariance les valeurs et vecteurs propres avec la fonction <code>eigen</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">setosa_eigen &lt;-<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">cov</span>(setosa_sepal))
setosa_eigenval &lt;-<span class="st"> </span>setosa_eigen<span class="op">$</span>values
setosa_eigenvec &lt;-<span class="st"> </span>setosa_eigen<span class="op">$</span>vectors</code></pre>
<p>Le premier vecteur propre correspond à la première colonne, et le second à la deuxième. Les coordonnées x et y sont les premières et deuxièmes lignes. Les vecteurs propres ont une longueur unitaire (norme de 1). Ils peuvent être mis à l’échelles à la racine carrée des valeurs propres.</p>
<pre class="sourceCode r"><code class="sourceCode r">setosa_eigenvec_sc &lt;-<span class="st"> </span>setosa_eigenvec <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(<span class="kw">sqrt</span>(setosa_eigen<span class="op">$</span>values))</code></pre>
<p>Pour effectuer une translation des vecteurs propres au centre du nuage de point, nous avons besoin du centroïde.</p>
<pre class="sourceCode r"><code class="sourceCode r">centroid &lt;-<span class="st"> </span>setosa_sepal <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">apply</span>(., <span class="dv">2</span>, mean)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(setosa_sepal, <span class="dt">asp =</span> <span class="dv">1</span>)

<span class="co"># vecteurs propres brutes</span>
<span class="kw">lines</span>(<span class="dt">x=</span><span class="kw">c</span>(centroid[<span class="dv">1</span>], centroid[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec[<span class="dv">1</span>, <span class="dv">1</span>]),
      <span class="dt">y=</span><span class="kw">c</span>(centroid[<span class="dv">2</span>], centroid[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec[<span class="dv">2</span>, <span class="dv">1</span>]), <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>) <span class="co"># vecteur propre 1</span>
<span class="kw">lines</span>(<span class="dt">x=</span><span class="kw">c</span>(centroid[<span class="dv">1</span>], centroid[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec[<span class="dv">1</span>, <span class="dv">2</span>]),
      <span class="dt">y=</span><span class="kw">c</span>(centroid[<span class="dv">2</span>], centroid[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec[<span class="dv">2</span>, <span class="dv">2</span>]), <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, <span class="dt">lwd =</span> <span class="dv">3</span>) <span class="co"># vecteur propre 1</span>

<span class="co"># vecteurs propres à l&#39;échelle</span>
<span class="kw">lines</span>(<span class="dt">x=</span><span class="kw">c</span>(centroid[<span class="dv">1</span>], centroid[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec_sc[<span class="dv">1</span>, <span class="dv">1</span>]),
      <span class="dt">y=</span><span class="kw">c</span>(centroid[<span class="dv">2</span>], centroid[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec_sc[<span class="dv">2</span>, <span class="dv">1</span>]), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">4</span>) <span class="co"># vecteur propre 1</span>
<span class="kw">lines</span>(<span class="dt">x=</span><span class="kw">c</span>(centroid[<span class="dv">1</span>], centroid[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec_sc[<span class="dv">1</span>, <span class="dv">2</span>]),
      <span class="dt">y=</span><span class="kw">c</span>(centroid[<span class="dv">2</span>], centroid[<span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>setosa_eigenvec_sc[<span class="dv">2</span>, <span class="dv">2</span>]), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">4</span>) <span class="co"># vecteur propre 1</span>

<span class="kw">points</span>(<span class="dt">x=</span>centroid[<span class="dv">1</span>], <span class="dt">y=</span>centroid[<span class="dv">2</span>], <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">cex =</span> <span class="dv">2</span>, <span class="dt">col  =</span><span class="st">&quot;blue&quot;</span>) <span class="co"># centroid</span></code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p>On peut observer que, comme je l’ai mentionné plus haut, <strong>les vecteurs propres indiquent l’orientation de la covariance, et les valeurs propres indique la longueur associée à cette direction</strong>.</p>
</div>
<div id="biplot" class="section level5">
<h5><span class="header-section-number">8.4.1.1.2</span> Biplot</h5>
<p>Imaginez un nuage de points en 3D, axes y compris. Vous tournez votre nuage de points pour trouver la perspective en 2D qui fera en sorte que vos données soient les plus dispersées possibles. Avec une lampe de poche, vous illuminez votre nuage de points dans l’axe de cette perspective: vous venez d’effectuer une analyse en composantes principales, et l’ombre des points et des axes sur le mur formera votre biplot.</p>
<p>Pour créer un biplot, on juxtapose les descripteurs (variables) en tant que vecteurs propres, représentés par des flèches, et les objets (observations) en tant que scores, représentés par des points. Les résultats d’une ordination peuvent être présentés selon deux types de biplots (<a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Legendre et Legendre, 2012</a>).</p>
<p><img src="images/07_bipolot-meteo-sc2.svg" /></p>
<center>
Biplot de corrélation permettant de visualiser les corrélations entre des variables météorologiques. Source: <a href="">Parent, 2017</a>
</center>
<p>Deux types de projection sont courramment utilisés.</p>
<p><strong>Biplot de distance</strong>. Ce type de projection permet de visualiser la position des objets entre eux et par rapport aux descripteurs et d’apprécier la contribution des descripteurs pour créer les composantes principales. Pour créer un biplot de distance, on projette directement les vecteurs propres (<span class="math inline">\(U\)</span>) en guise de descripteurs. Pour ce qui est des objets, on utilise les scores de l’ACP (<span class="math inline">\(F\)</span>). De cette manière,</p>
<ol style="list-style-type: decimal">
<li>les distances euclidiennes entre les scores sont des approximations des distances euclidiennes dans l’espace multidimentionnel,</li>
<li>la projection d’un objet sur un descripteur perpendiculairement à ce dernier est une approximation de la position de l’objet sur le descripteur et</li>
<li>la projection d’un descripteur sur un axe principal est proportionnelle à sa contribution pour générer l’axe.</li>
</ol>
<p><strong>Biplot de corrélation</strong>. Cette projection permet d’apprécier les corrélations entre les descripteurs. Pour ce faire, les objets et les valeurs propres doivent être transformés. Pour générer les descripteurs, les vecteurs propres (<span class="math inline">\(U\)</span>) doivent être multipliés par la matrice diagonalisée de la racine carrée des valeurs propres (<span class="math inline">\(\Lambda\)</span>), c’est-à-dire <span class="math inline">\(U \Lambda ^{\frac{1}{2}}\)</span>. En ce qui a trait aux objets, on multiplie les scores par (<span class="math inline">\(F\)</span>) par la racine carrée négative des valeurs propres diagonalisées, c’est-à-dire <span class="math inline">\(F \Lambda ^{- \frac{1}{2}}\)</span>. De cette manière,</p>
<ol style="list-style-type: decimal">
<li>tout comme c’est le cas pour le biplot de distance, la projection d’un objet sur un descripteur perpendiculairement à ce dernier est une approximation de la position de l’objet sur le descripteur,</li>
<li>la projection d’un descripteur sur un axe principal est proportionnelle à son écart-type et</li>
<li>les <strong>angles</strong> entre les descripteurs sont proportionnelles à leur corrélation (et non pas leur proximité).</li>
</ol>
<p>En d’autres mots, le bilot de distances devrait être utilisé pour apprécier la distance entre les objets et le biplot de corrélation devrait être utilisé pour apprécier les corrélations entre les descripteurs. Mais dans tous les cas, <strong>le type de biplot utilisé doit être indiqué</strong>.</p>
<p>Le <em>triplot</em> est une forme apparentée au biplot, auquel on ajoute des variables prédictives. Le triplot est utile pour représenter les résultats des ordinations contraignantes comme les analyses de redondance et les analyse de correspondance canoniques.</p>
</div>
<div id="application-2" class="section level5">
<h5><span class="header-section-number">8.4.1.1.3</span> Application</h5>
<p>Bien que l’ACP puisse être effectuée grâce à des modules de base de R, nous utiliserons le module vegan. Le tableau <a href="https://rdrr.io/rforge/vegan/man/varechem.html"><code>varechem</code></a> comprend des données issues d’analyse de sols identifiés par leur composition chimique, leur pH, leur profondeur totale et la profondeur de l’humus publiées dans <a href="http://onlinelibrary.wiley.com/doi/10.2307/3236351/abstract">Väre et al. (1995)</a> et exportées du module <a href="https://rdrr.io/rforge/vegan/">vegan</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;vegan&quot;</span>)
<span class="kw">data</span>(<span class="st">&quot;varechem&quot;</span>)
varechem <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">5</span>)</code></pre>
<pre><code>##      N    P     K    Ca    Mg    S    Al   Fe    Mn   Zn  Mo Baresoil
## 1 22.8 50.6 151.7 648.0  64.8 30.2  12.1  2.3 122.9  8.1 0.2     23.7
## 2 19.1 26.4  61.1 259.1  37.0 21.4 155.1 81.4  20.6  4.0 0.6      5.8
## 3 26.2 61.9 202.2 741.2  86.3 48.6 124.3 23.6  94.5 10.2 0.6     56.9
## 4 23.8 54.5 180.6 777.0 125.8 39.5  24.2  3.0  50.1  6.6 0.3     46.0
## 5 24.2 31.0 138.2 394.6  45.3 27.1  74.2  9.8  24.4  5.2 0.3     29.8
##   Humdepth  pH
## 1      2.6 2.9
## 2      1.9 3.0
## 3      2.5 2.9
## 4      3.0 2.7
## 5      2.0 2.8</code></pre>
<p>Comme nous l’avons vu précdemment, les données de concentration sont de type <em>compositionnelles</em>. Les données compositionnelles du tableau <code>varechem</code> mériteraient d’être transformées (<a href="http://doi.wiley.com/10.1111/1467-9876.00275">Aitchison et Greenacre, 2002</a>). Utilisons les log-ratios centrés (<em>clr</em>).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;compositions&quot;</span>)</code></pre>
<pre><code>## Loading required package: tensorA</code></pre>
<pre><code>## 
## Attaching package: &#39;tensorA&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     norm</code></pre>
<pre><code>## Loading required package: robustbase</code></pre>
<pre><code>## Loading required package: energy</code></pre>
<pre><code>## Loading required package: bayesm</code></pre>
<pre><code>## Welcome to compositions, a package for compositional data analysis.
## Find an intro with &quot;? compositions&quot;</code></pre>
<pre><code>## 
## Attaching package: &#39;compositions&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, cov, dist, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     %*%, scale, scale.default</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">varecomp &lt;-<span class="st"> </span>varechem <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Baresoil, <span class="op">-</span>Humdepth, <span class="op">-</span>pH) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Fv =</span> <span class="kw">apply</span>(., <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fl">1e6</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(x)))
vareclr &lt;-<span class="st"> </span>varecomp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">acomp</span>(.) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">clr</span>(.) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(varechem <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">select</span>(Baresoil, Humdepth, pH))</code></pre>
<pre><code>## Warning: Calling `as_tibble()` on a vector is discouraged, because the behavior is likely to change in the future. Use `enframe(name = NULL)` instead.
## This warning is displayed once per session.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">vareclr <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">5</span>)</code></pre>
<pre><code>## # A tibble: 5 x 15
##        N        P     K    Ca      Mg      S     Al     Fe     Mn    Zn
##    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 -1.49  -1.12    0.923  1.47 -0.0470 -0.728  0.973 -0.126 -0.703 -2.62
## 2 -0.901  0.00174 1.27   2.32  0.361  -0.546 -1.41  -3.42   0.374 -2.07
## 3 -0.881 -0.648   0.723  2.26  0.384  -0.825 -0.347 -2.15  -0.611 -2.26
## 4 -0.871 -0.623   0.872  1.92 -0.244  -0.757  0.250 -1.77  -0.862 -2.41
## 5 -0.920 -0.123   0.975  2.43  0.125  -0.639 -1.55  -3.21   0.765 -1.95
## # … with 5 more variables: Mo &lt;dbl&gt;, Fv &lt;dbl&gt;, Baresoil &lt;dbl&gt;,
## #   Humdepth &lt;dbl&gt;, pH &lt;dbl&gt;</code></pre>
<p>Effectuons l’ACP. Pour cet exemple, nous standardiserons les données étant données que les colonnes Baresoil, Humedepth et pH ne sont pas à la même échelle que les colonnes des clr.</p>
<pre class="sourceCode r"><code class="sourceCode r">vareclr_sc &lt;-<span class="st"> </span><span class="kw">scale</span>(vareclr)
vare_pca &lt;-<span class="st"> </span><span class="kw">rda</span>(vareclr_sc) <span class="co"># ou bien rda(vareclr, scale = TRUE, mais la mise à l&#39;échelle préalable est plus explicite)</span></code></pre>
<p>L’objet <code>vareclr_pca</code> contient l’information nécessaire pour mener notre ACP.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(vare_pca, <span class="dt">scaling =</span> <span class="dv">2</span>) <span class="co"># scaling = 2 pour obtenir les infos pour les biplots de corrélation</span></code></pre>
<pre><code>## 
## Call:
## rda(X = vareclr_sc) 
## 
## Partitioning of variance:
##               Inertia Proportion
## Total              15          1
## Unconstrained      15          1
## 
## Eigenvalues, and their contribution to the variance 
## 
## Importance of components:
##                          PC1    PC2    PC3     PC4     PC5     PC6     PC7
## Eigenvalue            7.1523 2.4763 2.1122 0.93015 0.57977 0.48786 0.36646
## Proportion Explained  0.4768 0.1651 0.1408 0.06201 0.03865 0.03252 0.02443
## Cumulative Proportion 0.4768 0.6419 0.7827 0.84473 0.88338 0.91590 0.94034
##                           PC8     PC9    PC10     PC11     PC12     PC13
## Eigenvalue            0.29432 0.19686 0.15434 0.107357 0.095635 0.042245
## Proportion Explained  0.01962 0.01312 0.01029 0.007157 0.006376 0.002816
## Cumulative Proportion 0.95996 0.97308 0.98337 0.990527 0.996902 0.999719
##                            PC14
## Eigenvalue            0.0042200
## Proportion Explained  0.0002813
## Cumulative Proportion 1.0000000
## 
## Scaling 2 for species and site scores
## * Species are scaled proportional to eigenvalues
## * Sites are unscaled: weighted dispersion equal on all dimensions
## * General scaling constant of scores:  4.309777 
## 
## 
## Species scores
## 
##              PC1     PC2     PC3      PC4        PC5       PC6
## N         0.1437  0.7606 -0.6792  0.19837  0.1128526 -0.050149
## P         0.8670 -0.3214 -0.2950 -0.22940  0.1437960 -0.042884
## K         0.9122 -0.3857  0.2357  0.03469  0.2737020  0.075717
## Ca        0.9649 -0.3362 -0.2147  0.17757 -0.2188717  0.008051
## Mg        0.8263 -0.2723  0.1035  0.52135 -0.1495399 -0.342214
## S         0.8825 -0.3169  0.3539 -0.21216  0.1176279 -0.191386
## Al       -1.0105 -0.2442  0.2146  0.02674 -0.1005560 -0.043569
## Fe       -1.0338 -0.2464  0.1492  0.13162  0.1512218  0.081571
## Mn        0.9556  0.1041 -0.1256 -0.21300  0.2565831  0.275275
## Zn        0.7763 -0.1031 -0.3123 -0.36493 -0.5665691  0.153089
## Mo       -0.2152  0.8717  0.4065 -0.33643 -0.2134335 -0.167725
## Fv        0.2360  0.5776 -0.8112  0.12736  0.1280097 -0.109737
## Baresoil  0.5147  0.4210  0.4472  0.54980 -0.1438570  0.463148
## Humdepth  0.7455  0.4379  0.5194  0.16493  0.0004757 -0.273056
## pH       -0.5754 -0.5864 -0.5957  0.23408 -0.1517661 -0.056641
## 
## 
## Site scores (weighted sums of species scores)
## 
##            PC1       PC2      PC3      PC4      PC5      PC6
## sit1   0.16862  0.423777  0.46731  0.91175  1.10380  1.06421
## sit2  -0.09705 -0.097482  0.61143 -0.29049  1.14916  0.40622
## sit3   0.02831 -0.795737  0.74176 -0.19097 -2.43337 -0.81762
## sit4   1.39081 -0.354376 -0.19377 -0.45160  0.46020 -0.31446
## sit5   1.30346  0.357866  0.29887  0.76856  0.20913 -0.64145
## sit6   0.43636  0.495037  1.21722  1.18128 -0.98242 -0.74474
## sit7   1.07306  0.467575 -0.32245  0.03717  0.13956 -0.64972
## sit8   0.02545  0.659714 -0.28861 -0.01424  0.47105  0.45173
## sit9   1.42005  0.007356 -0.29000 -0.78474  0.97592 -0.80263
## sit10 -0.50638 -0.220909  1.52981  0.26289  0.42135  0.94054
## sit11  0.45392  0.649297  0.44573 -0.26620 -0.74522 -0.53228
## sit12  0.18623  0.259640  0.89112  0.21096 -0.51393  2.24361
## sit13  1.26264  0.225744 -0.96668 -0.69334  0.61990  0.43312
## sit14 -1.48685  0.739545 -0.20926  1.09256  0.61856 -0.87999
## sit15 -0.50622  1.108685 -2.61287 -1.00433 -1.35383  1.21964
## sit16 -1.28653  0.898663 -0.38778 -0.47556 -0.02449 -0.29419
## sit17 -1.72773  0.476962 -0.48878  0.71156  1.06398 -1.33473
## sit18 -0.82844 -0.296515  1.20315 -1.49821 -0.18330  1.05231
## sit19 -1.00247 -0.609253  0.25185 -0.85420  0.71031  0.14854
## sit20 -0.43405 -0.338912  0.55348 -1.35776 -0.81986 -1.02468
## sit21 -0.05083  0.122645 -0.04611 -0.56047 -0.26151 -0.98053
## sit22  0.17891 -2.315489 -0.69084 -0.19547  0.80628  0.04291
## sit23 -0.46443 -2.592018 -1.21615  1.56359 -0.62334  0.28748
## sit24  0.46316  0.728185 -0.49843  1.89726 -0.80791  0.72671</code></pre>
<p>La deuxième ligne de <code>Importance of components</code>, <code>Proportion Explained</code>, indique la proportion de la variance totale captée successivement par les axes principaux. Le premier axe principal comporte 47.68% de la variance. Le deuxième axe principal ajoutant une proportion de 16,51%, une représentation en deux axes principaux présentent 64.19 % de la variance.</p>
<pre class="sourceCode r"><code class="sourceCode r">prop_expl &lt;-<span class="st"> </span>vare_pca<span class="op">$</span>CA<span class="op">$</span>eig <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig)
prop_expl</code></pre>
<pre><code>##          PC1          PC2          PC3          PC4          PC5 
## 0.4768180610 0.1650859388 0.1408156459 0.0620101490 0.0386511040 
##          PC6          PC7          PC8          PC9         PC10 
## 0.0325238535 0.0244303815 0.0196215021 0.0131238464 0.0102890284 
##         PC11         PC12         PC13         PC14 
## 0.0071571089 0.0063756951 0.0028163495 0.0002813359</code></pre>
<p>La décision du nombre d’axes principaux à retenir est arbitraire. Elle peut dépendre d’un nombre maximal de paramètre à retenir pour éviter de surdimensionner un modèle (<em>curse of dimensionality</em>, section 11) ou d’un seuil de pourcentage de variance minimal à retenir, par exemple 75%. Ou bien, vous retiendrez deux composantes principales si vous désirez présenter un seul biplot.</p>
<p>L’approche de <em>Kaiser-Guttmann</em> (<a href="http://www.springer.com/us/book/9781441979759">Borcard et al., 2011</a>) consiste à sélectionner les composantes principales dont la valeur propre est supérieure à leur moyenne.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig),
     <span class="dt">y =</span> vare_pca<span class="op">$</span>CA<span class="op">$</span>eig,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="kw">mean</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p>L’approche du <em>broken stick</em> consiste à couper un bâton d’une longueur de 1 en n tranches. La première tranche est de longueur <span class="math inline">\(\frac{1}{n}\)</span>. La tranche suivante est d’une longueur de la tranche précédente à laquelle on aditionne <span class="math inline">\(\frac{1}{longueur~restante}\)</span>. Puis on place les longueurs en ordre décroissant. On retient les composantes principales dont les valeurs propres cumulées sont plus grandes que le broken stick.</p>
<pre class="sourceCode r"><code class="sourceCode r">broken_stick &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  bsm &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="dt">length =</span> x)
  bsm[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>x
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>x) {
    bsm[i] &lt;-<span class="st"> </span>bsm[i<span class="dv">-1</span>] <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>(x<span class="op">+</span><span class="dv">1</span><span class="op">-</span>i)
  }
  bsm &lt;-<span class="st"> </span><span class="kw">rev</span>(bsm<span class="op">/</span>x)
  <span class="kw">return</span>(bsm)
}</code></pre>
<p>Le graphique du <em>broken stick</em>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig),
     <span class="dt">y =</span> prop_expl,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>)
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig),
      <span class="dt">y =</span> <span class="kw">broken_stick</span>(<span class="kw">length</span>(vare_pca<span class="op">$</span>CA<span class="op">$</span>eig)),
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>,
      <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-62-1.png" width="672" /></p>
<p>Les approches <em>Kaiser-Guttmann</em> et <em>broken stick</em> suggèrent que les trois premières composantes sont suffisantes pour décrire la dispersion des données.</p>
<p>Examinons les loadings (vecteurs propres) plus en particulier. Dans le langage du module vegan, les vecteurs propres sont les espèces (<code>species</code>) et les scores sont les <code>sites</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">vare_eigenvec &lt;-<span class="st"> </span><span class="kw">scores</span>(vare_pca, <span class="dt">scaling =</span> <span class="dv">2</span>, <span class="dt">display =</span> <span class="st">&quot;species&quot;</span>, <span class="dt">choices =</span> <span class="dv">1</span><span class="op">:</span>(<span class="kw">ncol</span>(vareclr)<span class="op">-</span><span class="dv">1</span>))
vare_eigenvec</code></pre>
<pre><code>##                 PC1        PC2        PC3        PC4           PC5
## N         0.1437343  0.7606006 -0.6792046  0.1983670  0.1128526122
## P         0.8669892 -0.3213683 -0.2949864 -0.2294036  0.1437959857
## K         0.9122089 -0.3857245  0.2356904  0.0346904  0.2737019601
## Ca        0.9648855 -0.3361651 -0.2147486  0.1775746 -0.2188716732
## Mg        0.8263327 -0.2723055  0.1035276  0.5213484 -0.1495399242
## S         0.8824519 -0.3169039  0.3538854 -0.2121562  0.1176278503
## Al       -1.0105173 -0.2441785  0.2145614  0.0267422 -0.1005559874
## Fe       -1.0337676 -0.2463987  0.1491865  0.1316173  0.1512218115
## Mn        0.9555632  0.1041030 -0.1256178 -0.2130047  0.2565830557
## Zn        0.7763480 -0.1030878 -0.3122919 -0.3649341 -0.5665691228
## Mo       -0.2152399  0.8717229  0.4064967 -0.3364279 -0.2134335302
## Fv        0.2360040  0.5775863 -0.8111953  0.1273582  0.1280096553
## Baresoil  0.5147445  0.4209983  0.4472351  0.5497950 -0.1438569673
## Humdepth  0.7455213  0.4379436  0.5193895  0.1649306  0.0004756685
## pH       -0.5753858 -0.5863743 -0.5957495  0.2340826 -0.1517660977
##                   PC6         PC7         PC8          PC9        PC10
## N        -0.050148980 -0.09111164 -0.06122008  0.315645453  0.08090232
## P        -0.042883754  0.26894062  0.34111276  0.021124287  0.08756299
## K         0.075717162 -0.21662612 -0.01641260  0.143099440 -0.08737113
## Ca        0.008050762  0.03630015  0.04775616 -0.073609828 -0.10601799
## Mg       -0.342213793  0.04617838 -0.12098602 -0.051599273  0.18373857
## S        -0.191386377 -0.26825994  0.15822845  0.038378858  0.05100717
## Al       -0.043569364 -0.22737412  0.10598673  0.040586196 -0.14473132
## Fe        0.081571443  0.10553041 -0.09254655 -0.079426433  0.09908706
## Mn        0.275275174  0.20224538 -0.19347804 -0.038859808 -0.07637994
## Zn        0.153089144 -0.12332232 -0.14862229  0.024026151  0.02643462
## Mo       -0.167725160  0.13788948  0.17165900  0.032981311  0.01419924
## Fv       -0.109737235 -0.20911147  0.11289753 -0.281443886 -0.08391004
## Baresoil  0.463148072 -0.02103009  0.23028292  0.004554036  0.02604286
## Humdepth -0.273056212  0.17061078 -0.11310394  0.027515405 -0.23068827
## pH       -0.056640816  0.19890884  0.12152266  0.150118818 -0.15240317
##                  PC11         PC12        PC13         PC14
## N        -0.019251478  0.045420621  0.05020956  0.002340519
## P        -0.045741546  0.145128883 -0.03337551 -0.010109130
## K         0.183005607  0.002260341 -0.10566808  0.001169065
## Ca        0.161460554  0.041210064  0.14341793  0.007419161
## Mg       -0.009862571 -0.063493608 -0.03782662 -0.023575986
## S        -0.138785063 -0.117144869  0.06075094  0.025874035
## Al       -0.089462074  0.058212507  0.01983102 -0.037901576
## Fe       -0.006376211  0.049837173 -0.01169516  0.036048221
## Mn       -0.083300112 -0.133353213  0.02679781 -0.021373612
## Zn       -0.064973307  0.051057277 -0.06538348  0.010896560
## Mo        0.128814989 -0.114803631 -0.01989539 -0.001335923
## Fv       -0.012456867 -0.020157331 -0.05448619  0.005707928
## Baresoil -0.061147847 -0.019696758 -0.01640490  0.003823725
## Humdepth -0.102189307  0.109293684 -0.02485030  0.016559206
## pH       -0.037691048 -0.153813168 -0.04523353  0.014193061
## attr(,&quot;const&quot;)
## [1] 4.309777</code></pre>
<p>L’ordre d’importance des vecteurs propres est établi en ordre croissant des élément des vecteurs propres associées. Un vecteur propre est une combinaison linéaire des variables. Par exemple, le premier vecteur propre pointe surtout dans la direction du Fe (-1.497) et de l’Al (-1.463). Le deuxième pointe surtout vers le Mo (2.145). Les vecteurs (<em>loadings</em>) d’un biplot de distance présentant les des deux premières composantes principales prendront les coordonnées des deux premières colonnes. Le vecteur Al aura la coordonnée [-1.463 ; -0.601], le vecteur de Fe sera placé à [-1.497 ; -0.606] et le vecteur Mo à [-0.312 ; 2.145]. Il existe différentes fonctions d’affichage des biplots. Notez que leur longueur peut être magnifiée pour améliorer la visualisation.</p>
<p>Lançons la fonction <code>biplot</code> pour créer un biplot de distance et un autre de corrélation.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">biplot</span>(vare_pca, <span class="dt">scaling =</span> <span class="dv">1</span>, <span class="dt">main =</span> <span class="st">&quot;Biplot de distance&quot;</span>)
<span class="kw">biplot</span>(vare_pca, <span class="dt">scaling =</span> <span class="dv">2</span>, <span class="dt">main =</span> <span class="st">&quot;Biplot de corrélation&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Le biplot de distance permet de dégager les variables qui expliquent davantage la variabilité dans notre tableau: les clr du Fe et de l’Al forment en grande partie le premier axe principal, alors que le clr du Mo forme en grande partie le second axe. Le biplot de corrélation montre que les clr du Fe et du Al sont corrélés dans le même sens, mais das le sens contraire du clr du Mn. L’information sur la teneur en Fe et celle de l’Al est en grande partie redondante. Toutefois, le clr du Mo est presque indépendant du clr du Fe, ceux-ci étant à angle presque droit (~90°). Ces relations peuvent être explorées directement.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(vareclr<span class="op">$</span>Al, vareclr<span class="op">$</span>Fe)
<span class="kw">plot</span>(vareclr<span class="op">$</span>Mo, vareclr<span class="op">$</span>Fe)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-65-1.png" width="672" /></p>
<p>Nous avons mentionné que l’ACP est une rotation. Prenons un second exemple pour bien en saisir les tenants et aboutissants. Le tableau de données que nous chargerons provient d’un infographie d’un dauphin, intitullée <em>Bottlenose Dolphin</em>, conçu par l’artiste <a href="https://www.blendswap.com/blends/view/83681">Tarnyloo</a>. Les points correspondent à la surface d’un dauphin. J’ai ajouté une colonne <code>anatomy</code>, qui indique à quelle partie anatomique le point appartient.</p>
<pre class="sourceCode r"><code class="sourceCode r">dolphin &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/07_dolphin.csv&quot;</span>)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   x = col_double(),
##   y = col_double(),
##   z = col_double(),
##   anatomy = col_character()
## )</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">dolphin <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">5</span>)</code></pre>
<pre><code>## # A tibble: 5 x 4
##          x      y       z anatomy   
##      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     
## 1  0.0326  -0.673 -0.137  Head      
## 2  0.173   -0.324 -0.0259 Head      
## 3 -0.0326  -0.547 -0.287  Head      
## 4  0.00656  0.700  0.577  Dorsal fin
## 5 -0.0664  -0.547 -0.0944 Head</code></pre>
<p>Voici en vue isométrique ce en quoi consiste ce nuage de points.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;scatterplot3d&quot;</span>)
<span class="kw">scatterplot3d</span>(<span class="dt">x =</span> dolphin<span class="op">$</span>x, <span class="dt">y =</span> dolphin<span class="op">$</span>y, <span class="dt">z =</span> dolphin<span class="op">$</span>z, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">cex.symbols =</span> <span class="fl">0.2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
<p>Effectuons l’ACP sur le dauphin.</p>
<pre class="sourceCode r"><code class="sourceCode r">dolph_pca &lt;-<span class="st"> </span><span class="kw">rda</span>(dolphin <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(x, y, z), <span class="dt">scale =</span> <span class="ot">FALSE</span>)
<span class="kw">biplot</span>(dolph_pca, <span class="dt">scaling =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>On n’y voit pas grand chose, mais si l’on extrait les scores et que l’on raccourcit les vecteurs:</p>
<pre class="sourceCode r"><code class="sourceCode r">dolph_scores &lt;-<span class="st"> </span><span class="kw">scores</span>(dolph_pca, <span class="dt">display =</span> <span class="st">&quot;sites&quot;</span>)
dolph_loads &lt;-<span class="st"> </span><span class="kw">scores</span>(dolph_pca, <span class="dt">display =</span> <span class="st">&quot;species&quot;</span>)
dolph_loads</code></pre>
<pre><code>##           PC1         PC2
## x -0.02990131  0.01608095
## y -7.13731672 -1.43221776
## z -4.56612084  2.23859843
## attr(,&quot;const&quot;)
## [1] 9.089026</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(dolph_scores, <span class="dt">pch =</span> <span class="dv">16</span>, <span class="dt">cex =</span> <span class="fl">0.24</span>, <span class="dt">asp =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="kw">factor</span>(dolphin<span class="op">$</span>anatomy))
<span class="kw">segments</span>(<span class="dt">x0 =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">3</span>), <span class="dt">y0 =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">3</span>),
         <span class="dt">x =</span> dolph_loads[, <span class="dv">1</span>]<span class="op">/</span><span class="dv">50</span>,
         <span class="dt">y =</span> dolph_loads[, <span class="dv">2</span>]<span class="op">/</span><span class="dv">50</span>,
         <span class="dt">col =</span> <span class="st">&quot;chocolate&quot;</span>, <span class="dt">lwd =</span> <span class="dv">4</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
<p>La meilleure représentation du dauphin en 2D, selon la variance, est son profil - en effet, il est plus long et haut que large.</p>
<div class="alert alert-block alert-info">
<strong>Note</strong>. Une ACP effectue seulement une rotation des points. Les distances euclidiennes entre les points sont maintenues.
</div>
<div class="alert alert-block alert-info">
<strong>Note</strong>. L’ACP a été conçue pour projetter en un nombre moindre de dimensions des observations dont les distributions sont multinormales (ce n’est évidemment pas le cas du dauphin).
</div>
<div class="alert alert-block alert-info">
<strong>Note</strong>. Les axes principaux d’une ACP sont des variables aléatoires. Elles peuvent être assujetties à des tests ststistiques, des modèles, du partitionnement de données, etc.
</div>
<div class="alert alert-block alert-success">
<strong>Excercice</strong>. Effectuez maintenant une ACP avec les données d’iris.
</div>
</div>
</div>
<div id="analyse-de-correspondance-ac" class="section level4">
<h4><span class="header-section-number">8.4.1.2</span> Analyse de correspondance (AC)</h4>
<p>L’analyse de correspondance (ac) est particulièrement appropriée pour traiter des données d’abondance et d’occurence. Tout comme l’analyse en composantes principales, les données apportés vers une AC doivent être dimentionnellement homogène, c’est-à-dire que chaque variable doit être de même métrique: pour des données d’abondance, cela signifie que les décomptes réfèrent tous au même concept: individus, colonies, surfaces occupées, etc. Alors que la distance euclidienne est préservée avec l’ACP, l’AC préserve la distance du <span class="math inline">\(\chi^2\)</span>, qui est insensible aux double-zéros.</p>
<p>L’AC produit <span class="math inline">\(min(n,p)-1\)</span> axes principaux orthogonaux qui captent non pas le maximum de variance, mais la proportion de mesures aux carré par rapport à la somme des carrés de la matrice. Le biplot obtenu peut être présenté sous forme de biplot de site (<em>scaling 1</em>), où la distance du <span class="math inline">\(\chi^2\)</span> est préservée entre les sites ou biplot d’espèces (<em>scaling 2</em>), ou la distance du <span class="math inline">\(\chi^2\)</span> est préservée entre les espèces. L’AC hérite du coup une propriété importate de la distance du <span class="math inline">\(\chi^2\)</span>, qui accorde davantage de distance entre un compte de 0 et de 1 qu’entre 1 et 2, et davantage entre 1 et 2 qu’entre 2 et 3.</p>
<p>Par exemple, sur ces trois sites, on a compté un individu A de moins que d’individu B.</p>
<pre class="sourceCode r"><code class="sourceCode r">abundance_<span class="dv">0123</span> =<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">Site =</span> <span class="kw">c</span>(<span class="st">&quot;Site 1&quot;</span>, <span class="st">&quot;Site 2&quot;</span>, <span class="st">&quot;Site 3&quot;</span>),
                        <span class="dt">A =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">9</span>),
                        <span class="dt">B =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">10</span>))
abundance_<span class="dv">0123</span></code></pre>
<pre><code>## # A tibble: 3 x 3
##   Site       A     B
##   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 Site 1     0     1
## 2 Site 2     1     2
## 3 Site 3     9    10</code></pre>
<p>Pourtant, la distance du <span class="math inline">\(\chi^2\)</span> est plus élevée entre le site 1 et le site 2 qu’entre le site 2 et le site 3.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dist</span>(<span class="kw">decostand</span>(abundance_<span class="dv">0123</span> <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Site), <span class="dt">method=</span><span class="st">&quot;chi.square&quot;</span>))</code></pre>
<pre><code>##           1         2
## 2 0.6724111          
## 3 0.9555316 0.2831205</code></pre>
<p>La distance du <span class="math inline">\(\chi^2\)</span> donne davantage d’importance aux espèces rares, ce dont une analyse doit tenir compte. Il pourrait être envisageable de retirer d’un tableau des espèces rare, ou bien prétransformer des données d’abondance par une transformation de chord ou de Hellinger (tel que discuté au chapitre 6), puis procéder à une ACP sur ces données (<a href="https://doi.org/10.1007/s004420100716">Legendre et Gallagher, 2001</a>).</p>
<div id="application-3" class="section level5">
<h5><span class="header-section-number">8.4.1.2.1</span> Application</h5>
<p>Le tableau <a href="https://rdrr.io/rforge/vegan/man/varechem.html"><code>varespec</code></a> comprend des données de surface de couverture de 44 espèces de plantes en lien avec les données environnementales du tableau <code>varechem</code>. Ces données ont été publiées dans <a href="http://onlinelibrary.wiley.com/doi/10.2307/3236351/abstract">Väre et al. (1995)</a> et exportées du module <a href="https://rdrr.io/rforge/vegan/">vegan</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;varespec&quot;</span>)
varespec <span class="op">%&gt;%</span><span class="kw">sample_n</span>(<span class="dv">5</span>)</code></pre>
<pre><code>##   Callvulg Empenigr Rhodtome Vaccmyrt Vaccviti Pinusylv Descflex Betupube
## 1     0.00    12.68     0.00     0.00    23.73     0.03      0.0     0.00
## 2     0.67     0.17     0.00     0.35    12.13     0.12      0.0     0.00
## 3     0.00    16.00     4.00    15.00    25.00     0.25      0.5     0.25
## 4     3.75     5.65     0.00     0.08     5.30     0.10      0.0     0.00
## 5    24.13     1.90     0.07     0.22     5.30     0.12      0.0     0.00
##   Vacculig Diphcomp Dicrsp Dicrfusc Dicrpoly Hylosple Pleuschr Polypili
## 1        0     0.00   0.00     3.42     0.02        0    19.42     0.02
## 2        0     0.00   0.33    10.92     0.02        0    37.75     0.02
## 3        0     0.00   0.25     0.25     3.00        0     2.00     0.00
## 4        0     0.00   0.00    11.32     0.00        0     7.75     0.00
## 5        0     0.07   0.02     2.50     0.00        0     5.52     0.00
##   Polyjuni Polycomm Pohlnuta Ptilcili Barbhatc Cladarbu Cladrang Cladstel
## 1     2.12     0.00     0.17     1.80     0.02     9.08     9.22     0.05
## 2     0.23     0.00     0.03     0.02     0.00    12.05     8.13     0.18
## 3     0.25     0.25     0.25    10.00     3.00     0.70     4.70    10.90
## 4     0.30     0.02     0.07     0.00     0.00    17.45     1.32     0.12
## 5     0.02     0.00     0.03     0.25     0.07    23.07    23.67    11.90
##   Cladunci Cladcocc Cladcorn Cladgrac Cladfimb Cladcris Cladchlo Cladbotr
## 1     0.73     0.08     1.42     0.50     0.17     1.78     0.05     0.05
## 2     2.65     0.13     0.18     0.23     0.25     1.23     0.00     0.00
## 3     0.25     0.00     0.05     0.25     0.25     0.25     0.25     0.25
## 4    23.68     0.22     0.50     0.15     0.23     0.97     0.00     0.00
## 5     0.95     0.17     0.05     0.23     0.18     0.57     0.02     0.07
##   Cladamau Cladsp Cetreric Cetrisla Flavniva Nepharct Stersp Peltapht
## 1        0   0.00     0.00     0.00     0.02        0   1.58     0.33
## 2        0   0.00     0.15     0.03     0.00        0   0.85     0.00
## 3        0   0.00     0.00     0.67     0.00        0   0.00     0.00
## 4        0   0.00     0.68     0.02     0.00        0   0.33     0.00
## 5        0   0.07     0.18     0.02     0.00        0   0.03     0.02
##   Icmaeric Cladcerv Claddefo Cladphyl
## 1     0.00        0     1.97     0.00
## 2     0.00        0     1.00     0.00
## 3     0.00        0     0.40     0.00
## 4     0.02        0     1.57     0.05
## 5     0.00        0     0.47     0.00</code></pre>
<p>Pour effectuer l’AC, nous utiliserons, comme pour l’ACP, le module vegan mais cette fois-ci avec la fonction <code>cca</code>. L’AC en <em>scaling 1</em> est effectuée sur le tableau des abondances avec les espèces comme colonnes et les sites comme lignes. Les matrices d’abondance transposées indique les sites où chque espèce ont été dénombrées: pour une analyse en <em>scaling 2</em>, on effectue une analyse de correspondance sur la matrice d’abondance (ou d’occurence) transposée.</p>
<p>Pour chacune des AC, je filtre pour m’assurer que toutes les lignes contiennent au moins une observation. Ce n’est pas nécessaire dans notre cas, mais je le laisse pour l’exemple.</p>
<pre class="sourceCode r"><code class="sourceCode r">vare_cca &lt;-<span class="st"> </span><span class="kw">cca</span>(varespec <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">rowSums</span>(.) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))
<span class="kw">summary</span>(vare_cca, <span class="dt">scaling =</span> <span class="dv">1</span>)</code></pre>
<pre><code>## 
## Call:
## cca(X = varespec %&gt;% filter(rowSums(.) &gt; 0)) 
## 
## Partitioning of scaled Chi-square:
##               Inertia Proportion
## Total           2.083          1
## Unconstrained   2.083          1
## 
## Eigenvalues, and their contribution to the scaled Chi-square 
## 
## Importance of components:
##                          CA1    CA2    CA3     CA4     CA5     CA6     CA7
## Eigenvalue            0.5249 0.3568 0.2344 0.19546 0.17762 0.12156 0.11549
## Proportion Explained  0.2520 0.1713 0.1125 0.09383 0.08526 0.05835 0.05544
## Cumulative Proportion 0.2520 0.4233 0.5358 0.62962 0.71489 0.77324 0.82868
##                           CA8     CA9    CA10    CA11    CA12    CA13
## Eigenvalue            0.08894 0.07318 0.05752 0.04434 0.02546 0.01710
## Proportion Explained  0.04269 0.03513 0.02761 0.02129 0.01222 0.00821
## Cumulative Proportion 0.87137 0.90650 0.93411 0.95539 0.96762 0.97583
##                           CA14     CA15     CA16     CA17     CA18
## Eigenvalue            0.014896 0.010160 0.007830 0.006032 0.004008
## Proportion Explained  0.007151 0.004877 0.003759 0.002896 0.001924
## Cumulative Proportion 0.982978 0.987855 0.991614 0.994510 0.996434
##                           CA19      CA20      CA21      CA22      CA23
## Eigenvalue            0.002865 0.0019275 0.0018074 0.0005864 0.0002434
## Proportion Explained  0.001375 0.0009253 0.0008676 0.0002815 0.0001168
## Cumulative Proportion 0.997809 0.9987341 0.9996017 0.9998832 1.0000000
## 
## Scaling 1 for species and site scores
## * Sites are scaled proportional to eigenvalues
## * Species are unscaled: weighted dispersion equal on all dimensions
## 
## 
## Species scores
## 
##                 CA1       CA2      CA3       CA4        CA5       CA6
## Callvulg  0.0303167 -1.597460  0.11455 -2.894569  0.1376073  2.291129
## Empenigr  0.0751030  0.379305  0.39303  0.023675  0.8568729 -0.400964
## Rhodtome  1.1052309  1.499299  3.04284  0.120106  3.2324306 -0.283510
## Vaccmyrt  1.4614812  1.622935  2.72375  0.231688  0.4604556  0.712538
## Vaccviti  0.1468014  0.313436  0.14696  0.243505  0.6868371 -0.147815
## Pinusylv -0.4820096  0.588517 -0.36020 -0.127094  0.4064754  0.386604
## Descflex  1.5348239  1.218806  1.87562 -0.001340 -1.3136979 -0.070731
## Betupube  0.6694503  1.951826  3.84017  1.389423  7.5959115 -0.244478
## Vacculig -0.0830789 -1.629259  1.05063  0.802648 -0.3058811 -1.625341
## Diphcomp -0.5446464 -1.037570  0.52282  0.940275  0.3682126 -1.082929
## Dicrsp    1.8120408  0.360290 -4.92082  3.088562  1.3867372  0.157815
## Dicrfusc  1.2704743 -0.562978 -0.39718 -2.929542  0.3848272 -2.408710
## Dicrpoly  0.7248118  1.409347  0.80341  1.915549  4.5674148  1.295447
## Hylosple  2.0062408  1.743883  2.27549  0.928884 -3.7648428  2.254851
## Pleuschr  1.3102086  0.583036 -0.01004  0.137298 -1.1216144  0.200422
## Polypili -0.3805097 -1.243904  0.54593  1.477188 -0.7276341 -0.387641
## Polyjuni  1.0133795  0.099043 -2.24697  1.510641  0.7729714 -3.062378
## Polycomm  0.8468241  1.321773  1.13585  1.140723  2.6836594 -0.605038
## Pohlnuta -0.0136453  0.589290 -0.35542  0.135481  0.9369707  0.397246
## Ptilcili  0.4223631  1.598584  3.43474  1.400065  6.3209491  0.198935
## Barbhatc  0.5018348  2.119334  4.57303  1.693188  8.1101807  0.645995
## Cladarbu -0.1531729 -1.483884  0.20024  0.193680  0.0734141  0.358926
## Cladrang -0.5502561 -1.084008  0.40552  0.724060 -0.3357992 -0.335924
## Cladstel -1.4373146  1.077753 -0.44397 -0.375926 -0.2421525  0.004212
## Cladunci  0.8151727 -1.006186 -1.82587 -1.389523  1.6046713  3.675908
## Cladcocc -0.2133215 -0.584429 -0.21434 -0.567886 -0.0003788 -0.145303
## Cladcorn  0.2631227 -0.177858 -0.44464  0.272422  0.3992282 -0.306738
## Cladgrac  0.1956947 -0.311167 -0.23894  0.379013  0.4933026  0.037581
## Cladfimb  0.0009213 -0.161418  0.18463 -0.435908  0.4831233 -0.143751
## Cladcris  0.3373031 -0.470369 -0.05093 -0.823855  0.7182250  0.636140
## Cladchlo -0.6200021  1.207278  0.21889  0.426447  1.9506082  0.120722
## Cladbotr  0.5647242  1.047333  2.65330  0.907734  4.4946805  1.201655
## Cladamau -0.6598144 -1.512880  0.83251  1.577699 -0.0407227 -1.419139
## Cladsp   -0.8209003  0.476164 -0.49752 -0.998241 -0.2393208  0.390785
## Cetreric  0.2458192 -0.689228 -1.68427 -0.131681  0.7439412  2.374535
## Cetrisla -0.3465221  1.362693  0.85897  0.396752  2.7526968  0.396591
## Flavniva -1.4391907 -0.833589 -0.12919  0.007071 -1.4841375  2.956977
## Nepharct  1.6813309  0.199484 -4.33509  2.229917  0.9561223 -5.472858
## Stersp   -0.5172793 -2.280900  0.99775  2.377013 -0.8892757 -1.441228
## Peltapht  0.4035858 -0.043265  0.04538  0.711040  0.1824679 -0.841227
## Icmaeric  0.0378754 -2.419595  0.72135  0.361302 -0.3736424 -2.092136
## Cladcerv -0.9232858 -0.005233 -1.22058  0.305290 -0.8142627  0.414135
## Claddefo  0.5190399 -0.496632 -0.15271 -0.695927  0.9042143  0.909191
## Cladphyl -1.2836161  1.155872 -0.79912 -0.741170 -0.1608002  0.490526
## 
## 
## Site scores (weighted averages of species scores)
## 
##             CA1      CA2       CA3      CA4        CA5      CA6
## sit1  -0.108122 -0.53705  0.229574  0.24412  0.1405624 -0.14253
## sit2   0.697118 -0.14441 -0.031788 -0.21743 -0.2738522 -0.08146
## sit3   0.987603  0.15042 -1.348447  0.80472  0.3095168  0.46773
## sit4   0.851765  0.49901  0.443559  0.12277 -0.4814871  0.07589
## sit5   0.359881 -0.05608  0.145813  0.15087  0.2405263 -0.17770
## sit6   0.003545  0.37017  0.027760  0.06168 -0.1158930 -0.03413
## sit7   0.860732 -0.11504  0.110869 -1.02169  0.0772348 -0.60530
## sit8   0.636936 -0.33250  0.001120 -0.79797  0.0130769 -0.54049
## sit9   1.279352  0.81557  0.670053  0.23137 -0.8929976  0.41783
## sit10 -0.195009 -0.80564  0.117686 -0.58286 -0.0007212  0.53071
## sit11  0.528532 -0.70420 -0.517771 -0.86836  0.5713441  0.91671
## sit12  0.382866 -0.18686 -0.004789  0.10156  0.0458125  0.21087
## sit13  0.990715  0.11967 -1.110040  0.44929  0.1885902 -0.70694
## sit14 -0.264704 -1.06013  0.334900  0.45973 -0.0326631 -0.19945
## sit15 -0.428410 -1.20765  0.374344  0.74970 -0.2596294 -0.30467
## sit16 -0.330534 -0.77498  0.130760  0.22391  0.0632686  0.09060
## sit17 -0.899601  0.12075 -0.075742  0.03842 -0.1489585 -0.12031
## sit18 -0.770294 -0.35351 -0.033779 -0.01795 -0.3007839  0.44303
## sit19 -0.992193  0.50319 -0.157505 -0.07070 -0.1065172 -0.09928
## sit20 -0.937173  0.78688 -0.258119 -0.19377 -0.0343535 -0.01259
## sit21 -0.726413  0.49163 -0.157235 -0.08698 -0.0105774 -0.02801
## sit22 -1.002083  0.71239 -0.236526 -0.18643 -0.0231666 -0.04928
## sit23 -0.322647 -0.03871 -0.001297  0.09029 -0.1481448  0.06934
## sit24  0.259527  0.80746  1.124258  0.36083  1.5437866  0.07051</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">varespec_eigenval &lt;-<span class="st"> </span><span class="kw">eigenvals</span>(vare_cca, <span class="dt">scaling =</span> <span class="dv">1</span>)

prop_expl &lt;-<span class="st"> </span>varespec_eigenval <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(varespec_eigenval)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
     <span class="dt">y =</span> vare_cca<span class="op">$</span>CA<span class="op">$</span>eig,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="kw">mean</span>(varespec_eigenval), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
     <span class="dt">y =</span> prop_expl,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>)
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
      <span class="dt">y =</span> <span class="kw">broken_stick</span>(<span class="kw">length</span>(varespec_eigenval)),
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>,
      <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>Créons les biplots.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(vare_cca, <span class="dt">scaling =</span> <span class="dv">1</span>, <span class="dt">main =</span> <span class="st">&quot;Biplot des espèces&quot;</span>)
<span class="kw">plot</span>(vare_cca, <span class="dt">scaling =</span> <span class="dv">2</span>, <span class="dt">main =</span> <span class="st">&quot;Biplot des sites&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="960" /></p>
<p>Le <strong>biplot des espèces</strong>, à gauche (<code>scaling = 1</code>), montre la distribution des sites selon les espèces. Les emplacements des scores (en noir) montrent les contrastes entre sites selon les espèces qui les recouvrent. Les sites 14 et 15, par exemple, contrastent les sites 19, 20, 21 et 22 selon le 2ième axe principal. Par ailleurs, les axes principaux sont formé de plusieurs espèces dont aucune ne domine clairement.</p>
<p>Le <strong>biplot des sites</strong>, à droite (<code>scaling = 2</code>), montre la distribution des recouvrements d’espèces selon les sites. Par exemple, les espèces Betupube (<a href="https://fr.wikipedia.org/wiki/Betula_pubescens"><em>Betula pubescens</em></a>) et Barbhatc (<a href="https://en.wikipedia.org/wiki/Marchantiophyta"><em>Barbilophozia hatcheri </em></a>) se recouvrent en particulier le site 24. Le site 1 est difficile à identifier, car il est couvert par plusieurs noms d’espèces, au bas au centre. Les sites 3 et 13 se confondent avec Dicrsp (une espèce de <a href="https://en.wikipedia.org/wiki/Dicranum"><em>Dicranum</em></a>) qui le recouvre amplement.</p>
<p>Pour les deux types de biplot, les sites où les espèces situés près de l’origine, car ils peuvent être soit près de la moyenne, soit distribués uniformément.</p>
<p>Le nombre de composantes à retenir peut être évalué par les approches <em>Kaiser-Guttmann</em> et <em>broken-stick</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r">scaling &lt;-<span class="st"> </span><span class="dv">1</span>
varespec_eigenval &lt;-<span class="st"> </span><span class="kw">eigenvals</span>(vare_cca, <span class="dt">scaling =</span> scaling) <span class="co"># peut être effectué sur les deux types de scaling</span>

prop_expl &lt;-<span class="st"> </span>varespec_eigenval <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(varespec_eigenval)

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
     <span class="dt">y =</span> vare_cca<span class="op">$</span>CA<span class="op">$</span>eig,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>,
     <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;Eigenvalue - Kaiser-Guttmann, scaling =&quot;</span>, scaling))
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="kw">mean</span>(varespec_eigenval), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="kw">plot</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
     <span class="dt">y =</span> prop_expl,
     <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;Rang de la valeur propre&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Valeur propre&quot;</span>,
     <span class="dt">main =</span> <span class="kw">paste</span>(<span class="st">&quot;Proportion - broken stick, scaling =&quot;</span>, scaling))
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(varespec_eigenval),
      <span class="dt">y =</span> <span class="kw">broken_stick</span>(<span class="kw">length</span>(varespec_eigenval)),
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>,
      <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-76-1.png" width="960" /></p>
<p>Pour les deux scalings, l’approche <em>Kaiser-Guttmann</em> propose 7 axes, tandis que l’approche <em>broken-stick</em> en propose 5.</p>
<p>Les représentations biplot d’analyse de correspondance peuvent prendre la forme d’un boomerang, en particulier celles qui sont basées sur des données d’occurence. Le tableau suivant initialement de <a href="http://pbil.univ-lyon1.fr/R/pdf/pps047.pdf">Chessel et al. (1987)</a> et est distribué dans le module ade4.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;ade4&quot;</span>)
<span class="kw">data</span>(<span class="st">&quot;doubs&quot;</span>)
fish &lt;-<span class="st"> </span>doubs<span class="op">$</span>fish
doubs_cca &lt;-<span class="st"> </span><span class="kw">cca</span>(fish <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(<span class="kw">rowSums</span>(.) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))
<span class="kw">plot</span>(doubs_cca, <span class="dt">scaling =</span> <span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>Les numéros de sites correspondent à la position dans une rivière, 1 étant en amont et 30 en aval. Le premier axe discrimine l’amont et l’aval, tandis que le deuxième montre deux niches en amont. Bien que l’on observe une discontinuité dans le cours d’eau, il y a une continuité dans les abondances. Cet effet peut être corrigé en retirant la tendance de l’analyse de correspondance par une <em>detrended correspondance analysis</em>. Pour cela, il faudra utiliser la fonction <code>decorana</code>, ce qui ne sera pas couvert ici.</p>
<p>L’<em>analyse des correspondances multiples</em> (ACM) est utile pour l’ordination des données catégorielles. Le module <a href="https://larmarange.github.io/analyse-R/analyse-des-correspondances-multiples.html#acm-avec-ade4"><em>ade4</em></a> est en mesure d’effectuer des AMC, mais n’est pas couvert dans ce manuel.</p>
<div class="alert alert-block alert-success">
<strong>Excercice</strong>. Effectuez et analysez une AC avec les données de recouvrement <code>varespec</code>.
</div>
</div>
</div>
<div id="positionnement-multidimensionnel-pomd" class="section level4">
<h4><span class="header-section-number">8.4.1.3</span> Positionnement multidimensionnel (PoMd)</h4>
<p>Le positionnement multidimensionnel (PoMd), ou <a href="http://scikit-learn.org/stable/modules/manifold.html"><em>manifold analysis</em></a>, se base sur les assiciations entre les objets (mode Q) ou les variables (mode R) pour en réduire les dimensions. Alors que l’analyse en composantes principales conserve la distance euclidienne et que l’analyse de correspondance conserve la distance du <span class="math inline">\(\chi^2\)</span>, l’AEM conserve l’association que vous sélectionnerez à votre convenance. L’AEM vise à représenter en un nombre limité de dimensions (souvent 2) la distance (ou dissimilarité) qu’ont les objets (ou des variables) les uns par rapport aux autres dans l’espace multidimensionnel.</p>
<p>Il existe deux types d’AEM. Le <strong>PoMd-métrique</strong> (<em>metric multidimentional scaling</em> MMDS, parfois le <em>metric</em> est retiré, MDS, et parfois l’on parle de <em>classic MDS</em>) vise à représenter fidèlement la distance entre les objets ou les variables. Le PoMd-métrique ne devrait être utilisée que lorsque la métrique n’est ni euclidienne, ni de <span class="math inline">\(\chi^2\)</span> et que l’on désire préserver les distances entre les objets. L’PoMd-métrique aussi appelée <em>analyse en coordonnées principales</em> (ACoP ou de l’anglais <em>PCoA</em>) .</p>
<p>Le <strong>PoMd-non-métrique</strong> (<em>nonmetric multidimentional scaling</em>, NMDS) vise quant à elle à représenter l’ordre des distances entre les objets ou les variables. C’est une approche par rang: le PoMd-non-métrique vise représenter les objets sont plus proches ou plus éloignées les uns des autres plutôt que de représenter leur similarité dans l’espace multidimentionnelle.</p>
<p>L’<strong>IsoMap</strong>, pour <em>isometric feature mapping</em>, est une extension du PoMd qui recontruit les distances selon les points retrouvés dans le voisinage. Les isomaps sont en mesure d’applatir des données ayant des formes complexes.</p>
<p>Nous ne traitons pour l’instant que de l’PoMd-métrique (fonction <code>vegan::cmdscale</code>) et des PoMd-non-métrique (fonction <code>vegan::metaMDS</code>).</p>
<div id="application-4" class="section level5">
<h5><span class="header-section-number">8.4.1.3.1</span> Application</h5>
<p>Utilisons les données d’abondance que nous avions au tout début de ce chapitre. La matrice d’association de Bray-Curtis sera utilisée.</p>
<pre class="sourceCode r"><code class="sourceCode r">assoc_mat &lt;-<span class="st"> </span><span class="kw">vegdist</span>(abundance, <span class="dt">method =</span> <span class="st">&quot;bray&quot;</span>)
<span class="kw">pheatmap</span>(assoc_mat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>(), <span class="dt">cluster_rows =</span> <span class="ot">FALSE</span>, <span class="dt">cluster_cols =</span> <span class="ot">FALSE</span>,
         <span class="dt">display_numbers =</span> <span class="kw">round</span>(assoc_mat <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>(), <span class="dv">2</span>))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-78-1.png" width="288" /></p>
<p>Les sites 2 et 3 devraient être plus près l’un et l’autre, puis les sites 3 et 4. Les autres associations sont éloignés d’environ la même distance. Lançons le calcul de la PoMd-métrique.</p>
<pre class="sourceCode r"><code class="sourceCode r">pcoa &lt;-<span class="st"> </span><span class="kw">cmdscale</span>(assoc_mat, <span class="dt">k =</span> <span class="kw">nrow</span>(abundance)<span class="op">-</span><span class="dv">1</span>, <span class="dt">eig =</span> <span class="ot">TRUE</span>)
spec_scores &lt;-<span class="st"> </span><span class="kw">wascores</span>(pcoa<span class="op">$</span>points, abundance)
<span class="kw">ordiplot</span>(<span class="kw">scores</span>(pcoa), <span class="dt">type =</span> <span class="st">&#39;t&#39;</span>, <span class="dt">cex =</span> <span class="fl">1.5</span>)</code></pre>
<pre><code>## species scores not available</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">text</span>(spec_scores, <span class="kw">row.names</span>(spec_scores), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.75</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>On observe en effet que les sites 2 et 3 sont les plus près. Les sites 3 et 4sont plus éloignés. Les sites 1, 2 et 4 font à peu près un triangle équilatéral, ce qui correspond à ce à quoi on devrait s’attendre. Les wa-scores permettent de juxtaposer les espèces sur les sites, pour référence. Le colibri n’est prsent que sur le site 2. Le site 1 est populé par des jaseurs et des mésanges, et c’est le seul site où l’on a observé une citelle. On a observé des chardonnerets sur les sites 2 et 3. Sur le site 4, on n’a observé que des bruants, que l’on a aussi observé ailleurs, sauf au site 2.</p>
<p>Le PoMd-non-métrique (<em>non metric dimensional scaling, NMDS</em>) fonctionne de la même manière que la PoMd-métrique, à la différence que la distance est basée sur les rangs. À cet égard, le site 4 à une distance de 0.76 du site 3, mais plutôt le deuxième plus loin, après le site 2 et avant le site 1. Utilisons la fonction <code>metaMDS</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">nmds &lt;-<span class="st"> </span><span class="kw">metaMDS</span>(assoc_mat, <span class="dt">k =</span> <span class="kw">nrow</span>(abundance)<span class="op">-</span><span class="dv">1</span>, <span class="dt">eig =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>## Run 0 stress 0 
## Run 1 stress 0 
## ... Procrustes: rmse 0.1031808  max resid 0.1304025 
## Run 2 stress 0 
## ... Procrustes: rmse 0.1171868  max resid 0.1589257 
## Run 3 stress 0 
## ... Procrustes: rmse 0.1609769  max resid 0.1988774 
## Run 4 stress 0 
## ... Procrustes: rmse 0.1256693  max resid 0.162229 
## Run 5 stress 0 
## ... Procrustes: rmse 0.08798558  max resid 0.1245979 
## Run 6 stress 0 
## ... Procrustes: rmse 0.1224955  max resid 0.1570506 
## Run 7 stress 0 
## ... Procrustes: rmse 0.03637895  max resid 0.05051536 
## Run 8 stress 0 
## ... Procrustes: rmse 0.06461653  max resid 0.09001241 
## Run 9 stress 0 
## ... Procrustes: rmse 0.09044352  max resid 0.1329249 
## Run 10 stress 0 
## ... Procrustes: rmse 0.05059687  max resid 0.07345422 
## Run 11 stress 0 
## ... Procrustes: rmse 0.1047102  max resid 0.1380324 
## Run 12 stress 0 
## ... Procrustes: rmse 0.07951172  max resid 0.1123667 
## Run 13 stress 0 
## ... Procrustes: rmse 0.09382783  max resid 0.1276259 
## Run 14 stress 1.839704e-05 
## ... Procrustes: rmse 0.1508167  max resid 0.1798566 
## Run 15 stress 0 
## ... Procrustes: rmse 0.07590129  max resid 0.1056722 
## Run 16 stress 0 
## ... Procrustes: rmse 0.119933  max resid 0.1487336 
## Run 17 stress 0 
## ... Procrustes: rmse 0.06422595  max resid 0.09161838 
## Run 18 stress 0 
## ... Procrustes: rmse 0.07901353  max resid 0.1034832 
## Run 19 stress 8.508492e-05 
## ... Procrustes: rmse 0.094234  max resid 0.1383797 
## Run 20 stress 0 
## ... Procrustes: rmse 0.08159783  max resid 0.09589774 
## *** No convergence -- monoMDS stopping criteria:
##     20: stress &lt; smin</code></pre>
<pre><code>## Warning in metaMDS(assoc_mat, k = nrow(abundance) - 1, eig = TRUE): stress
## is (nearly) zero: you may have insufficient data</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">spec_scores &lt;-<span class="st"> </span><span class="kw">wascores</span>(nmds<span class="op">$</span>points, abundance)
<span class="kw">ordiplot</span>(<span class="kw">scores</span>(nmds), <span class="dt">type =</span> <span class="st">&#39;t&#39;</span>, <span class="dt">cex =</span> <span class="fl">1.5</span>)</code></pre>
<pre><code>## species scores not available</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">text</span>(spec_scores, <span class="kw">row.names</span>(spec_scores), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.75</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>Dans ce cas, entre PoMd-métrique et non-métrique, les résultats peuvent être interprétés de manière similaire.</p>
<p>En ce qui a trait au dauphin,</p>
<p><img src="_main_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<p>Pour plus de détails, je vous invite à vous référer à <a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>) ou de consulter l’excellent site <a href="https://mb3is.megx.net/gustame/dissimilarity-based-methods/nmds">GUSTA ME</a>.</p>
</div>
</div>
<div id="conclusion-sur-lordination-non-contraignante" class="section level4">
<h4><span class="header-section-number">8.4.1.4</span> Conclusion sur l’ordination non contraignante</h4>
<p>Lorsque les données sont euclidiennes, l’analyse en composantes principales (ACP) dervait être utilisée. Lorsque la métrique est celle du <span class="math inline">\(\chi^2\)</span>, on préférera l’analyse de correspondance (AC). Si la métrique est autre, le positionnement multidimensionel (PoMd) est préférable. Dans ce dernier cas, si l’on recherche une représentation simplifiée de la distance entre les objets ou variables, on utilisera un PoMd-métrique. À l’inverse, si l’on désire une représentation plus fidèle au rang des distances, on préférera l’PoMd-non-métrique.</p>
</div>
</div>
<div id="ordination-contraignante" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Ordination contraignante</h3>
<p>Alors que l’ordination non contraignante vous permet de dresser un protrait de vos variables, l’ordination contraignante (ou canonique) permet de tester statistiquement ainsi que de représenter la relation entre plusieurs variables explicatives (par exemple, des conditions environnementales) et une ou plusieurs variables réponses (par exemple, les espèces observées).</p>
<ul>
<li>L’analyse discriminante n’a fondamentalement qu’une seulement variable réponse, et celle-ci doit décrire l’appartenance à une catégorie.</li>
<li>L’analyse canonique des corrélations sera préférée lorsque les variables sont étalées (comme les variables d’abondance).</li>
<li>L’analyse de redondance sera préférée lorsque le nombre de variable est plus restreint (variables ionomiques et indicateurs de performance des cultures). Les détails, ainsi que les tenants et aboutissants de ces méthodes, sont présentés dans <a href="https://www.elsevier.com/books/numerical-ecology/legendre/978-0-444-53868-0">Numerical Ecology (Legendre et Legendre, 2012)</a>.</li>
</ul>
<div id="analyse-discriminante" class="section level4">
<h4><span class="header-section-number">8.4.2.1</span> Analyse discriminante</h4>
<p>Alors que l’analyse en composante principale vise à présenter la perspective (les axes) selon laquelle les points sont les plus éclatées, l’analyse discriminante, le plus souvent utilisé dans sa forme linéaire (ADL) et quadratique (ADQ), vise à présenter la perspective selon laquelle les groupes sont les plus éclatés, les groupes formant la variable contraignante. Ces groupes peuvent être connus (e.g. cultivar, région géographique) ou attribués (exemple: par partitionnement). L’ADL est parfois nommée <em>analyse canonique de la variance</em>.</p>
<p>L’AD vise à représenter des différences entre des groupes aux moyens de combinaisons linéaires (ADL) ou quadratique (ADQ) de variables mesurées. Sa représentation sous forme de biplot permet d’apprécier les différences entre les groupes d’identifier les variables qui sont responsables de la discrimination.</p>
<p><img src="images/07_ionome-revisited-figure4d.png" alt="" style="width: 600px;"/></p>
<center>
Biplot de distance de l’analyse discriminante des ionomes d’espèces de plantes à fruits cultivées sauvages et domestiquées, Source: <a href="https://doi.org/10.3389/fpls.2013.00039">Parent et al. (2013)</a>
</center>
<p>L’ADL a été développée par <a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/abstract">Fisher (1936)</a>, qui à titre d’exemple d’application a utilisé un jeu de données de dimensions d’iris collectées par Edgar Anderson, du Jardin botanique du Missouri, sur 150 spécimens d’iris collectés en Gaspésie (Est du Québec), ma région natale. Ce jeu de données est amplement utilisé à titre d’exemple en analyse multivariée.</p>
<p><a href="http://www.jstor.org/stable/1937836">Williams (1983)</a> a présenté les tenants et aboutissants de l’ADL en écologie. Tout comme les données passant pas une ACP doivent suivre une distribution multinormale pour être statistiquement valide, les distributions des groupes dans une ADL doivent être multinormales et les variances des points par groupe doivent être homogènes… ce qui est rarement le cas en science. Néanmoins:</p>
<blockquote>
<p>Heureusement, il y a des évidences dans la littérature que certaines d’entre [ces règles] peuvent être transgressées modérément sans de grands changement dans les taux de classification. Cette conclusion dépends, toutefois, de la sévérité des transgressions, et de facteurs structueaux comme la position relative des moyennes des populations et de la nature des dispersions. - <a href="http://www.jstor.org/stable/1937836">Williams (1983)</a></p>
</blockquote>
<p>L’ADL peut servir autant d’outil d’interprétation que d’outil de classification, c’est à dire de prédire une catégorie selon les variables (chapitre 11). Dans les deux cas, lorsque le nombre de variables approchent le nombre d’observation, les résultats d’une ADL risque d’être difficilement interprétables. Le test approprié pour évaluer l’homodénéité de la covariance est le M-test de Box. Ce test est peu documenté dans la littérature, est rarement utilisé mais a la <a href="https://en.wikiversity.org/wiki/Box%27s_M">réputation</a> d’être particulièrement sévère.</p>
<p>Il est rare que des données écologiques aient des dispersions (covariances) homogènes. Contrairement à l’ADL, l’ADQ ne demande pas à ce que les dispersions (covariances) soient homogènes. Néanmoins, l’ADQ ne génère ni de scores, ni de loadings: il s’agit d’un outil pour prédire des catégories (classification), non pas d’un outil d’ordination.</p>
<div id="application-5" class="section level5">
<h5><span class="header-section-number">8.4.2.1.1</span> Application</h5>
<p>Utilisons les données d’iris.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>)</code></pre>
<p>Testons la multinormalité par groupe. Rappelons-nous que pour considérer la distribution comme multinormale, la p-value de la distortion ainsi que la statistique de Kurtosis doivent être égale ou plus élevée que 0.05. La fonction <code>split</code> sépare le tableau en listes et la fonction <code>map</code> applique la fonction spécifiée à chaque élément de la liste. Cela permet d’effectuer des tests de multinormalité sur chacune des espèces d’iris.</p>
<pre class="sourceCode r"><code class="sourceCode r">iris <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">split</span>(.<span class="op">$</span>Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">map</span>(<span class="op">~</span><span class="st"> </span><span class="kw">mvn</span>(.x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species),
            <span class="dt">mvnTest =</span> <span class="st">&quot;mardia&quot;</span>)<span class="op">$</span>multivariateNormality)</code></pre>
<pre><code>## $setosa
##              Test        Statistic           p value Result
## 1 Mardia Skewness 25.6643445196298 0.177185884467652    YES
## 2 Mardia Kurtosis 1.29499223711605 0.195322907441935    YES
## 3             MVN             &lt;NA&gt;              &lt;NA&gt;    YES
## 
## $versicolor
##              Test         Statistic           p value Result
## 1 Mardia Skewness  25.1850115362466 0.194444483140265    YES
## 2 Mardia Kurtosis -0.57186635893429 0.567412516528727    YES
## 3             MVN              &lt;NA&gt;              &lt;NA&gt;    YES
## 
## $virginica
##              Test         Statistic           p value Result
## 1 Mardia Skewness  26.2705981752915 0.157059707690356    YES
## 2 Mardia Kurtosis 0.152614173978342 0.878702546726567    YES
## 3             MVN              &lt;NA&gt;              &lt;NA&gt;    YES</code></pre>
<p>Le test est passé pour toutes les espèces. Voyons maintenant l’homogénéité de la covariance. Pour ce faire, nous aurons besoin de la fonction <code>boxM</code>, disponible avec le module <code>biotools</code>. Pour que les covariances soient considérées comme égales, la p-vaule doit être supérieure à 0.05.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;heplots&quot;</span>)</code></pre>
<pre><code>## Loading required package: car</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## 
## Attaching package: &#39;car&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     recode</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     some</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxM</span>(iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species),
     <span class="dt">group =</span> iris<span class="op">$</span>Species)</code></pre>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  iris %&gt;% select(-Species)
## Chi-Sq (approx.) = 140.94, df = 20, p-value &lt; 2.2e-16</code></pre>
<p>On est loin d’un cas où les distributions sont homogènes. Nous allons néanmoins procéder à l’analyse discriminante avec le module ade4. Nous aurons d’abord besoin d’effectuer une ACP avec la fonction <code>dudi.pca</code> de ade4 (en spécifiant une mise à l’échelle), que nous projeterons en ADL avec <code>discrimin</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;ade4&quot;</span>)
iris_pca &lt;-<span class="st"> </span><span class="kw">dudi.pca</span>(<span class="dt">df =</span> iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species),
                     <span class="dt">scannf =</span> <span class="ot">FALSE</span>, <span class="co"># ne pas générer de graphique</span>
                     <span class="dt">scale =</span> <span class="ot">TRUE</span>)
iris_lda &lt;-<span class="st"> </span><span class="kw">discrimin</span>(<span class="dt">dudi =</span> iris_pca,
                      <span class="dt">fac =</span> iris<span class="op">$</span>Species,
                      <span class="dt">scannf =</span> <span class="ot">FALSE</span>)</code></pre>
<p>La visualisation peut être effectuée directement sur l’objet issu de la fonction <code>discrimin</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(iris_lda)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<p>Il s’agit toutefois d’une visualisation pour le diagnostic davantage que pour la publication. Si l’objectif est la pubilcation, vous pourriez utiliser la fonction <code>plotDA</code> que j’ai conçue à cet effet. J’ai aussi conçu une <a href="https://raw.githubusercontent.com/essicolo/AgFun/master/plotDA_trad.R">fonction similaire qui utilise le module graphique de base de R</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;https://raw.githubusercontent.com/essicolo/AgFun/master/plotDA_gg.R&quot;</span>)
<span class="kw">plotDA</span>(<span class="dt">scores =</span> iris_lda<span class="op">$</span>li,
       <span class="dt">loadings =</span> iris_lda<span class="op">$</span>fa,
       <span class="dt">fac =</span> iris<span class="op">$</span>Species,
       <span class="dt">level=</span><span class="fl">0.95</span>,
       <span class="dt">facname =</span> <span class="st">&quot;Species&quot;</span>,
       <span class="dt">propLoadings =</span> <span class="dv">1</span>) </code></pre>
<pre><code>## Loading required package: ellipse</code></pre>
<pre><code>## 
## Attaching package: &#39;ellipse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     ellipse</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     pairs</code></pre>
<pre><code>## Loading required package: grid</code></pre>
<pre><code>## Loading required package: plyr</code></pre>
<pre><code>## -------------------------------------------------------------------------</code></pre>
<pre><code>## You have loaded plyr after dplyr - this is likely to cause problems.
## If you need functions from both plyr and dplyr, please load plyr first, then dplyr:
## library(plyr); library(dplyr)</code></pre>
<pre><code>## -------------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;plyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     arrange, count, desc, failwith, id, mutate, rename, summarise,
##     summarize</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     compact</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-87-1.png" width="672" /></p>
<p>À la différence de l’ACP, l’ADL maximise la sépatation des groupes. Nous avions noté avec l’ACP que les dimensions des pétales distingaient les groupes. Puisque nous avions justement des informations sur les groupes, nous aurions pu procéder directement à un ADL pour obtenir des conclusions plus directes. Si la longueur des pétales permet de distinguer l’espèce <em>setosa</em> des deux autres, la largeur des pétales permet de distinguer <em>virginica</em> et <em>versicolor</em>, bien que les nuages de points se superposent. De manière bivariée, les régions de confiance des moyennes des scores discriminants (petites ellipses) montrent des différence significatives au seuil 0.05.</p>
<div class="alert alert-block alert-success">
<strong>Excercice</strong>. Si l’on effectuait l’ADL sur notre dauphin, avec la colonne <code>anatomy</code> comme variable de regroupement, qu’obtiendrions-nous? Si l’on consière la nageoire codale (queue) comme faisant partie du corps? Quelles sont les limitations?
</div>
</div>
</div>
<div id="analyse-de-redondance-rda" class="section level4">
<h4><span class="header-section-number">8.4.2.2</span> Analyse de redondance (RDA)</h4>
<p>En anglais, on la nomme <em>redundancy analysis</em>, souvent abrégée RDA. Elle est utilisée pour résumer les relations linéaires entre des variables réponse et des variables explicatives. La “redondance” se situe dans l’utilisation de deux tableaux de données contenant de l’information concordante. L’analyse de redondance est une manière élégante d’effectuer une régresssion linéaire multiple, où la matrice de valeurs prédites par la régression est assujettie à une analyse en composantes principales. Il est ainsi possible de superposer les scores des variables explicatives à ceux des variables réponse.</p>
<p>Plus précisément, une RDA effectue les étapes suivantes (<a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>) entre une matrice de variables indépendantes (explicatives) <span class="math inline">\(X\)</span> et une matrice de variables dépendantes (réponse) <span class="math inline">\(Y\)</span>.</p>
<div id="regression-entre-y-et-x" class="section level5">
<h5><span class="header-section-number">8.4.2.2.1</span> 1. Régression entre <span class="math inline">\(Y\)</span> et <span class="math inline">\(X\)</span></h5>
<p>Pour chacune des variables réponse de <span class="math inline">\(Y\)</span> (<span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span>, , <span class="math inline">\(y_j\)</span>), effectuer une régression linéaire sur les variables explicatives <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[\hat{y}_j = b_j + m_{1, j} \times x_1 + m_{2, j} \times x_2 + ... + m_{i, j} \times x_i\]</span></p>
<p><span class="math display">\[\hat{y}_j = y_j + y_{res, j}\]</span></p>
<p>Pour chaque observation (<span class="math inline">\(n\)</span>), nous obtenons une série de valeurs de <span class="math inline">\(\hat{y}_j\)</span> et de <span class="math inline">\(y_{res, j}\)</span>. Donc chaque cellule de la matrice <span class="math inline">\(Y\)</span> a ses pendant <span class="math inline">\(\hat{y}\)</span> et <span class="math inline">\(y_{res}\)</span>. Nous obtenons ainsi une matrice de prédiction <span class="math inline">\(\hat{Y}\)</span> et une matrice des résidus <span class="math inline">\(Y_{res} = Y - \hat{Y}\)</span>.</p>
</div>
<div id="analyse-en-composantes-principales-1" class="section level5">
<h5><span class="header-section-number">8.4.2.2.2</span> 2. Analyse en composantes principales</h5>
<p>Ensuite, on effectue une analyse en composantes principales (ACP) sur la matrice des prédictions <span class="math inline">\(\hat{Y}\)</span>. On obtient ainsi ses valeurs et vecteurs propres. Nommons <span class="math inline">\(U\)</span> ses vecteurs propres. Les fonctions de RDA mettent souvent ces veceturs à l’échelle avant de les retourner à l’utilisateur. En ordination écologique, ces vecteurs mis à l’échelle sont souvent appelés les <em>scores des espèces</em>, bien qu’il ne s’agisse pas nécessairement d’espèces, mais plus généralement des variables de la matrice dépendante <span class="math inline">\(Y\)</span>.</p>
<p>Il est aussi possible d’effectuer une ACP sur <span class="math inline">\(Y_{res}\)</span>.</p>
</div>
<div id="calculer-les-scores" class="section level5">
<h5><span class="header-section-number">8.4.2.2.3</span> 3. Calculer les scores</h5>
<p>Les vecteurs propres <span class="math inline">\(U\)</span> sont utilisés pour calculer les <em>scores des sites</em>, <span class="math inline">\(Y \times U\)</span>, ainsi que les <em>contraintes de site</em> <span class="math inline">\(\hat{Y} \times U\)</span>.</p>
</div>
<div id="application-6" class="section level5">
<h5><span class="header-section-number">8.4.2.2.4</span> Application</h5>
<p>Nous allons utiliser la fonction <code>rda</code> du module vegan. En ce qui a trait aux données, utilisons les données varespec (matrice Y) et varechem (matrice X). La fonction <code>rda</code> peut fonctionner avec l’interface-formule de R, où à gauche du <code>~</code> on retrouve le Y (la matrice de la communauté écologique, i.e. les abondances d’espèces) contre le X (l), à gauche, ce qui peut être pratique pour l’analyse d’intéractions. Mais pour comparer deux matrices, nous pouvons définir X et Y. Ce qui est mélangeant, c’est que vegan, contrairement aux conventions, défini X comme étant la matrice réponse et Y comme étant la matrice explicative.</p>
<pre class="sourceCode r"><code class="sourceCode r">vare_rda &lt;-<span class="st"> </span><span class="kw">rda</span>(<span class="dt">X =</span> varespec, <span class="dt">Y =</span> vareclr, <span class="dt">scale =</span> <span class="ot">FALSE</span>)
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">ordiplot</span>(vare_rda, <span class="dt">scaling =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Scaling 1: triplot de distance&quot;</span>)
<span class="kw">ordiplot</span>(vare_rda, <span class="dt">scaling =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;Scaling 2: triplot de corrélation&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-88-1.png" width="960" /></p>
<p>La fonction <code>ordiplot</code> permet de créer un triplot de base. La représentation des wascores est réputée plus robuste (moins susceptible d’être bruitée), mais leur interprétation porte à confusion (<a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>).</p>
<p><strong>Triplot de distance (scaling 1)</strong>. Les angles entre les variables explicatives représentent leur corrélation (non pas les variables réponse).</p>
<p><strong>Triplot de corrélation (scaling 2)</strong>. Les angles entre les variables représentent leurs corrélation, que les variables soient réponse ou explicative, ou entre variables réponses et variables explicatives. Les distances entre les objets sur le triplot ne sont pas des approximation de leur distance euclidienne.</p>
<p>Les triplots montrent que les variables ont toutes un rôle important sur la dispersion des sites autours des axeds principaux. Le premier axe principal est composé de manière plus marquée par le clr de l’Al et celui du Fe. Le deuxième axe principal est composé de manière plus marquée par le clr du S, du P et du K. Le triplot de corrélation ne présente pas de tendance appréciable pour la plupart des espèces, qui ne possèdent pas de niche particulière. Toutefois, l’espèce Cladstel, présente surtout dans les sites 9 et 10, est liée à de basses teneurs en N et à de faibles valeurs de Baresoil (sol nu). L’espèce Pleuschr est liée à des sols où l’on retrouve une grande épaisseur d’humus, ainsi que des teneurs élevées en nutriment K, P, S, Ca, Mg et Zn. Elle semble apprécier les sols à bas pH, mais à faible teneur en Fe et Al. La teneur en N lui semble plus indifférente (son vecteur étant presque perpendiculaire).</p>
<p>On pourra personnaliser les graphiques en extrayant les scores.</p>
<pre class="sourceCode r"><code class="sourceCode r">scaling &lt;-<span class="st"> </span><span class="dv">2</span>
sites &lt;-<span class="st"> </span><span class="kw">scores</span>(vare_rda, <span class="dt">display =</span> <span class="st">&quot;wa&quot;</span>, <span class="dt">scaling =</span> scaling)
species &lt;-<span class="st"> </span><span class="kw">scores</span>(vare_rda, <span class="dt">display =</span> <span class="st">&quot;species&quot;</span>, <span class="dt">scaling =</span> scaling)
env &lt;-<span class="st"> </span><span class="kw">scores</span>(vare_rda, <span class="dt">display =</span> <span class="st">&quot;reg&quot;</span>, <span class="dt">scaling =</span> scaling)

<span class="kw">plot</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">5</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>), <span class="dt">asp =</span> <span class="dv">1</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">v =</span> <span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;grey80&quot;</span>)
<span class="kw">text</span>(sites<span class="op">/</span><span class="dv">2</span>, <span class="dt">labels =</span> <span class="kw">rownames</span>(sites), <span class="dt">cex =</span> <span class="fl">0.7</span>, <span class="dt">col =</span> <span class="st">&quot;grey50&quot;</span>)
<span class="kw">text</span>(species<span class="op">/</span><span class="dv">2</span>, <span class="dt">labels =</span> <span class="kw">rownames</span>(species), <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>, <span class="dt">cex =</span> <span class="fl">0.7</span>)
<span class="kw">segments</span>(<span class="dt">x0 =</span> <span class="dv">0</span>, <span class="dt">y0 =</span> <span class="dv">0</span>, <span class="dt">x =</span> env[, <span class="dv">1</span>], <span class="dt">y =</span> env[, <span class="dv">2</span>], <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">text</span>(env, <span class="dt">labels =</span> <span class="kw">rownames</span>(env), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">cex =</span> <span class="dv">1</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-89-1.png" width="576" /></p>
<p>On pourra effectuer une analyse de Kaiser-Guttmann ou de broken-stick de la même manière que précédemment. Étant une collection de régressions, une RDA est en mesure d’effectuer des tests statistiques sur les coefficients de la régression en utilisant des permutations pour tester la signification des coefficients et des axes d’une RDA. On doit néanmoins obligatoirement effectuer la RDA avec l’interface formule. L’a variable de gauche’objet à gauche du <code>~</code> peut être une matrice ou un tableau, et celui de droite est défini dans <code>data</code>. Le <code>.</code> dans l’interface formule signifie “une combinaison linéaire de toutes les variables, sans intéraction”.</p>
<pre class="sourceCode r"><code class="sourceCode r">vare_rda &lt;-<span class="st"> </span><span class="kw">rda</span>(varespec <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> vareclr, <span class="dt">scale =</span> <span class="ot">FALSE</span>)
perm_test_term &lt;-<span class="st"> </span><span class="kw">anova</span>(vare_rda, <span class="dt">by =</span> <span class="st">&quot;term&quot;</span>)
<span class="co">#perm_test_axis &lt;- anova(vare_rda, by = &quot;axis&quot;)</span></code></pre>
<p>La signification des axes est difficile à interpréter. Toutefois, celui des variables présente un intérêt.</p>
<pre class="sourceCode r"><code class="sourceCode r">perm_test_term</code></pre>
<pre><code>## Permutation test for rda under reduced model
## Terms added sequentially (first to last)
## Permutation: free
## Number of permutations: 999
## 
## Model: rda(formula = varespec ~ N + P + K + Ca + Mg + S + Al + Fe + Mn + Zn + Mo + Fv + Baresoil + Humdepth + pH, data = vareclr, scale = FALSE)
##          Df Variance      F Pr(&gt;F)   
## N         1   216.13 4.8470  0.008 **
## P         1   272.71 6.1159  0.004 **
## K         1   194.97 4.3724  0.017 * 
## Ca        1    24.92 0.5589  0.679   
## Mg        1    52.61 1.1799  0.356   
## S         1   100.07 2.2441  0.103   
## Al        1   177.91 3.9900  0.021 * 
## Fe        1   118.59 2.6595  0.072 . 
## Mn        1    25.96 0.5822  0.611   
## Zn        1    35.81 0.8030  0.478   
## Mo        1    23.51 0.5273  0.703   
## Baresoil  1    98.64 2.2122  0.103   
## Humdepth  1    43.59 0.9777  0.374   
## pH        1    38.93 0.8730  0.445   
## Residual  9   401.31                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>La p-value est la probabilité que les pentes calculées pour les variables émergent de distributions dont la moyenne est nulle. Au seuil 0.05, les variables significatives sont (les clr de) l’azote, le phosphore, le potassium et l’aluminium.</p>
<p>Dans le cas des matrices d’abondance (ce n’est pas le cas de varespec, constituée de données de recouvrement), il est préférable avec les RDA de les transformer préalablement avec la transformation compositionnelle, de chord ou de Hellinger (chapitre 6). Une autre option est d’effectuer une RDA sur des matrices d’association en passant par une analyse en coordonnées principales (<a href="http://www.jstor.org/stable/2657192">Legendre et Anderson, 1999</a>). Enfin, les données d’abondance à l’état brutes devraient plutôt passer utiliser une analyse canonique des corrélations.</p>
</div>
</div>
<div id="analyse-canonique-des-correspondances-acc" class="section level4">
<h4><span class="header-section-number">8.4.2.3</span> Analyse canonique des correspondances (ACC)</h4>
<p>L’analyse canonique des correspondances (<em>Canonical correspondance analysis</em>), ACC, a été à l’origine conçue pour étudier les liens entre des variables environnementales et l’abondance (décompte) ou l’occurence (présence-absence) d’espèces (<a href="https://www.ohio.edu/plantbio/staff/mccarthy/multivariate/terBraak1986.pdf">ter Braak, 1986</a>). L’ACC est à la RDA ce que la CA est à l’ACP. Alors que la RDA préserve les distance euclidiennes entre variables dépendantes et indpendantes, l’ACC préserve les distances du <span class="math inline">\(\chi^2\)</span>. Tout comme l’AC, elle hérite du coup une propriété importate de la distance du <span class="math inline">\(\chi^2\)</span>: il y a davantage davantage d’importance aux espèces rares.</p>
<p>L’analyse des correspondances canoniques est souvent utilisée dans la littérature, mais dans bien des cas une RDA sur des données d’abondance transformées donnera des résultats davantage intérprétables (<a href="https://doi.org/10.1007/s004420100716">Legendre et Gallagher, 2001</a>).</p>
<div id="application-7" class="section level5">
<h5><span class="header-section-number">8.4.2.3.1</span> Application</h5>
<p>Cet exemple d’application concerne des données d’abondance. Nous allons conséquemment utiliser une CCA avec la fonction <code>cca</code>, toujours avec le module vegan.</p>
<p>Les tableaux <a href="https://rdrr.io/cran/ade4/man/doubs.html"><code>doubs_fish</code> et <code>doubs_env</code></a> comprennent respectivement des données d’abondance d’espèces de poissons et dans différents environnements de la rivière Doubs (Europe) publiées dans <a href="https://www.worldcat.org/title/cours-deau-de-franche-comte-massif-du-jura-recherches-ecologiques-sur-le-reseau-hydrographique-du-doubs-essai-de-biotypologie/oclc/496763306">Verneaux. (1973)</a> et exportées du module <a href="https://rdrr.io/rforge/ade4/"><code>ade4</code></a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;doubs&quot;</span>)
doubs_fish &lt;-<span class="st"> </span>doubs<span class="op">$</span>fish
doubs_env &lt;-<span class="st"> </span>doubs<span class="op">$</span>env</code></pre>
<p>Sur le site no 8, aucun poisson n’a pas été observé. Les observations ne comprenant que des zéro doivent être préalablement retirées.</p>
<pre class="sourceCode r"><code class="sourceCode r">tot_spec &lt;-<span class="st"> </span>doubs_fish <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">tot_spec =</span> <span class="kw">apply</span>(., <span class="dv">1</span>, sum))
doubs_fish &lt;-<span class="st"> </span>doubs_fish <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(tot_spec <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>)
doubs_env &lt;-<span class="st"> </span>doubs_env <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(tot_spec <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>)</code></pre>
<p>De la même manière qu’avec la fonction <code>rda</code> de vegan, nous utilisons <code>cca</code> pour l’ACC.</p>
<pre class="sourceCode r"><code class="sourceCode r">doubs_cca &lt;-<span class="st"> </span><span class="kw">cca</span>(doubs_fish <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> doubs_env, <span class="dt">scale =</span> <span class="ot">FALSE</span>)</code></pre>
<p>Comparons les résultats</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">ordiplot</span>(doubs_cca, <span class="dt">scaling =</span> <span class="dv">1</span>, <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;CCA - Scaling 1 - Triplot de distance&quot;</span>)
<span class="kw">ordiplot</span>(doubs_cca, <span class="dt">scaling =</span> <span class="dv">2</span>, <span class="dt">type =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">main =</span> <span class="st">&quot;CCA - Scaling 2 - Triplot de corrélation&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-95-1.png" width="960" /></p>
<p><strong>Triplot de distance (scaling 1)</strong>.</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>La projection des variables réponse à angle droit sur les variables explicatives est une approximation de la réponse sur l’explication. (2) Un objet (site ou réponse) situé près d’une variable explicative est plus susceptible d’avoir le décompte <code>1</code>. (3) Les distances entre les variables (réponse et explicatives) approximent la distance du <span class="math inline">\(\chi^2\)</span> (traduction adaptée de <a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>).</li>
</ol>
</blockquote>
<p><strong>Triplot de corrélation (scaling 2)</strong>.</p>
<blockquote>
<ol style="list-style-type: decimal">
<li>La valeur optmiale de l’espèce sur une variable environnementale quantitative peut être obtenue en projetant l’espèce à angle droit sur al variable. (2) Une espèce se trouvant près d’une variable environnementale est susceptible de se trouver en plus grande abondance aux sites de statut <code>1</code> pour cette variable. (3) Les distances n’approximent pas la distance du <span class="math inline">\(\chi^2\)</span> (traduction adaptée de <a href="http://www.springer.com/us/book/9781441979759">Borcard et al. (2011)</a>).</li>
</ol>
</blockquote>

</div>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapitre-explorer.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapitre-outliers.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
