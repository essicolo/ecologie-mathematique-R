[
["chapitre-outliers.html", "10 D√©tection de valeurs aberrantes et imputation de donn√©es manquantes 10.1 Donn√©es manquantes: d√©finition, origine, typologie et traitement 10.2 Valeurs et √©chantillons aberrants: d√©finition, origines, m√©thodes de d√©tection et traitement", " 10 D√©tection de valeurs aberrantes et imputation de donn√©es manquantes Ô∏è Objectifs sp√©cifiques: √Ä la fin de ce chapitre, vous saurez comment proc√©der √† l‚Äôimputation de valeurs manquantes en mode univari√© et multivari√© saurez comment d√©tecter des valeurs aberrantes en mode univari√© et multivari√© Note. Ce chapitre a √©t√© initialement r√©dig√© par Zonlehoua Coulibali, qui a gracieusement accept√© de contribuer √† ces notes de cours. Le texte a √©t√© adapt√© au format du manuel par Serge-√âtienne Parent. Les donn√©es √©cologiques sont g√©n√©ralement recueillies √† diff√©rentes √©chelles, concernent plusieurs sites et plusieurs variables (corr√©l√©es ou non), impliquent diff√©rents individus de diff√©rentes agences et peuvent s‚Äô√©tendre sur plusieurs ann√©es (Alameddine et al., 2010; Lokupitiya et al., 2006). De ce fait, la plupart de ces bases de donn√©es contiennent des valeurs manquantes et/ou aberrantes li√©es √† diff√©rentes sources d‚Äôerreurs, pouvant parfois limiter l‚Äôutilit√© des inf√©rences statistiques (Collins et al., 2001; Glasson-Cicognani et Berchtold, 2010). Il convient alors de les traiter correctement avant d‚Äôeffectuer les analyses statistiques car les ignorer peut entra√Æner, outre une perte de pr√©cision, de forts biais dans les mod√®les d‚Äôanalyse (Alameddine et al., 2010; Filzmoser et al., 2008; Glasson-Cicognani et Berchtold, 2010). 10.1 Donn√©es manquantes: d√©finition, origine, typologie et traitement 10.1.1 D√©finition Les tableaux de donn√©es sont organis√©s en lignes et colonnes. Les lignes repr√©sentent les observations, les unit√©s, les sujets ou les cas √©tudi√©s selon le contexte, et les colonnes repr√©sentent les variables mesur√©es pour chaque observation. Les entr√©es qui sont les valeurs (ou contenus) des cellules ou encore les valeurs observ√©es, peuvent √™tre des valeurs continues, ou des valeurs cat√©goriales (Little et Rubin, 2002). Consid√©rant une variable al√©atoire \\(X\\) quelconque, une donn√©e manquante \\(x_m\\), est une donn√©e pour laquelle la valeur de la variable \\(X\\) est inconnue (ou absente). En d‚Äôautres termes, on ne dispose pas de la valeur de \\(X\\) pour le sujet \\(i\\) donn√©. C‚Äôest une donn√©e non disponible qui serait utile pour l‚Äôanalyse si elle √©tait observ√©e (Ware et al., 2012). La litt√©rature sur les donn√©es manquantes est plus abondante dans les domaines des sciences sociales sur les donn√©es d‚Äôenqu√™tes, et des sciences m√©dicales (Davey et al., 2001; Graham, 2012). Pour repr√©senter leur r√©partition dans la table de donn√©es, une matrice indicatrice des valeurs manquantes \\(M = (m_{ij})\\) est g√©n√©ralement utilis√©e o√π \\(m_{ij}\\) est une variable binaire qui prend la valeur 1 si la valeur de la variable (\\(X\\)) est observ√©e et 0 si \\(x\\) est absent (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002). 10.1.2 Origines des donn√©es manquantes Les donn√©es manquantes ont des origines mat√©rielles diverses. Des valeurs peuvent √™tre absentes soit parce qu‚Äôelles n‚Äôont pas √©t√© observ√©es, ou qu‚Äôelles ont √©t√© perdues ou √©taient incoh√©rentes (Glasson-Cicognani et Berchtold, 2010. La donn√©e peut avoir √©t√© perdue lors de la collecte ou du processus d‚Äôenregistrement des donn√©es, non mesur√©e en raison du dysfonctionnement d‚Äôun √©quipement, non mesurable en raison de la disparition du sujet d‚Äô√©tude (mort, fugue, champ non r√©colt√©, etc.), √©cart√©e en raison d‚Äôune contamination, oubli√©e, non √©tudi√©e, etc. 10.1.3 Profils des donn√©es manquantes Les auteurs traitant des donn√©es manquantes distinguent des formes de r√©partition des donn√©es manquantes et des m√©canismes conduisant √† ces derni√®res. La r√©partition des donn√©es manquantes d√©crit les dispositions des valeurs pr√©sentes et celles qui sont manquantes dans la matrice indicatrice. Les m√©canismes √† l‚Äôorigine des donn√©es manquantes d√©crivent la relation probabiliste entre les valeurs observ√©es et les valeurs manquantes de la table de donn√©es. 10.1.3.1 R√©partition des donn√©es manquantes Les donn√©es manquantes se r√©partissent selon diff√©rents cas de figures (Graham, 2012; Little et Rubin, 2002) dont les trois principaux sont les valeurs manquantes univari√©es, les valeurs manquantes monotones et celles non monotones ou arbitraires. Cette distinction est fonction de la matrice indicatrice des valeurs manquantes. Cette matrice est dite √† valeurs manquantes univari√©es ou de non-r√©ponse univari√©e, lorsque pour une variable donn√©e, si une observation est absente, alors toutes les observations suivantes pour cette variable sont absentes (figure 10.1a). En exp√©rimentation agricole, ce cas de figure est qualifi√© de probl√®me de la parcelle manquante o√π, pour une raison quelconque (par exemple : une absence de germination, une destruction accidentelle d‚Äôune parcelle ou des enregistrements incorrects), un facteur √† l‚Äô√©tude est non disponible. Les valeurs manquantes monotones surviennent lorsque la valeur d‚Äôune variable \\(Y_j\\) manquante pour un individu \\(i\\) implique que toutes les variables suivantes \\(Y_k\\) (\\(k &gt; j\\)) sont manquantes pour cet individu (figure 10.1b). Les valeurs manquantes arbitraires ou non monotones ou encore g√©n√©rales, surviennent lorsque la matrice ne dessine sp√©cifiquement aucune des formes pr√©c√©dentes (figure 10.1c). Figure 10.1: Exemple de profils de donn√©es manquantes Le module VIM permet de visualiser la structure des donn√©es manquantes. ## Loading required package: colorspace ## Loading required package: grid ## Loading required package: data.table ## VIM is ready to use. ## Since version 4.0.0 the GUI is in its own package VIMGUI. ## ## Please use the package to use the new (and old) GUI. ## Suggestions and bug-reports can be submitted at: https://github.com/alexkowa/VIM/issues ## ## Attaching package: &#39;VIM&#39; ## The following object is masked from &#39;package:datasets&#39;: ## ## sleep ## -- Attaching packages ---------------------------------------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.0 v purrr 0.3.3 ## v tibble 3.0.0 v dplyr 0.8.5 ## v tidyr 1.0.2 v stringr 1.4.0 ## v readr 1.3.1 v forcats 0.5.0 ## -- Conflicts ------------------------------------------------- tidyverse_conflicts() -- ## x dplyr::between() masks data.table::between() ## x dplyr::filter() masks stats::filter() ## x dplyr::first() masks data.table::first() ## x dplyr::lag() masks stats::lag() ## x dplyr::last() masks data.table::last() ## x purrr::transpose() masks data.table::transpose() Pour l‚Äôexemple, prenons le tableau iris puis rempla√ßons au hasard des donn√©es par des valeurs manquantes (NA), puis v√©rifions les proportions de donn√©es manquantes et les proportions de combinaisons de donn√©es manquantes. set.seed(2868374) data(&quot;iris&quot;) iris_NA &lt;- iris n_NA &lt;- 20 row_NA &lt;- sample(1:nrow(iris), n_NA, replace = TRUE) col_NA &lt;- sample(1:ncol(iris), n_NA, replace = TRUE) for (i in 1:n_NA) iris_NA[row_NA[i], col_NA[i]] &lt;- NA summary(aggr(iris_NA, sortVar = TRUE)) ## ## Variables sorted by number of missings: ## Variable Count ## Sepal.Width 0.046666667 ## Species 0.040000000 ## Petal.Length 0.020000000 ## Petal.Width 0.020000000 ## Sepal.Length 0.006666667 ## ## Missings per variable: ## Variable Count ## Sepal.Length 1 ## Sepal.Width 7 ## Petal.Length 3 ## Petal.Width 3 ## Species 6 ## ## Missings in combinations of variables: ## Combinations Count Percent ## 0:0:0:0:0 132 88.0000000 ## 0:0:0:0:1 4 2.6666667 ## 0:0:0:1:0 2 1.3333333 ## 0:0:0:1:1 1 0.6666667 ## 0:0:1:0:0 3 2.0000000 ## 0:1:0:0:0 6 4.0000000 ## 0:1:0:0:1 1 0.6666667 ## 1:0:0:0:0 1 0.6666667 Avec la fonction matrixplot, il est possible de visualiser les donn√©es manquantes en rouge, tandis que les donn√©es pr√©sentes prennent un niveau de gris selon leur valeur. matrixplot(iris_NA) 10.1.3.2 M√©canismes conduisant aux donn√©es manquantes Les m√©canismes conduisant aux donn√©es manquantes d√©crivent la relation entre les valeurs manquantes et celles observ√©es des variables de la table (Collins et al., 2001; Graham, 2012; Little et Rubin, 2002). En consid√©rant la table de donn√©e \\(Y = \\{O,M\\}\\) o√π \\(O = \\left[ o_{i, j} \\right]\\) repr√©sente les donn√©es observ√©es et \\(M = \\left[ m_{i, j} \\right]\\) la matrice indicatrice des donn√©es manquantes, le m√©canisme √† l‚Äôorigine des donn√©es manquantes est d√©fini par la distribution conditionnelle de \\(M\\) sachant \\(Y\\). Lorsque la probabilit√© qu‚Äôune valeur soit manquante ne d√©pend ni des valeurs observ√©es, ni de celles manquantes, les donn√©es sont dites manquantes compl√®tement au hasard (* MCAR, missing completely at random*). La probabilit√© d‚Äôabsence est donc la m√™me pour toutes les observations et elle ne d√©pend que de param√®tres ext√©rieurs ind√©pendants de cette variable (Collins et al., 2001; Graham, 2012; Heitjan, 1997; Little et Rubin, 2002; Rubin, 1976). Avec de telles donn√©es (MCAR), les r√©gressions qui n‚Äôutilisent que les enregistrements complets, les moyennes des cas disponibles, les tests non-param√©triques et les m√©thodes bas√©es sur les ‚Äúmoments‚Äù, sont toutes valides (Heitjan, 1997). Toutefois, une perte de pr√©cision est √† pr√©voir dans les r√©sultats (Collins et al., 2001). Selon les m√™mes auteurs, lorsque la probabilit√© qu‚Äôune valeur soit manquante d√©pend uniquement de la composante observ√©e ‚ÄúO‚Äù (une ou plusieurs variables observ√©es) mais pas des valeurs manquantes elles-m√™mes, les donn√©es sont dites manquantes au hasard (* MAR: missing at random*). Dans ce cas, les m√©thodes du maximum de vraisemblance sont valides pour estimer les param√®tres du mod√®le. Les proc√©dures d‚Äôimputation multiples utilisent implicitement le m√©canisme MAR (Collins et al., 2001; Heitjan, 1997). Lorsque la probabilit√© qu‚Äôune valeur manque d√©pend de la valeur non observ√©e de la variable elle-m√™me (\\(M\\)), les donn√©es ne manquent pas au hasard (* MNAR: missing not at random*). Ce type de donn√©es ne doit pas √™tre ignor√© dans l‚Äôajustement de mod√®les car elles induisent une perte de pr√©cision (inh√©rente √† tout cas de donn√©es manquantes) mais aussi un biais dans l‚Äôestimation des param√®tres (Collins et al., 2001; Heitjan, 1997). 10.1.4 Traitement des donn√©es manquantes La pr√©sence de donn√©es manquantes dans une analyse peut conduire √† des estim√©s de param√®tres biais√©s, gonfler les erreurs de type I et II, baisser les performances des intervalles de confiance (Collins et al., 2001) et entacher la g√©n√©ralisation des r√©sultats (Taylor et al., 2002). Plusieurs m√©thodes existent pour calculer des estim√©s de param√®tres de mod√®les approximativement sans biais, en pr√©sence de donn√©es manquantes. 10.1.4.1 L‚Äôanalyse des cas complets Cette m√©thode consiste √† exclure du fichier de donn√©es tous les individus ayant au moins une donn√©e manquante (Glasson-Cicognani et Berchtold, 2010. Elle serait la plus utilis√©e pour traiter les valeurs manquantes mais n‚Äôest efficace que pour les cas de donn√©es manquant compl√®tement au hasard (MCAR) lorsque le nombre de d‚Äôobservations √† √©liminer n‚Äôest pas trop important (Davey et al., 2001). En R, de mani√®re g√©n√©rique, il est possible d‚Äôidentifier une donn√©e manquante dans un tableau, une matrice ou un vecteur avec is.na, qui retourne un objet bool√©en (TRUE / FALSE). La fonction any permet d‚Äôidentifier si au moins une valeur est vraie ou fausse dans un objet, alors que la fonction all permet d‚Äôidentifier si toutes les valeurs sont vraies. On pourra v√©rifier si une ligne contient une valeur manquante avec la fonction apply, dans l‚Äôaxe des lignes. Il faudra toutefois inverser le r√©sultat bool√©en avec un ! pour faire en sorte que l‚Äôon √©carte les valeurs manquantes. row_missing &lt;- iris_NA %&gt;% filter(apply(., 1, function(x) any(is.na(x)))) row_complete &lt;- iris_NA %&gt;% filter(!apply(., 1, function(x) any(is.na(x)))) row_missing ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4.6 3.4 1.4 0.3 &lt;NA&gt; ## 2 5.7 NA 1.5 0.4 setosa ## 3 4.4 NA 1.3 0.2 setosa ## 4 5.1 NA 1.9 0.4 setosa ## 5 6.7 3.1 4.4 1.4 &lt;NA&gt; ## 6 6.2 2.2 4.5 NA versicolor ## 7 6.7 NA 5.0 1.7 versicolor ## 8 7.1 NA 5.9 2.1 virginica ## 9 6.7 NA 5.8 1.8 virginica ## 10 6.4 2.7 NA 1.9 virginica ## 11 6.5 NA 5.5 1.8 &lt;NA&gt; ## 12 5.6 2.8 4.9 NA virginica ## 13 7.7 2.8 6.7 2.0 &lt;NA&gt; ## 14 6.4 2.8 5.6 NA &lt;NA&gt; ## 15 6.3 2.8 NA 1.5 virginica ## 16 6.1 2.6 5.6 1.4 &lt;NA&gt; ## 17 NA 3.1 5.5 1.8 virginica ## 18 6.7 3.0 NA 2.3 virginica Au lieu de apply, R fournit la fontion raccourci complete.cases. row_missing &lt;- iris_NA %&gt;% filter(complete.cases(.)) Le module tidyr (inclus dans tidyverse) nous facilite la vie avec la fonction tidyr::drop_na, qui retire toutes les lignes contenant au moins une valeur manquante. row_complete &lt;- iris_NA %&gt;% drop_na() De m√™me, on pourra √©valuer la proportion de donn√©es manquantes. nrow(row_complete) / nrow(iris) ## [1] 0.88 Ou bien, √©valuer la proportion de donn√©e manquante par groupe. iris_NA %&gt;% group_by(Species) %&gt;% summarise_each(funs(sum(is.na(.))/length(.))) ## Warning: Factor `Species` contains implicit NA, consider using ## `forcats::fct_explicit_na` ## Warning: funs() is soft deprecated as of dplyr 0.8.0 ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once per session. ## # A tibble: 4 x 5 ## Species Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 setosa 0 0.0612 0 0 ## 2 versicolor 0 0.0204 0 0.0204 ## 3 virginica 0.0217 0.0435 0.0652 0.0217 ## 4 &lt;NA&gt; 0 0.167 0 0.167 Pour terminer cette section, il est possible que certaines variables soient peu mesur√©es dans une √©tude. Au jugement, on pourra sacrifier une colonne contenant plusieurs donn√©es manquantes en vue de conserver des lignes. 10.1.4.2 L‚Äôimputation L‚Äôimputation permet de cr√©er des bases de donn√©es compl√®tes (Donz√©, 2001). Elle corrige la non-r√©ponse partielle en substituant une ‚Äúvaleur artificielle‚Äù √† la valeur manquante. Les auteurs distinguent l‚Äôimputation unique et l‚Äôimputation multiple. 10.1.4.2.1 L‚Äôimputation unique L‚Äôimputation unique consiste √† remplacer chaque donn√©e manquante par une seule valeur plausible telle que la moyenne calcul√©e sur les donn√©es r√©ellement observ√©es, l‚Äôimputation par le ou les plus proche(s) voisin(s) (la technique des plus proches voisins est couverte au chapitre 12). Cette derni√®re remplace les donn√©es manquantes par des valeurs provenant d‚Äôindividus similaires pour lesquels toute l‚Äôinformation a √©t√© observ√©e. L‚Äôimputation peut aussi se faire par r√©gression en rempla√ßant les valeurs manquantes par des valeurs pr√©dites selon un mod√®le de r√©gression ou des m√©thodes bay√©siennes plus sophistiqu√©es. L‚Äôimputation unique est valide en pr√©sence de donn√©es manquantes de type MAR (Davey et al., 2001; Donz√©, 2001; Glasson-Cicognani et Berchtold, 2010. Selon Heitjan (1997), il n‚Äôexiste pas de r√®gles strictes pour d√©cider quand il faut entreprendre une imputation multiple. N√©anmoins, si la fraction des observations avec des donn√©es manquantes est inf√©rieure √† par exemple 5%, et le m√©canisme est ignorable (MCAR ou MAR), les analyses les plus simples sont satisfaisantes. Bien que con√ßu principalement pour l‚Äôimputation multiple (on y arrive bient√¥t), le module mice permet l‚Äôimputation univari√©e. Nous allons tester l‚Äôimputation par la moyenne. Voyons par exemple la moyenne des longueurs des s√©pales. mean(iris_NA$Sepal.Length[!complete.cases(iris_NA)], na.rm = TRUE) ## [1] 6.170588 Lan√ßons l‚Äôimputation par la fonction mice, puis la pr√©diction du tableau imput√© par la fonction complete. library(&quot;mice&quot;) iris_mice &lt;- mice(iris_NA, method = &quot;mean&quot;) iris_imp &lt;- complete(iris_mice) Le tableau original peut √™tre compar√© au tableau imput√©. iris_NA[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 &lt;NA&gt; ## 16 5.7 NA 1.5 0.4 setosa ## 39 4.4 NA 1.3 0.2 setosa ## 45 5.1 NA 1.9 0.4 setosa ## 66 6.7 3.1 4.4 1.4 &lt;NA&gt; ## 69 6.2 2.2 4.5 NA versicolor ## 78 6.7 NA 5.0 1.7 versicolor ## 103 7.1 NA 5.9 2.1 virginica ## 109 6.7 NA 5.8 1.8 virginica ## 112 6.4 2.7 NA 1.9 virginica ## 117 6.5 NA 5.5 1.8 &lt;NA&gt; ## 122 5.6 2.8 4.9 NA virginica ## 123 7.7 2.8 6.7 2.0 &lt;NA&gt; ## 133 6.4 2.8 5.6 NA &lt;NA&gt; ## 134 6.3 2.8 NA 1.5 virginica ## 135 6.1 2.6 5.6 1.4 &lt;NA&gt; ## 138 NA 3.1 5.5 1.8 virginica ## 146 6.7 3.0 NA 2.3 virginica iris[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 66 6.7 3.1 4.4 1.4 versicolor ## 69 6.2 2.2 4.5 1.5 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 103 7.1 3.0 5.9 2.1 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 112 6.4 2.7 5.3 1.9 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 122 5.6 2.8 4.9 2.0 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 133 6.4 2.8 5.6 2.2 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica ## 146 6.7 3.0 5.2 2.3 virginica iris_imp[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.600000 3.400000 1.400000 0.300000 &lt;NA&gt; ## 16 5.700000 3.052174 1.500000 0.400000 setosa ## 39 4.400000 3.052174 1.300000 0.200000 setosa ## 45 5.100000 3.052174 1.900000 0.400000 setosa ## 66 6.700000 3.100000 4.400000 1.400000 &lt;NA&gt; ## 69 6.200000 2.200000 4.500000 1.178169 versicolor ## 78 6.700000 3.052174 5.000000 1.700000 versicolor ## 103 7.100000 3.052174 5.900000 2.100000 virginica ## 109 6.700000 3.052174 5.800000 1.800000 virginica ## 112 6.400000 2.700000 3.680142 1.900000 virginica ## 117 6.500000 NA 5.500000 1.800000 &lt;NA&gt; ## 122 5.600000 2.800000 4.900000 1.178169 virginica ## 123 7.700000 2.800000 6.700000 2.000000 &lt;NA&gt; ## 133 6.400000 2.800000 5.600000 NA &lt;NA&gt; ## 134 6.300000 2.800000 3.680142 1.500000 virginica ## 135 6.100000 2.600000 5.600000 1.400000 &lt;NA&gt; ## 138 5.818881 3.100000 5.500000 1.800000 virginica ## 146 6.700000 3.000000 3.680142 2.300000 virginica Dans la colonne Sepal.Length, toutes les valeurs manquantes ont √©t√© remplac√©es par ~5.862. Exercice. Pourquoi la pr√©diction diff√®re-t-elle de la moyenne? üò± Attention. Lorsque les valeurs sont syst√©matiquement manquantes chez une cat√©gorie, les estimateurs seront biais√©s. iris_NA_biais_1 &lt;- tibble(Sepal.Length = c(5.3, NA, 4.9, NA, 4.7, NA), Species = c(&quot;setosa&quot;, &quot;versicolor&quot;, &quot;setosa&quot;, &quot;versicolor&quot;, &quot;setosa&quot;, &quot;versicolor&quot;)) mean(iris_NA_biais_1$Sepal.Length, na.rm = TRUE) ## [1] 4.966667 iris_NA_biais_2 &lt;- tibble(Sepal.Length = c(5.3, 7.0, 4.6, 6.4, 4.8, 6.9), Species = c(&quot;setosa&quot;, &quot;versicolor&quot;, &quot;setosa&quot;, &quot;versicolor&quot;, &quot;setosa&quot;, &quot;versicolor&quot;)) mean(iris_NA_biais_2$Sepal.Length, na.rm = TRUE) ## [1] 5.833333 Dans l‚Äôexemple pr√©c√©dent, les donn√©es sont syst√©matiquement manquantes chez l‚Äôesp√®ce versicolor. La moyenne de la longueur des s√©pales est donc biais√©e, et l‚Äôimputation par la moyenne de sera tout autant. L‚Äôimputation par la moyenne est jug√©e non recommandable par plusieurs statisticiens. Dans la mesure du possible, l‚Äôimputation multiple devrait √™tre favoris√©e √† l‚Äôimputation univari√©e. 10.1.4.2.2 L‚Äôimputation multiple L‚Äôimputation multiple consiste √† imputer plusieurs fois les valeurs manquantes et √† combiner les r√©sultats pour diminuer l‚Äôerreur caus√©e par la compl√©tion (Davey et al., 2001). Les valeurs manquantes sont remplac√©es par \\(M\\) (\\(M &gt; 1\\)) ensembles de valeurs simul√©es donnant lieu √† \\(M\\) versions plausibles mais diff√©rentes des donn√©es compl√®tes (Collins et al., 2001; Taylor et al., 2002). En pratique, seulement \\(M\\) allant de 5 √† 10 (imputations) est suffisant pour produire des bonnes inf√©rences (Collins et al., 2001; Donz√©, 2001). Chacun des \\(M\\) ensembles de donn√©es est analys√© de la m√™me mani√®re par des m√©thodes standards d‚Äôanalyse de donn√©es compl√®tes, et les r√©sultats sont combin√©s en utilisant une arithm√©tique simple: les moyennes des param√®tres estim√©s sont calcul√©es, les erreurs standards sont combin√©es pour refleter l‚Äôincertitude des donn√©es manquantes et l‚Äôerreur d‚Äô√©chantillonnage. L‚Äôimputation multiple est une proc√©dure bas√©e sur un mod√®le (model-based). L‚Äôutilisateur doit sp√©cifier un mod√®le de probabilit√© conjointe pour les donn√©es observ√©es et manquantes (Collins et al., 2001; Taylor et al., 2002). Le module mice donne acc√®s √† plusieurs types de mod√®les (argument method). Les mod√®les cart et rf tombent la la cat√©gorie de l‚Äôautoapprentissage (couvert au chapitre 12). Ils ont l‚Äôavantage important d‚Äô√™tre applicables autant pour tout type de variable. iris_mice &lt;- mice(iris_NA, method = &quot;rf&quot;) iris_imp &lt;- complete(iris_mice) De m√™me que pr√©c√©demment, le tableau original peut √™tre compar√© au tableau imput√©. iris_NA[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 &lt;NA&gt; ## 16 5.7 NA 1.5 0.4 setosa ## 39 4.4 NA 1.3 0.2 setosa ## 45 5.1 NA 1.9 0.4 setosa ## 66 6.7 3.1 4.4 1.4 &lt;NA&gt; ## 69 6.2 2.2 4.5 NA versicolor ## 78 6.7 NA 5.0 1.7 versicolor ## 103 7.1 NA 5.9 2.1 virginica ## 109 6.7 NA 5.8 1.8 virginica ## 112 6.4 2.7 NA 1.9 virginica ## 117 6.5 NA 5.5 1.8 &lt;NA&gt; ## 122 5.6 2.8 4.9 NA virginica ## 123 7.7 2.8 6.7 2.0 &lt;NA&gt; ## 133 6.4 2.8 5.6 NA &lt;NA&gt; ## 134 6.3 2.8 NA 1.5 virginica ## 135 6.1 2.6 5.6 1.4 &lt;NA&gt; ## 138 NA 3.1 5.5 1.8 virginica ## 146 6.7 3.0 NA 2.3 virginica iris[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 setosa ## 16 5.7 4.4 1.5 0.4 setosa ## 39 4.4 3.0 1.3 0.2 setosa ## 45 5.1 3.8 1.9 0.4 setosa ## 66 6.7 3.1 4.4 1.4 versicolor ## 69 6.2 2.2 4.5 1.5 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 103 7.1 3.0 5.9 2.1 virginica ## 109 6.7 2.5 5.8 1.8 virginica ## 112 6.4 2.7 5.3 1.9 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 122 5.6 2.8 4.9 2.0 virginica ## 123 7.7 2.8 6.7 2.0 virginica ## 133 6.4 2.8 5.6 2.2 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 virginica ## 138 6.4 3.1 5.5 1.8 virginica ## 146 6.7 3.0 5.2 2.3 virginica iris_imp[!complete.cases(iris_NA), ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 7 4.6 3.4 1.4 0.3 setosa ## 16 5.7 3.8 1.5 0.4 setosa ## 39 4.4 3.3 1.3 0.2 setosa ## 45 5.1 2.8 1.9 0.4 setosa ## 66 6.7 3.1 4.4 1.4 versicolor ## 69 6.2 2.2 4.5 1.4 versicolor ## 78 6.7 3.0 5.0 1.7 versicolor ## 103 7.1 3.3 5.9 2.1 virginica ## 109 6.7 3.3 5.8 1.8 virginica ## 112 6.4 2.7 4.9 1.9 virginica ## 117 6.5 3.0 5.5 1.8 virginica ## 122 5.6 2.8 4.9 1.7 virginica ## 123 7.7 2.8 6.7 2.0 versicolor ## 133 6.4 2.8 5.6 1.9 virginica ## 134 6.3 2.8 5.1 1.5 virginica ## 135 6.1 2.6 5.6 1.4 versicolor ## 138 6.3 3.1 5.5 1.8 virginica ## 146 6.7 3.0 5.5 2.3 virginica Mieux vauit √©viter d‚Äôimputer des donn√©es compositionnelles transform√©es (alr, clr ou ilr), car l‚Äôimputation d‚Äôune dimension transform√©e aura un impact sur tout le vecteur. Dans ce cas, vous pourriez pr√©f√©rablemen utiliser la fonction robCompositions::impCoda. Vous avez peut-√™tre remarqu√© que le mode tidyverse a √©t√© quelque peu d√©laiss√© dans cette section. Il aurait pu l‚Äô√™tre davantage, mais le mode classique (iris[!complete.cases(iris_NA), ] au lieu de iris %&gt;% drop_na()) semblait mieux convenir pour la diversit√© de fonctions en imputation. Le module recipes, couvert rapidement au chapitre 8, permet d‚Äôeffectuer des op√©rations d‚Äôimputation modernes en pipelines (voir Step Functions - Imputation). Ce module est toutefois en d√©veloppement et ne me semble pas suffisamment mature pour une utilisation professionnelle. Dans le futur, recipes deviendra probablement le module de choix pour l‚Äôimputation. 10.2 Valeurs et √©chantillons aberrants: d√©finition, origines, m√©thodes de d√©tection et traitement 10.2.1 D√©finitions En analyse univari√©e, une valeur aberrante est une ‚Äúdonn√©e observ√©e‚Äù pour une variable qui semble anormale au regard des valeurs dont on dispose pour les autres observations de l‚Äô√©chantillon (Planchon, 2005). En analyse multivari√©e, l‚Äô√©chantillon aberrant r√©sulte d‚Äôune erreur importante se trouvant dans un des composants du vecteur de r√©ponse, ou de petites erreurs syst√©matiques dans chacun de ses composants, et qui de ce fait, ne partage pas les relations entre les variables de la population (Planchon, 2005). La valeur ou l‚Äôobservation aberrante est statistiquement discordante dans le contexte d‚Äôun mod√®le de probabilit√© suppos√© connu (Barnett et Lewis, 1994; Grubbs, 1969; Munoz-Garcia et al., 1990; Pires et Santos-Pereira, 2005). Leur pr√©sence dans les donn√©es peut conduire √† des estimateurs de param√®tres biais√©s et, suite √† la r√©alisation de tests statistiques, √† une interpr√©tation des r√©sultats erron√©e (Planchon, 2005). 10.2.2 Origines Dans une collecte de donn√©es, plusieurs sources de variabilit√© peuvent mener √† des donn√©es aberrantes: la variabilit√© inh√©rente mais inusit√©e ou erreur syst√©matique, l‚Äôerreur de mesure et l‚Äôerreur d‚Äôex√©cution (figure 10.2) (Barnett et Lewis, 1994; Planchon, 2005). Figure 10.2: Sch√©ma g√©n√©ral de traitement des valeurs aberrantes - adapt√© de Barnett et Lewis, 1994 La variabilit√© inh√©rente est celle par laquelle les observations varient naturellement de mani√®re al√©atoire √† travers la population. L‚Äôerreur de mesure renferme les inad√©quations au niveau de la m√©thode de mesure, des instruments de mesure, l‚Äôarrondi des valeurs obtenues ou les erreurs d‚Äôenregistrement. Cette erreur est donc li√©e √† des circonstances bien d√©termin√©es. Les erreurs d‚Äôex√©cution interviennent √©galement dans des circonstances bien d√©termin√©es. Ce sont les erreurs de manipulation, les erreurs commises dans l‚Äôassemblage des donn√©es, ou lors du traitement informatique. L‚Äôexamen des valeurs aberrantes dans une base de donn√©es a pour objectif de les identifier pour soit les supprimer, soit les conserver, ou les corriger avant d‚Äôajuster des mod√®les non robustes (Filzmoser et al., 2008; Planchon, 2005). La valeur extr√™me peut √™tre li√©e √† un √©v√©nement atypique, mais n√©anmoins connu et int√©ressant √† √©tudier. Dans ce cas elle est importante √† conserver. La correction (ou accommodation) √©vite le rejet des observations aberrantes et consiste √† estimer les valeurs des param√®tres de la distribution de base de fa√ßon relativement libre sans d√©formation des r√©sultats li√©s √† leur pr√©sence (Barnett et Lewis, 1994). L‚Äôapproche d‚Äôidentification des observations aberrantes selon Davies et Gather (1993) est de supposer qu‚Äôelles ont une distribution diff√©rente de celle du reste des observations. Reimann et al. (2005) les distinguent ainsi des valeurs extr√™mes qui, bien qu‚Äô√©loign√©es du centre du nuage, appartiennent √† la m√™me distribution que les autres observations. 10.2.3 D√©tection et traitement des valeurs aberrantes univari√©s En analyse univari√©e, les m√©thodes graphiques telles que le diagramme de dispersion des observations class√©es en fonction de leur rang, les boxplots, les graphiques des quantiles de valeurs brutes ou des r√©sidus, permettent de signaler la pr√©sence de valeurs aberrantes (Planchon, 2005). Prenons, par exemple, les donn√©es mtcars. data(&quot;mtcars&quot;) mtcars %&gt;% sample_n(5) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## 2 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## 3 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## 4 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## 5 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 Disons que nous cherchons √† d√©tecter les valeurs aberrantes de la puissance du moteur, soit la colonne hp. On pourrait jeter un oeil √† la colonne hp, mais mieux vaudrait consid√©rer qu‚Äôil ne s‚Äôagit pas de moteurs de m√™me type. De m√™me, si vous consigniez la masse des abeilles d‚Äôesp√®ces dif√©rentes collect√©es dans des trappes, vous risqueriez, en consid√©rant que les masses proviennent d‚Äôune seule distribution, d‚Äô√©carter syst√©matiquement une esp√®ce plus petite ou un autre plus imposante. Examinons donc la puissance des moteurs selon le nombre de cylindres. mtcars %&gt;% ggplot(aes(x = factor(cyl), y = hp)) + geom_boxplot() 10.2.3.1 D√©tection selon la distance interquartile Selon la d√©finition classique d‚Äôun boxplot, un point est affich√© comme aberrant si \\(x &lt; Q_{25\\%}(x) - 1.5 \\times IQR_{25\\%~75\\%}(x)\\) ou \\(x &gt; Q_{75\\%}(x) + 1.5 \\times IQR_{25\\%~75\\%}(x)\\), o√π \\(Q{a}\\) est le quartile pour la probabilit√© \\(a\\) et \\(IQR_{a~b}\\) est la distance entre les quartiles de \\(a\\) et \\(b\\) (\\(b&gt;a\\)). Les probabilit√©s des quartiles (25% et 75%), ainsi que le multiplicateur (1.5) sont arbitraires. On pourra utiliser des fonctions automatiques offertes par des modules sp√©cialis√©s. Mais pour les fonctions simples, pourquoi ne pas les concenvoir soit-m√™me! iqr_01 &lt;- function(x, probs = c(.25, .75), mult = 1.5, na.rm = TRUE) { # x est le vecteur de valeurs # probs est un vecteur de deux valeurs idntifiant les quartiles recherch√©s # mult est le multiplicateur io &lt;- rep(NA, length(x)) # cr√©er un vecteur vide qui consignera si la valeur est aberrante ou non limits &lt;- quantile(x, probs = probs, na.rm = na.rm) # calculer la valeur des quartiles offset &lt;- mult * (limits[2] - limits[1]) # calculer la distance limite des quartiles io[x &gt; (limits[2] + offset) | x &lt; (limits[1] - offset)] &lt;- 0 # si en-de√ßa ou au-del√† des limites io[x &lt;= (limits[2] + offset) &amp; x &gt;= (limits[1] - offset)] &lt;- 1 # si √† l&#39;int√©rieur des limites return(io) } En se servant des possibilit√©s de dplyr, on pourra d√©tecter les valeurs aberrantes par groupe. mtcars %&gt;% group_by(cyl) %&gt;% # grouper par cylindre mutate(io = iqr_01(hp)) %&gt;% # d√©tecter les valeurs aberrantes filter(io == 1) %&gt;% # ne conserver que les valeurs non aberrantes select(-io) # enlever la colonne io cr√©√©e pr√©c√©demment ## # A tibble: 31 x 11 ## # Groups: cyl [3] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ... with 21 more rows Le nouveau tableau est de 31 lignes. La valeur enlev√©e est elle qui apparaissait pr√©c√©demment sur le boxplot. 10.2.3.2 D√©tection selon la cote Z La cote Z est l‚Äô√©cart de la moyenne mesur√©e en terme de nombre d‚Äô√©cart-type. Si une valeur est situ√©e √† 3 √©carts-type de la moyenne, la cote Z est de 3. On pourra d√©tecter les valeurs aberrantes selon la distance des points en terme de cote Z, et retrancher les valeurs qui se situes au-del√† d‚Äôune certaine limite. Il n‚Äôexiste pas de distance standard: √† vous de d√©cider. Mais le nombre 3 est souvent utilis√©. zscore_01 &lt;- function(x, delimiter = 3, na.rm = TRUE) { centered &lt;- x - mean(x, na.rm = na.rm) limit &lt;- delimiter * sd(x, na.rm = na.rm) io &lt;- ifelse(abs(centered) &gt; limit, 0, 1) return(io) } La foncion zscore_01 est con√ßue de la m√™me mani√®re que iqr_01. mtcars %&gt;% group_by(cyl) %&gt;% # grouper par cylindre mutate(io = zscore_01(hp)) %&gt;% # d√©tecter les valeurs aberrantes filter(io == 1) %&gt;% # ne conserver que les valeurs non aberrantes select(-io) # enlever la colonne io cr√©√©e pr√©c√©demment ## # A tibble: 32 x 11 ## # Groups: cyl [3] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ... with 22 more rows Selon ce crit√®re, toutes les valeurs sont conserv√©es. 10.2.4 D√©tection et traitement des √©chantillons aberrants multivari√©s En analyse multivari√©e, il existe deux approches fondamentales d‚Äôidentification des valeurs aberrantes: celles bas√©es sur le calcul de distances et les m√©thodes par projection (Filzmoser et al., 2008; Hadi et al., 2009). 10.2.4.1 Approches bas√©es sur les distances 10.2.4.1.1 La distance de Mahalanobis Les m√©thodes bas√©es sur la distance d√©tectent les valeurs aberrantes en calculant la distance, g√©n√©ralement la distance de Mahalanobis (vue au chapitre 9) entre un point particulier et le centre des donn√©es (Filzmoser et al., 2008; Pires et Santos-Pereira, 2005). Pour un √©chantillon \\(x\\) multivari√©, la distance de Mahalanobis est calcul√©e comme: \\[ \\mathscr{M} = \\sqrt{(\\vec{x}-\\vec{\\mu})^T S^{-1} (\\vec{x}-\\vec{\\mu})}.\\ \\] o√π \\(\\vec{\\mu}\\) est la moyenne arithm√©tique multivari√©e (le centro√Øde) et \\(S\\) la matrice de variance-covariances de l‚Äô√©chantillon, qui doit √™tre invers√©e. Cette distance indique √† quel point chaque observation est √©loign√©e du centre du nuage multivari√© cr√©√© par les donn√©es (Alameddine et al., 2010; Davies et Gather, 1993). D‚Äôapr√®s Alameddine et al. (2010), lorsque les donn√©es sont suppos√©es suivre une distribution normale, les carr√©s des distances \\(\\mathscr{M}\\) calcul√©es peuvent √™tre consid√©r√©s comme suivant une distribution du \\(\\chi^2\\). Par convention, tout point qui a une d√©passant un quantile donn√© de la distribution du \\(\\chi^2\\) (par exemple, \\(\\chi^2_{df = p ; 0.975}\\), le quantile 97,5% avec \\(p\\) (le nombre de variables) degr√©s de libert√©), est consid√©r√© comme atypique et identifi√© comme une valeur aberrante (Filzmoser et al., 2005). Les observations aberrantes multivari√©es peuvent ainsi √™tre d√©finies comme des observations ayant une grande distance de Mahalanobis (\\(\\mathscr{M}^2\\)). L‚Äôinconv√©nient avec les m√©thodes bas√©es sur les distances r√©side dans la difficult√© d‚Äôobtenir des estim√©s robuste de la moyenne \\(\\mu\\) et de la matrice de variance-covariances \\(S\\), puisque la distance de Mahalanobis est elle-m√™me sensible aux donn√©es extr√™mes. De plus, il serait difficile de fixer la valeur critique id√©ale de \\(\\mathscr{M}\\) permettant de s√©parer les valeurs aberrantes des points r√©guliers (Filzmoser et al., 2005; Filzmoser et al., 2008). La fonction sign1 du module mvoutlier d√©tecte les valeurs aberrantes selon un seuil du \\(\\chi^2_{df = 3 ; 0.975}\\) pour les transformations en log-ratio isom√©triques de Al, Fe et K dans un humus (l‚Äôinverse de la matrice de covariance des les log-ratio centr√©s est singuli√®re). library(&quot;mvoutlier&quot;) library(&quot;compositions&quot;) data(&quot;humus&quot;) sbp &lt;- matrix(c(1, 1,-1,-1, 1,-1, 0, 0, 0, 0, 1,-1), ncol = 4, byrow = TRUE) ilr_elements &lt;- humus %&gt;% dplyr::select(Al, Fe, K, Na) %&gt;% ilr(., V = gsi.buildilrBase(t(sbp))) %&gt;% as_tibble(.) %&gt;% dplyr::rename(AlFe_KNa = V1, Al_Fe = V2, K_Na = V3) is_out &lt;- sign1(ilr_elements, qcrit = 0.975)$wfinal01 plot(ilr_elements, col = is_out + 2) La proportion de valeurs aberrantes: sum(is_out == 0) / length(is_out) ## [1] 0.089141 Diff√©rentes m√©thodes robustes (qui s‚Äôaccommodent de la pr√©sence de points extr√™mes) de d√©tection des valeurs aberrantes sont pr√©sent√©es dans la litt√©rature telles que la m√©thode du volume minimum de l‚Äôellipso√Øde (MVE, minimum volume ellipsoid), du d√©terminant minimum de la matrice de covariance (MCD, minimum Covariance matrix determinant), et les estimateurs de type maximum de vraisemblance (M-estimators) (Alameddine et al., 2010; Filzmoser et al., 2008). Ces m√©thodes calculent des distances robustes similaires aux distances de Mahalanobis, mais remplacent les matrices des moyennes et des covariances respectivement par un seuil critique multivari√© robuste (sur \\(\\mu\\)) et un estimateur d‚Äô√©chelle (sur \\(S\\)) qui ne sont pas influenc√©s par les valeurs aberrantes (Alameddine et al., 2010). 10.2.4.1.2 La m√©thode du volume minimum de l‚Äôellipso√Øde (MVE) Le volume minimum de l‚Äôellipso√Øde est le plus petit ellipso√Øde r√©gulier couvrant au moins \\(h\\) √©l√©ments de l‚Äôensemble des donn√©es \\(X = \\{x_1, x_2, ..., x_n \\}\\) o√π l‚Äôestimateur de localisation est le centre de cet ellipso√Øde et l‚Äôestimateur de dispersion correspond √† sa matrice de covariance. \\(h\\) est fix√© √† priori sup√©rieur ou √©gal √† \\(\\frac{n}{2}+1\\), o√π \\(n\\) est le nombre total de points du nuage de donn√©es. Le seuil de d√©tection qui est la fraction des valeurs aberrantes qui, lorsqu‚Äôelle est d√©pass√©e entra√Æne des estim√©s totalement biais√©s est de l‚Äôordre de 50% √† mesure que \\(n\\) augmente (Alameddine et al., 2010; Croux et al., 2002; Filzmoser et al., 2005; Van Aelst et Rousseeuw, 2009). L‚Äôalgorithme MVE est initi√© en choisissant au hasard un ensemble de \\(p+1\\) points de donn√©es pour estimer le mod√®le majoritaire, o√π \\(p\\) est le nombre de variables. Cet ensemble initial est alors augment√© pour contenir les \\(h\\) points de donn√©es. L‚Äôalgorithme passe par plusieurs it√©rations avant de converger sur l‚Äôensemble des points les plus rapproch√©s qui auront le plus petit volume d‚Äôellipso√Øde (Alameddine et al., 2010). Le module MASS comprend la fonction cov.mve √† cet effet. Cette fonction demande le nombre minimal de points que l‚Äôon d√©sire conserver, en absolu. Il s‚Äôagit d‚Äôun nombre entier, alors si l‚Äôon d√©sire en utiliser une fraction (ici, 90%), il faut l‚Äôarrondir. Parmi les sorties de la fonction cov.mve, on retrouve les num√©ros de ligne qui se trouvent √† l‚Äôint√©rieur de l‚Äôellipsoide. library(&quot;MASS&quot;) select &lt;- dplyr::select # pour √©viter que la fonction select du module MASS remplace celle de dplyr min_in &lt;- round(0.9 * nrow(ilr_elements)) # le minimum de points √† garder, 90% du total id_in &lt;- cov.mve(ilr_elements, quantile.used = min_in)$best is_in &lt;- 1:nrow(ilr_elements) %in% id_in plot(ilr_elements, col = is_in + 2) La proportion de valeurs aberrantes: sum(!is_in) / length(is_in) ## [1] 0.1004862 10.2.4.1.3 La m√©thode du d√©terminant minimum de la matrice de covariance (MCD) La m√©thode du d√©terminant minimum de la matrice de covariance a pour objectif de trouver \\(h\\) (\\(h &gt; n\\)) observations de l‚Äôensemble de donn√©es \\(X = \\{x_1, x_2, ..., x_n \\}\\), dont la matrice de covariance a le plus petit d√©terminant. Comme avec la m√©thode MVE, l‚Äôestimateur de localisation est la moyenne de ces \\(h\\) points et celui de la dispersion est proportionnel √† la matrice de covariance (Filzmoser et al., 2005; Hubert et al., 2018; Rousseeuw et Van Driessen, 1999). id_in &lt;- cov.mcd(ilr_elements, quantile.used = min_in)$best is_in &lt;- 1:nrow(ilr_elements) %in% id_in plot(ilr_elements, col = is_in + 2) La proportion de valeurs aberrantes: sum(!is_in) / length(is_in) ## [1] 0.1004862 Mais en cas de dissym√©trie des donn√©es, ces tests (MVE, MCD) ne seraient pas applicables (Planchon, 2005). 10.2.4.2 Les m√©thodes par projection Ces m√©thodes de d√©tection des observations aberrantes trouvent des projections appropri√©es des donn√©es dans lesquelles les observations aberrantes sont facilement apparentes. Ces observations sont ensuite pond√©r√©s pour produire un estimateur robuste pouvant √™tre utilis√© pour identifier les observations aberrantes (Filzmoser et al., 2008). Ces m√©thodes n‚Äôassument pas une distribution particuli√®re des donn√©es mais cherchent des projections utiles. Elles ne sont donc pas affect√©es par la non-normalit√© et s‚Äôappliquent sur divers types de distributions (Filzmoser et al., 2008; Hadi et al., 2009). Le but de cette projection exploratoire est d‚Äôutiliser les donn√©es pour trouver des projections minimales (√† une, deux ou trois dimensions) qui fournissent les vues les plus r√©v√©latrices des donn√©es compl√®tes (Friedman, 1987). La m√©thode attribue un indice num√©rique √† chaque projection en fonction de la densit√© des donn√©es projet√©e pour capturer le degr√© de structure non lin√©aire pr√©sent dans la distribution projet√©e (Friedman, 1987; Hadi et al., 2009). En R, nous revenons au module mvoutlier, mais cette fois-ci avec la fonction sign2. is_out &lt;- sign2(ilr_elements, qcrit = 0.975)$wfinal01 plot(ilr_elements, col = is_out + 2) La proportion de valeurs aberrantes: sum(is_out == 0) / length(is_out) ## [1] 0.102107 "]
]
