[
["chapitre-explorer.html", "8 Explorer R 8.1 R sur le web 8.2 R en chaire et en os 8.3 Quelques outils en √©cologie math√©matique avec R", " 8 Explorer R L‚Äôapprentissage de R peut √™tre √©tourdissant. Cette section est une petite pause fourre-tout qui vous introduira aux nombreuses possibilit√©s de R. Ô∏è¬†Objectifs sp√©cifiques: √Ä la fin de ce chapitre, vous serez en mesure d‚Äôidentifier les sources d‚Äôinformation principales sur le d√©veloppement de R et de ses modules comprendrez l‚Äôimportance du pr√©traitement des donn√©es, en particulier dans le cadre de l‚Äôanalyse de donn√©es compositionnelles, et saurez effectuer un pr√©traitement ad√©quat saurez comment acqu√©rir des donn√©es m√©t√©o d‚ÄôEnvironnement Canada avec le module weathercan saurez identifier les modules d‚Äôanalyse de sols (soiltexture et aqp) saurez comment d√©buter un projet de m√©ta-analyse et de d√©ploiement d‚Äôun logiciel sur R Pour certains, le langage R est un labyrinthe. Pour d‚Äôautres, c‚Äôest une myriade de portes ouvertes. Si vous lisez ce manuel, vous vous √™tes peut-√™tre engag√© dans un labyrinthe dans l‚Äôobjectif d‚Äôy trouver la cl√© qui d√©v√©rouillera une porte bien pr√©cise qui m√®ne √† un tr√©sor, un objet magique‚Ä¶ ou un dipl√¥me. Peut-√™tre aussi prendrez-vous le go√ªt d‚Äôerrer dans ce labyrinthe, explorant ses d√©bouch√©s, pour y d√©nicher au hasard des petits outils et des d√©bouch√©s. S√©quence du jeu vid√©o The legend of Zelda. Cette section est un amalgame de plusieurs outils de R pertinents en analyse √©cologique. 8.1 R sur le web Dans un environnement de travail en √©volution rapide et constante, il est difficile de consid√©rer que ses comp√©tences sont abouties. Rester inform√© sur le d√©veloppement de R vous permettra de d√©nicher de r√©soudre des probl√®mes persistants de mani√®re plus efficace ou par de nouvelles avenues, et vous offrira m√™me l‚Äôoccasion de d√©nicher des probl√®mes dont vous ne soup√ßonniez pas l‚Äôexistance. Plusieurs sources d‚Äôinformation vous permettront de vous tenir √† jour sur le d√©veloppement de R, de ses environnement de travail (RStudio, Jupyter, Atom, etc.) et des nouveaux modules qui s‚Äôy greffent. Plus largement, vous gagnerez √† vous informer sur les derni√®res tendances en calcul scientifique sur d‚Äôautres plate-forme que R (Python, Javascript, Julia, etc.). √âvidemment, nos t√¢ches quotidiennes ne nous permettent pas de tout suivre. M√™me si vous pouviez n‚Äôattrapper qu‚Äô1% du d√©filement, ce sera d√©j√† 1% de plus que rien du tout. √âvidemment, rester au courant aide parce que vous en apprenez davantage sur les outils et leurs applications. Mais √ßa aide aussi parce que √ßa vous permet de conna√Ætre des gens et des organisations! Il est tr√®s utile de savoir qui travaille sur quoi et o√π se d√©roulent les d√©veloppements sur un sujet donn√©, car si vous cherchez consciemment quelque chose plus tard, √ßa vous aidera √† trouver votre chemin plus facilement. - Ma√´lle Salmon, Keeping up to date with R news (ma traduction) Je vous propose une liste de ressources. Ne vous y tenez surtout pas: discartez ce qui ne vous convient pas, et partez √† l‚Äôaventure! The Hobbit: An Unexpected Journey, Peter Jackson (2012) 8.1.1 GitHub Nous verrons au chapitre 5 l‚Äôimportance d‚Äôutilser des outils d‚Äôarchivage et de suivi de version, comme git, dans le d√©ploiement de la science ouverte. Pour l‚Äôinstant, retenons que GitHub est une plate-forme git en ligne acquise par Microsoft qui est devenue un r√©seau social de d√©veloppement informatique. De nombreux modules de R y sont d√©velopp√©s. Au chapitre 5, vous serez invit√©s √† y ouvrir un compte et √† y archiver du contenu. Vous pourrez alors suivre (dans le m√™me sens que sur Facebook ou Twitter) le d√©veloppement de projets et suivre les travaux des personnes qui vous semblent d‚Äôint√©r√™t. 8.1.2 Twitter Le hashtag #rstats rassemble sur Twitter ce qui se tweete sur le sujet. On y retrouve les comptes de R-bloggers, RStudio et rOpenSci. Certaines communaut√© y sont aussi actives, comme R4DS online learning community, qui partage des nouvelles sur R, et R-Ladies Global, qui vise √† amener davantage de diversit√© √† la communaut√© de R. Des comptes th√©matiques comme Daily R Cheatsheets et One R Package a Day permettent de d√©couvrir quotidiennement de nouvelles possibilit√©s. Enfin, plusieurs personnes contribuent positivement √† la communaut√© R. Hadley Wickham brille parmi les √©toiles de R. Les comptes de Mara Averick, Claus Wilke et David Robinson sont aussi int√©ressants. 8.1.3 Nouvelles Le site d‚Äôaggr√©gation R-bloggers, mis √† jour quotidiennement, republie des articles en anglais tir√©s d‚Äôun peu partout sur la toile. On y trouve principalement des tutoriels et des annonces de nouveaux d√©veloppement. Deux fois par mois, l‚Äôorganisation rOpenSci offre un portrait de l‚Äôuniv-R (üí©), ce que R Weekely offre de mani√®re hebdomadaire (l‚Äôinformation sera probablement redondante). Le tidyverse a quant √† lui son propre blogue. 8.1.4 Des questions? Bien que davantage vou√©s √† la r√©solution de probl√®me qu‚Äô √† l‚Äôexploration de nouvelles opportunit√©s, Stackoverflow et Cross Validated sont des plate-forme pris√©es. De plus, la liste de courriels r-sig-ecology permet des √©changes entre professionnels et novices en analyse de donn√©es √©cologiques avec R. 8.1.5 Participer R est un logiciel bas√© sur une communaut√© de d√©veloppement, d‚Äôutilisation et de vulgarisation. Des personnes offrent g√©n√©reusement du temps de support. Si vous vous sentez √† l‚Äôaise, offrez aussi le v√¥tre! 8.1.6 Mise en garde Les modules de R sont d√©velopp√©s par quiconque le veut bien: leur qualit√© n‚Äôest pas n√©cessairement audit√©e. Souvent, ils ne sont v√©rifi√©s que par une vigilance communautaire: dans ce cas, vous √™tes les cobailles. Ce qui n‚Äôest pas n√©cessairement une mauvaise chose, mais cela n√©cessite de prendre ses pr√©cautions. Dans sa conf√©rence How to be a resilient R user, Ma√´lle Salmon propose quelques guides pour juger de la qualit√© d‚Äôun module. 1. Le module est-il activement d√©velopp√©? Bien! Attention! 2. Le module est-il bien test√©? V√©rifiez si le module a fait l‚Äôobjet d‚Äôune publication scientifique, s‚Äôil a √©t√© utilis√© avec succ√®s dans la lit√©rature ou dans des documents cr√©dibles. 3. Le module est-il bien document√©? Un site internet d√©di√© est-il utilis√© pour documenter l‚Äôutilisation du module? Les fichiers d‚Äôaide sont-ils complets, et sont-ils de bonne qualit√©? 4. Le module est-il largement utilis√©? Un module peu populaire n‚Äôest pas n√©cessessairement de mauvaise qualit√©: peut-√™tre est-il seulement destin√© √† des applications de niche. S‚Äôil n‚Äôest pas un indicateur √† lui seul de la solidit√© ou la validit√© d‚Äôun module, une masse critique indique que le module a pass√© sous la surveillance de plusieurs utilisateurs. Dans GitHub, ceci peut √™tre √©valu√© par le nombre d‚Äô√©toiles attribu√© au module (√©quivalent √† un J‚Äôaime). 5. Le module est-il d√©velopp√© par une personne ou une organisation cr√©dible? On peut affirmer sans trop se compromettre que l‚Äô√©quipe de RStudio d√©veloppe des modules de confiance. Tout comme il faudrait se m√©fier d‚Äôun module d√©velopp√© par une personne anonyme. Le module packagemetrics permet d‚Äô√©valuer ces crit√®res. # devtools::install_github(&quot;ropenscilabs/packagemetrics&quot;) library(&quot;packagemetrics&quot;) pm &lt;- package_list_metrics(c(&quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;vegan&quot;, &quot;greta&quot;)) metrics_table(pm) 8.1.7 Prendre tout √ßa en note Un logiciel de prise de notes (comme Evernote, OneNote, Notion, Simplenote, Turtl, etc.) pourrait vous √™tre utile pour retrouver l‚Äôinformation soutir√©e de vos flux d‚Äôinformation. Mais certaines personnes consignent simplement leurs informations dans un carnet ou un document de traitement de texte. 8.2 R en chaire et en os L‚ÄôUniversit√© Laval (institution aupr√®s de laquelle ce manuel est d√©velopp√©) sera haute en mai 2019 de la conf√©rence R √† Qu√©bec 2019. Des ateliers seront offerts pour les utilisateurs novices et avanc√©s. 8.3 Quelques outils en √©cologie math√©matique avec R 8.3.1 Pr√©traitement des donn√©es Il arrive souvent ques les donn√©es brutes ne soient pas exprim√©es de mani√®re appropri√©e ou optimale pour l‚Äôanalyse statistique ou la mod√©lisation. Vous devrez alors effectuer un pr√©traitement sur ces donn√©es. Lors du chapitre 6, nous avons abord√© la mise √† l‚Äô√©chelle, o√π des variables num√©riques √©taient transform√©es pour avoir une moyenne de z√©ro et un √©cart-type de 1. Cette op√©ration permettait d‚Äôappr√©cier les coefficients et leur incertitude sur une m√™me √©chelle. L‚Äôencodage cat√©gorielle a quant √† lui permi d‚Äôutiliser des m√©thodes quantitatives sur des donn√©es qualitatives. Dans les deux cas, nous n‚Äôavons pas utilis√© le terme, mais il s‚Äôagissait d‚Äôun pr√©traitement, c‚Äôest-√†-dire une transformation des donn√©es pr√©alable √† l‚Äôanalyse ou la mod√©lisation. Un pr√©traitement peut consister simplement en une transformation logarithmique ou exponentielle. En particulier, si vos donn√©es forment une partie d‚Äôun tout (exprim√©es en pourcentages ou fractions), vous devriez probablement utiliser un pr√©traitement gr√¢ce aux outils de l‚Äôanalyse compositionnelle. Avant de les aborder, nous allons traiter des transformations de base. 8.3.1.1 Standardisation La standardisation consiste √† centrer vos donn√©es √† une moyenne de 0 et √† les √©chelonner √† une variance de 1, c‚Äôest-√†-dire \\[x_{standard} = \\frac{x - \\bar{x}}{\\sigma}\\] o√π \\(\\bar{x}\\) est la moyenne du vecteur \\(x\\) et o√π \\(\\sigma\\) est son √©cart-type. Ce pr√©traitement des donn√©es peut s‚Äôav√©r√©r utile lorsque la mod√©lisation tient compte de l‚Äô√©chelle de vos mesures (par exemple, les param√®tres de r√©gression vus au chapitre 6 ou les distances que nous verrons au chapitre 9). En effet, les pentes d‚Äôune r√©gression lin√©aire multiple ne pourront √™tre compar√©es entre elles que si elles sont une m√™me √©chelle. Par exemple, on veut mod√©liser la consommation en miles au gallon (mpg) de voitures en fonction de leur puissance (hp), le temps en secondes pour parcourir un quart de mile (qsec) et le nombre de cylindre. data(&quot;mtcars&quot;) modl &lt;- lm(mpg ~ hp + qsec + cyl, mtcars) summary(modl) ## ## Call: ## lm(formula = mpg ~ hp + qsec + cyl, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.3223 -1.9483 -0.5656 1.5452 7.7773 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 55.30540 9.03697 6.120 1.33e-06 *** ## hp -0.03552 0.01622 -2.190 0.03700 * ## qsec -0.89424 0.42755 -2.092 0.04567 * ## cyl -2.26960 0.54505 -4.164 0.00027 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.003 on 28 degrees of freedom ## Multiple R-squared: 0.7757, Adjusted R-squared: 0.7517 ## F-statistic: 32.29 on 3 and 28 DF, p-value: 3.135e-09 Les pentes signifient que la distance parcourue par gallon d‚Äôessence diminue de 0.03552 miles au gallon pour chaque HP, de 0.89242 par seconde au quart de mile et de 2.2696 par cyclindre additionnel. L‚Äôinterpr√©tation est conviviale √† cette √©chelle. Mais lequel de ces effets est le plus important? L t value indique que ce seraient les cylindres. Mais pour juger l‚Äôimportance en terme de pente, il vaudrait mieux standardiser. library(&quot;tidyverse&quot;) ## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ ## ‚úì ggplot2 3.2.1 ‚úì purrr 0.3.3 ## ‚úì tibble 2.1.3 ‚úì dplyr 0.8.3 ## ‚úì tidyr 1.0.2 ‚úì stringr 1.4.0 ## ‚úì readr 1.3.1 ‚úì forcats 0.4.0 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() standardise &lt;- function(x) (x-mean(x))/sd(x) mtcars_sc &lt;- mtcars %&gt;% mutate_if(is.numeric, standardise) # ou bien scale(mtcars, center = TRUE, scale = TRUE) modl_sc &lt;- lm(mpg ~ hp + qsec + cyl, mtcars_sc) summary(modl_sc) ## ## Call: ## lm(formula = mpg ~ hp + qsec + cyl, data = mtcars_sc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.71716 -0.32326 -0.09384 0.25639 1.29042 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.061e-16 8.808e-02 0.000 1.00000 ## hp -4.041e-01 1.845e-01 -2.190 0.03700 * ## qsec -2.651e-01 1.268e-01 -2.092 0.04567 * ## cyl -6.725e-01 1.615e-01 -4.164 0.00027 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4983 on 28 degrees of freedom ## Multiple R-squared: 0.7757, Adjusted R-squared: 0.7517 ## F-statistic: 32.29 on 3 and 28 DF, p-value: 3.135e-09 Les valeurs des pentes ne peuvent plus √™tre interpr√©t√©es directement, mais peuvent maintenant √™tre compar√©es entre elles. Dans ce cas, le nombre de cilyndres a en effet une importance plus grande que la puissance et le temps pour parcourir un 1/4 de mile. Les algorithmes bas√©s sur des distances auront, de m√™me, avantage √† √™tre standardis√©s. 8.3.1.2 √Ä l‚Äô√©chelle de la plage Si vous d√©sirez pr√©server le z√©ro dans le cas de donn√©es positives ou plus g√©n√©ralement vous voulez que vos donn√©es pr√©trait√©es soient positives, vous pouvez les transformer √† l‚Äô√©chelle de la plage, c‚Äôest-√†-dire les forcer √† s‚Äô√©taler de 0 √† 1: \\[ x_{range01} = \\frac{x - x_{min}}{x_{max} - x_{min}} \\] Cette transformation est sensible aux valeurs aberrantes, et une fois le vecteur transform√© les valeurs aberrantes seront toutefois plus difficiles √† d√©tecter. range_01 &lt;- function(x) (x-min(x))/(max(x) - min(x)) mtcars %&gt;% mutate_if(is.numeric, range_01) %&gt;% # en fait, toutes les colonnes sont num√©riques, alors mutate_all aurait pu √™tre utilis√© au lieu de mutate_if sample_n(4) ## mpg cyl disp hp drat wt qsec vs am gear ## 1 0.4680851 0.0 0.1244699 0.2014134 0.6221198 0.32395807 0.4880952 1 1 0.5 ## 2 0.6638298 0.0 0.1227239 0.1378092 0.7695853 0.16031705 0.2619048 0 1 1.0 ## 3 1.0000000 0.0 0.0000000 0.0459364 0.6728111 0.08233188 0.6428571 1 1 0.5 ## 4 0.4680851 0.5 0.4662010 0.2049470 0.1474654 0.43518282 0.5880952 1 0 0.0 ## carb ## 1 0.1428571 ## 2 0.1428571 ## 3 0.0000000 ## 4 0.0000000 8.3.1.3 Normaliser Le terme normaliser est associer √† des op√©rations diff√©rentes dans la litt√©rature. Nous prendrons la nomenclature de scikit-learn, pour qui la normalisation consiste √† faire en sorte que la longueur du vecteur (sa norme, d‚Äôo√π normaliser) soit unitaire. Cette op√©ration est le plus souvent utilis√©e par observation (ligne), non pas par variable (colonne). Il existe plusieurs mani√®res de mesures la distance d‚Äôun vecteur, mais la plus commune est la distance euclidienne. La seule fois que j‚Äôai eu √† utiliser ce pr√©traitement √©tait en analyse spectrale (Chemometrics with R, Ron Wehrens, 2011, chapitre 3.5). En R, library(&quot;pls&quot;) ## ## Attaching package: &#39;pls&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## loadings data(&quot;gasoline&quot;) spectro &lt;- gasoline$NIR %&gt;% unclass() %&gt;% as_tibble() normalise &lt;- function(x) x/sqrt(sum(x^2)) spectro_norm &lt;- spectro %&gt;% rowwise() %&gt;% # diff√©rentes approches possibles pour les op√©rations sur les lignes normalise() spectro_norm[1:4, 1:4] ## 900 nm 902 nm 904 nm 906 nm ## 1 -0.0011224834 -0.0010265446 -0.0009434425 -0.0008314021 ## 2 -0.0009890637 -0.0008856332 -0.0007977676 -0.0006912734 ## 3 -0.0010481029 -0.0009227116 -0.0008269742 -0.0007035061 ## 4 -0.0010444801 -0.0009446277 -0.0008623530 -0.0007718261 8.3.1.4 Analyse compositionnelle en R En 1898, le statisticien Karl Pearson nota que des corr√©lations √©taient induites lorsque l‚Äôon effectuait des ratios par rapport √† une variable commune. Source Karl Pearson, 1897. Mathematical contributions to the theory of evolution.‚Äîon a form of spurious correlation which may arise when indices are used in the measurement of organs. Proceedings of the royal society of London Faisons l‚Äôexercice! Nous g√©n√©rons au hasard 1000 donn√©es (comme le proposait Pearson) pour trois dimensions: le f√©mur, le tibia et l‚Äôhum√©rus. Ces dimensions ne sont pas g√©n√©r√©es par des distributions corr√©l√©es. set.seed(3570536) n &lt;- 1000 bones &lt;- tibble(femur = rnorm(n, 10, 3), tibia = rnorm(n, 8, 2), humerus = rnorm(n, 6, 2)) plot(bones) cor(bones) ## femur tibia humerus ## femur 1.000000000 -0.069006171 0.002652292 ## tibia -0.069006171 1.000000000 -0.008994704 ## humerus 0.002652292 -0.008994704 1.000000000 Pourtant, si j‚Äôutilise des ratios allom√©triques avec l‚Äôhum√©rus comme base, bones_r &lt;- bones %&gt;% transmute(fh = femur/humerus, th = tibia/humerus) plot(bones_r) text(30, 20, paste(&quot;corr√©lation =&quot;, round(cor(bones_r$fh, bones_r$th), 2)), col = &quot;blue&quot;) Nous avons induit ce que Pearson appelait une fausse corr√©lation (spurious correlation). En 1960, Chayes proposa que de telles fausses corr√©lations sont induites non seulement sur des ratios de valeurs absolues, mais aussi sur des ratios d‚Äôune somme totale. Par exemple, dans une composition simple de deux types d‚Äôutilisation du territoire, si une proportion augmente, l‚Äôautre doit n√©cessairement diminuer. n &lt;- 100 tibble(A = runif(n, 0, 1)) %&gt;% mutate(B = 1 - A) %&gt;% ggplot(aes(x=A, y=B)) + geom_point() Les variables exprim√©es relativement √† une somme totale sont dites compositionnelles. Elles poss√®dent les caract√©ristiques suivantes. Redondance d‚Äôinformation. Un syst√®me de deux proportions ne contient qu‚Äôune seule variable du fait que l‚Äôon puisse d√©duire l‚Äôune en soutrayant l‚Äôautre de la somme totale. Un vecteur compositionnel contient de l‚Äôinformation redondante. Pourtant, effectuer des statistiques sur l‚Äôune plut√¥t que sur l‚Äôautre donnera des r√©sultats diff√©rents. D√©pendance d‚Äô√©chelle. Les statistiques devraient √™tre ind√©pendantes de la somme totale utilis√©e. Pourtant, elles diff√©reront sur l‚Äôon utilise par exemple, une proportion des m√¢les d‚Äôune part et des femelles d‚Äôautre part, ou la proportion de la somme des deux, de m√™me que les r√©sultats d‚Äôun test sanguin diff√©rera si l‚Äôon utilise une base s√®che ou une base humide. Distribution th√©orique des donn√©es. √âtant donn√©e que les proportions sont confin√©es entre 0 et 1 (ou 100%, ou une somme totale quelconque), la distribution normale (qui s‚Äô√©tend de -‚àû √† +‚àû) n‚Äôest souvent pas appropri√©e. On pourra utiliser la distribution de Dirichlet ou la distribution logitique-normale, mais d‚Äôautres approches sont souvent plus pratiques. Pour illustrer l‚Äôeffet de la distribution, voyons un diagramme ternaire incluant le sable, le limon et l‚Äôargile. En utilisant des √©cart-types univari√©s, nous obtenons l‚Äôellipse en rouge, qui non seulement repr√©sente peu l‚Äô√©talement des donn√©es, mais elle d√©passe les bornes du triangle, admettant ainsi des proportions n√©gatives. En bleu, la distribution logistique normale (issue des m√©thodes pr√©sent√©es plus loin dans cette section) convient davantage. Les cons√©quences d‚Äôeffectuer des statistiques lin√©aires sur des donn√©es compositionnelles brutes peuvent √™tre majeures. En outre, Pawlowksy-Glahn et Egozcue (2006), s‚Äôappuyant en outre sur Rock (1988), note les probl√®mes suivants (exprim√©s en mes mots). les r√©gressions, les regroupements et les analyses en composantes principales peuvent avoir peu ou pas de signification les propri√©t√©s des distributions peuvent √™tre g√©n√©r√©es par l‚Äôop√©ration de fermeture de la composition (s‚Äôassurer que le total des proportions donne 100%) les r√©sultats d‚Äôanalyses discriminantes lin√©aires sont propices √† √™tre illusoires tous les coefficients de corr√©lation seront affect√©s √† des degr√©s inconnus les r√©sultats des tests d‚Äôhypoth√®ses seront intrins√®quement fauss√©s Pour contourner ces probl√®mes, il faut d‚Äôabord aborder les donn√©es compositionnelles pour ce qu‚Äôelles sont: des donn√©es intrins√®quement multivari√©es. Elles sont un nuage de point, et non pas une collection de variables individuelles. Ceci qui n‚Äôemp√™che pas d‚Äôeffectuer des analyses consciencieusement sous des angles particuliers. En R, on pourra ais√©ment rapporter une composition en somme unitaire gr√¢ce √† la fonction apply. Mais auparavant, chargeons le module compositions (n‚Äôoubliez pas de l‚Äôinstaller au pr√©alable) pour acc√©der √† des donn√©es fictives de proportions de sable, limon et argile dans des s√©diments. library(&quot;compositions&quot;) ## Loading required package: tensorA ## ## Attaching package: &#39;tensorA&#39; ## The following object is masked from &#39;package:base&#39;: ## ## norm ## Loading required package: robustbase ## Loading required package: bayesm ## Welcome to compositions, a package for compositional data analysis. ## Find an intro with &quot;? compositions&quot; ## ## Attaching package: &#39;compositions&#39; ## The following object is masked from &#39;package:pls&#39;: ## ## R2 ## The following objects are masked from &#39;package:stats&#39;: ## ## cor, cov, dist, var ## The following objects are masked from &#39;package:base&#39;: ## ## %*%, scale, scale.default data(&quot;ArcticLake&quot;) ArcticLake &lt;- ArcticLake %&gt;% as_tibble() head(ArcticLake) ## # A tibble: 6 x 4 ## sand silt clay depth ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 77.5 19.5 3 10.4 ## 2 71.9 24.9 3.2 11.7 ## 3 50.7 36.1 13.2 12.8 ## 4 52.2 40.9 6.6 13 ## 5 70 26.5 3.5 15.7 ## 6 66.5 32.2 1.3 16.3 comp &lt;- ArcticLake %&gt;% select(-depth) %&gt;% apply(., 1, function(x) x/sum(x)) %&gt;% t() comp[1:5, ] ## sand silt clay ## [1,] 0.7750000 0.1950000 0.0300000 ## [2,] 0.7190000 0.2490000 0.0320000 ## [3,] 0.5070000 0.3610000 0.1320000 ## [4,] 0.5235707 0.4102307 0.0661986 ## [5,] 0.7000000 0.2650000 0.0350000 On pourra aussi utiliser la fonction acomp (pour Aitchison-composition) pour fermer la composition √† une somme de 1. comp &lt;- ArcticLake %&gt;% select(-depth) %&gt;% acomp(.) comp[1:5, ] ## sand silt clay ## [1,] 0.7750000 0.1950000 0.0300000 ## [2,] 0.7190000 0.2490000 0.0320000 ## [3,] 0.5070000 0.3610000 0.1320000 ## [4,] 0.5235707 0.4102307 0.0661986 ## [5,] 0.7000000 0.2650000 0.0350000 Cette strat√©gie a pour avantage d‚Äôattribuer √† la variable comp la classe acomp, qui automatise les op√©rations dans l‚Äôespace compositionnel (que l‚Äôon nomme aussi le simplex). La repr√©sentation ternaire est souvent utilis√©e pour pr√©senter des compositions. Toutefois, il est difficile d‚Äôinterpr√©ter les compositions de plus de trois parties. La classe acomp automatise aussi la repr√©sentation teranaire. plot(comp) Afin de transposer cet espace cl√¥t en un espace ouvert, on pourra diviser chaque proportion par une proportion de r√©f√©rence choisie parmi n‚Äôimporte quelle proportion. Du coup, on retire une dimension redondante! Dans ce ratio, on choisit d‚Äôutiliser la proportion de r√©f√©rence au d√©nominateur, ce qui est arbitraire. En utilisant le log du ratio, l‚Äôinverse du ratio ne sera qu‚Äôun changement de signe, ce qui est pratique en statistiques lin√©aries. Cette solution, propos√©e par Aitchison (1986), s‚Äôapplique non seulement sur les compositions √† deux composantes, mais sur toute composition. Il s‚Äôagit alors d‚Äôutiliser une composition de r√©f√©rence pour effecteur les ratios. Pour une composition de \\(A\\), \\(B\\), \\(C\\), \\(D\\) et \\(E\\): \\[alr_A = log \\left( \\frac{A}{E} \\right), alr_B = log \\left( \\frac{B}{E} \\right), alr_C = log \\left( \\frac{C}{E} \\right), alr_D = log \\left( \\frac{D}{E} \\right)\\] Dans R, la colonne de r√©f√©rence est par d√©faut la derni√®re colonne de la matrice des compositions. add_lr &lt;- alr(comp) Cette derni√®re strat√©gie se nomme les log-ratios aditifs (\\(alr\\) pour additive log-ratio). Bien que valide pour effectuer des tests statistiques, cette strat√©gie a le d√©savantage de d√©pendre de la d√©cision arbitraire de la composante √† utiliser au num√©rateur. Deuxi√®me restriction des alr: les axes de l‚Äôespace des alr n‚Äô√©tant pas orthogonaux, ils ne peuvent pas √™tre utilis√©s pour effectuer des statistiques bas√©es sur les distances (que nous couvrirons au chapitre 9). L‚Äôautre strat√©gie propos√©e par Aitchison √©tait d‚Äôeffectuer un log-ratio entre chaque composante et la moyenne g√©om√©trique de toutes les composantes. Cette transformation se nomme le log-ratio centr√© (\\(clr\\), pour centered log-ratio) \\[clr_i = log \\left( \\frac{x_i}{g \\left( x \\right)} \\right)\\] En R, cen_lr &lt;- clr(comp) Avec des CLRs, les distances sont valides. Mais‚Ä¶ nous restons avec le probl√®me de la redondance d‚Äôinformation. En fait, la somme de chacunes des lignes d‚Äôune matrice de clr est de 0. Pas tr√®s pratique lorsque l‚Äôon effectue des statistiques incluant une inversion de la matrice de covariance (distance de Mahalanobis, g√©ostatistiques, etc.) cen_lr %&gt;% cov() %&gt;% solve() Error in solve.default(.) : le syst√®me est num√©riquement singulier : conditionnement de la r√©ciproque = 4.44407e-17 Enfin, une autre m√©thode de transformation d√©velopp√©e par Egoscue et al. (2003), les log-ratios isom√©triques (ou isometric log-ratios, ilr) projette les compositions comprenant D composantes dans un espace restreint de D-1 dimensions orthonorm√©es. Ces dimensions doivent doivent √™tre pr√©alablement √©tablie dans un dendrogramme de bifurcation, o√π chaque composante ou groupe de composante est successivement divis√© en deux embranchement. La mani√®re d‚Äôarranger ces balances importe peu, mais on aura avantage √† cr√©er des balances interpr√©tables. Le diagramme de balances peut √™tre encod√© dans une partition binaire s√©quentielle (ou sequential bianry partition, sbp). Une sbp est une matrice de contraste ou chaque ligne repr√©sente une partition entre deux variables ou groupes de variables. Une composante √©tiquett√©e +1 correspondra au groupe du num√©rateur, une composante √©tiquett√©e -1 au d√©nominateur et une composante √©tiquett√©e 0 sera exclue de la partition (Parent et al., 2013). J‚Äôai reformul√© la fonction CoDaDendrogram pour que l‚Äôon puisse ajouter des informations int√©ressantes sur les balants horizontaux. Cette fonction est disponible sur github. source(&quot;https://raw.githubusercontent.com/essicolo/AgFun/master/codadend2.R&quot;) sbp &lt;- matrix(c(1, 1,-1, 1,-1, 0), byrow = TRUE, ncol = 3) CoDaDendrogram2(comp, V = gsi.buildilrBase(t(sbp)), ylim = c(0, 1), equal.height = TRUE) Si la SBP est plus imposante, il pourrait √™tre plus ais√© de monter dans un chiffrier, puis de l‚Äôimporter dans R via un fichier csv. Le calcul des ILRs est effectu√© comme suit. \\[ilr_j = \\sqrt{\\frac{n_j^+ n_j^-}{n_j^+ + n_j^-}} log \\left( \\frac{g \\left( c_j^+ \\right)}{g \\left( c_j^+ \\right)} \\right)\\] ou, √† la ligne \\(j\\) de la SBP, \\(n_j^+\\) et \\(n_j^-\\) sont respectivement le nombre de composantes au num√©rateur et au d√©nominateur, \\(g \\left( c_j^+ \\right)\\) est la moyenne g√©om√©trique des composantes au num√©rateur et \\(g \\left( c_j^- \\right)\\) est la moyenne g√©om√©trique des composantes au d√©nominateur. Les balances sont conventionnellement not√©es [A,B | C,D], ou les composantes A et B au d√©nominateur sont balanc√©es avec les composantes C and D au num√©rateur. Une balance positive signifie que la moyenne g√©om√©trique des concentrations au num√©rateur est sup√©rieur √† celle au d√©nominateur, et inversement, alors qu‚Äôune balance nulle signifie que les moyennes g√©om√©triques sont √©gales (√©quilibre). Ainsi, en mod√©lisation lin√©aire, un coefficient positif sur [A,B | C,D] signifie que l‚Äôaugmentation de l‚Äôimportance de C et D comparativement √† A et B est associ√© √† une augmentation de la variable r√©ponse du mod√®le. En R, iso_lr &lt;- ilr(comp, V = gsi.buildilrBase(t(sbp))) Notez la forme gsi.buildilrBase(t(sbp)) est une op√©ration pour obtenir la matrice d‚Äôorthonormalit√© √† partir de la SBP. Les ILRs sont des balances multivari√©es sur lesquelles on pourra effectuer des statistiques lin√©aries. Bien que l‚Äôinterpr√©tation des r√©sultats comme collection d‚Äôinterpr√©tations sur des balances univari√©es pourra √™tre affect√©e par la structure de la SBP, ni les statistiques lin√©aires multivari√©es, ni la distance entre les points ne seront affect√©s. En effet, chaque variante de la SBP est une rotation (d‚Äôun facteur de 60¬∞) par rapport √† l‚Äôorigine: source(&quot;lib/ilr-rotation-sbp.R&quot;) Pour les transformations inverses, vous pourrez utiliser les fonctions alrInv, clrInv et ilrInv. Dans tous les cas, si vous tenez √† garder la trace de vos donn√©es dans leur format original, vous aurez avantage √† ajouter √† votre vecteur compositionnel la valeur de remplissage, constitu√© d‚Äôun amalgame des composantes non mesur√©es. Par exemple, pourc &lt;- c(N = 0.03, P = 0.001, K = 0.01) acomp(pourc) # vous perdez la trace des proportions originales ## N P K ## 0.73170732 0.02439024 0.24390244 ## attr(,&quot;class&quot;) ## [1] acomp pourc &lt;- c(N = 0.03, P = 0.001, K = 0.01) Fv &lt;- 1 - sum(pourc) comp &lt;- acomp(c(pourc, Fv = Fv)) comp ## N P K Fv ## 0.030 0.001 0.010 0.959 ## attr(,&quot;class&quot;) ## [1] acomp iso_lr &lt;- ilr(comp) # avec une sbp par d√©faut ilrInv(iso_lr) ## 1 2 3 4 ## [1,] 0.03 0.001 0.01 0.959 ## attr(,&quot;class&quot;) ## [1] acomp Si vos donn√©es font partie d‚Äôun tout, je vous recommande chaudement d‚Äôutiliser des m√©thodes compositionnelles autant pour l‚Äôanalyse que la mod√©lisation. Pour en savoir davantage, le livre Compositional data analysis with R, de van den Boogart et Tolosana-Delgado, est disponible en format √©lectronique √† la biblioth√®que de l‚ÄôUniversit√© Laval. Pour aller plus loin, j‚Äôai √©cri un billet √† ce sujet (auquel √† ce jour il manque toujours un cas d‚Äô√©tude): We should use balances and machine learning to diagnose ionomes. 8.3.2 Acqu√©rir des donn√©es m√©t√©o Une t√¢che commune en √©cologie est de lier des observations √† la m√©t√©o‚Ä¶ qui sont rarement collect√©s lors d‚Äôexp√©riences. Environnement Canada poss√®de sont r√©seau de stations. Les donn√©es sont disponibles sur internet en libre acc√®s. Vous pouvez chercher des stations, effectuer des requ√™tes et t√©l√©charger des fichiers csv. Pour un petit tableau, la t√¢che est plut√¥t triviale. Mais √ßa devient rapidement laborieux √† mesure que l‚Äôon doit rechercher de nombreuses donn√©es. Le module weathercan, d√©velopp√© par Steffi LaZerte, permet d‚Äôeffectuer des requ√™tes rapidement √† partir des coordonn√©es de votre site exp√©rimental. Par exemple, si je cherche une station m√©t√©o sfournissant des donn√©es horaires situ√© √† moins de 20 km du sommet du Mont-Bellevue, √† Sherbrooke, aux coordonn√©es [latitude 45.35, longitude -71.90], library(&quot;weathercan&quot;) station_site &lt;- stations_search(coords = c(45.35, -71.90), dist = 20, interval = &quot;hour&quot;) station_site ## # A tibble: 4 x 15 ## prov station_name station_id climate_id WMO_id TC_id lat lon elev tz ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 QC LENNOXVILLE 5397 7024280 71611 WQH 45.4 -71.8 181 Etc/‚Ä¶ ## 2 QC SHERBROOKE 48371 7028123 71610 YSC 45.4 -71.7 241. Etc/‚Ä¶ ## 3 QC SHERBROOKE A 5530 7028124 71610 YSC 45.4 -71.7 241. Etc/‚Ä¶ ## 4 QC SHERBROOKE A 30171 7028126 NA GSC 45.4 -71.7 241. Etc/‚Ä¶ ## # ‚Ä¶ with 5 more variables: interval &lt;chr&gt;, start &lt;int&gt;, end &lt;int&gt;, ## # normals &lt;lgl&gt;, distance &lt;dbl&gt; Je prends en note l‚Äôidentifiant de la station d√©sir√©e (ou des stations, disons 5397 et 48371), puis je lance une requ√™te pour obtenir la m√©t√©o horaire entre les dates d√©sir√©es. mont_bellevue &lt;- weather_dl(station_ids = c(5397, 48371), start = &quot;2019-02-01&quot;, end = &quot;2019-02-07&quot;, interval = &quot;hour&quot;, verbose = TRUE, tz_disp = &quot;Etc/GMT+5&quot;) ## Warning in weather_dl(station_ids = c(5397, 48371), start = &quot;2019-02-01&quot;, : ## &#39;tz_disp&#39; is deprecated, see Details under ?weather_dlFALSE ## Getting station: 5397 ## Formatting station data: 5397 ## Adding header data: 5397 ## Getting station: 48371 ## Formatting station data: 48371 ## Adding header data: 48371 ## Trimming missing values before and after ## As of weathercan v0.3.0 time display is either local time or UTC ## See Details under ?weather_dl for more information. ## This message is shown once per session mont_bellevue %&gt;% head(5) ## # A tibble: 5 x 35 ## station_name station_id station_operator prov lat lon elev climate_id ## &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 LENNOXVILLE 5397 NA QC 45.4 -71.8 181 7024280 ## 2 LENNOXVILLE 5397 NA QC 45.4 -71.8 181 7024280 ## 3 LENNOXVILLE 5397 NA QC 45.4 -71.8 181 7024280 ## 4 LENNOXVILLE 5397 NA QC 45.4 -71.8 181 7024280 ## 5 LENNOXVILLE 5397 NA QC 45.4 -71.8 181 7024280 ## # ‚Ä¶ with 27 more variables: WMO_id &lt;chr&gt;, TC_id &lt;chr&gt;, date &lt;date&gt;, ## # time &lt;dttm&gt;, year &lt;chr&gt;, month &lt;chr&gt;, day &lt;chr&gt;, hour &lt;chr&gt;, weather &lt;chr&gt;, ## # hmdx &lt;dbl&gt;, hmdx_flag &lt;chr&gt;, pressure &lt;dbl&gt;, pressure_flag &lt;chr&gt;, ## # rel_hum &lt;dbl&gt;, rel_hum_flag &lt;chr&gt;, temp &lt;dbl&gt;, temp_dew &lt;dbl&gt;, ## # temp_dew_flag &lt;chr&gt;, temp_flag &lt;chr&gt;, visib &lt;dbl&gt;, visib_flag &lt;chr&gt;, ## # wind_chill &lt;dbl&gt;, wind_chill_flag &lt;chr&gt;, wind_dir &lt;dbl&gt;, ## # wind_dir_flag &lt;chr&gt;, wind_spd &lt;dbl&gt;, wind_spd_flag &lt;chr&gt; Et voil√†. mont_bellevue %&gt;% ggplot(aes(x = time, y = temp)) + geom_line(aes(colour = station_name)) 8.3.3 P√©dom√©trie avec R Cette section a √©t√© √©crite par Michael Leblanc. Plusieurs fonctionnalit√©s ont √©t√© d√©velopp√©es sur R afin d‚Äôaider les p√©dom√©triciens √† visualiser, explorer et traiter les donn√©es num√©riques en science des sols. Voici quelques exemples. 8.3.3.1 Texture du sol La texture du sol est d√©finie par sa composition granulom√©trique, habituellement repr√©sent√©e par trois fractions (sable, limon, argile), laquelle peut √™tre g√©n√©ralis√©e en classe texturale. La d√©finition des classes texturales diff√®re d‚Äôun syst√®me ou d‚Äôun pays √† l‚Äôautre comme en t√©moigne l‚Äôarticle Perdus dans le triangle des textures (Richer de Forges et al.¬†2008). La d√©finition des fractions granulom√©triques peut √©galement diff√©rer selon le domaine d‚Äô√©tude (ing√©nierie, p√©dologie) ou le pays. Par exemple, le diam√®tre du limon est de 0,002 mm √† 0,05 mm dans le syst√®me canadien, am√©ricain et fran√ßais alors qu‚Äôil est de 0,002 mm √† 0,02 mm dans le syst√®me australien et de 0,002 mm √† 0,063 mm dans le syst√®me allemand. Il est donc important de v√©rifier la m√©thodologie et le syst√®me de classification utilis√©s pour interpr√©ter les donn√©es de texture du sol. Le module soilTexture propose des fonctions permettant d‚Äôaborder ces multiples d√©finitions. library(&quot;soiltexture&quot;) 8.3.3.1.1 Les triangles texturaux Avec la fonction TT.plot, vous pouvez pr√©senter vos donn√©es granulom√©triques dans un triangle textural tel que d√©fini par les diff√©rents syst√®mes nationaux. Auparavant, cr√©ons un objet comprenant des textures al√©atoires. set.seed(848341) # random.org rand_text &lt;- TT.dataset(n=100, seed.val=29) head(rand_text) ## CLAY SILT SAND Z ## 1 54.650857 40.37101 4.978129 13.2477582 ## 2 44.745954 40.81782 14.436221 20.8433109 ## 3 18.192509 48.26752 33.539970 7.1814626 ## 4 17.750492 40.14405 42.105458 -0.2077358 ## 5 65.518360 23.36110 11.120538 10.8656027 ## 6 6.610293 22.45353 70.936173 3.7108567 Avec le module soiltexture, les tableaux de texture doivent inclure les intitull√©s exactes CLAY, SILT et SAND (notez les majuscules). Les points des textures g√©n√©r√©es peuvent √™tre port√©s dans des diagrammes ternaires texturaux de diff√©rents syst√®mes de classification, par exemple le syst√®me canadioen et le syst√®me USDA. par(mfrow=c(1, 2)) TT.plot(class.sys = &quot;CA.FR.TT&quot;, tri.data = rand_text, col = &quot;blue&quot;) TT.plot(class.sys = &quot;USDA.TT&quot;, tri.data = rand_text, col = &quot;blue&quot;) Les param√®tres de la figure (titres, polices, style de la grille, etc.) peuvent √™tre personnalis√©s avec les arguments TT.plot. 8.3.3.1.2 Les classes texturales La fonction TT.points.in.classes est utile pour d√©signer la classe texturale √† partir des donn√©es granulom√©triques, en sp√©cifiant bien le syst√®me de classification d√©sir√©. TT.points.in.classes( tri.data = rand_text[1:10, ], # class.sys = &quot;CA.FR.TT&quot;, PiC.type = &quot;t&quot; ) ## [1] &quot;ALi&quot; &quot;ALi&quot; &quot;L&quot; &quot;L&quot; &quot;ALo&quot; &quot;LS&quot; &quot;ALo&quot; &quot;A&quot; &quot;LLi&quot; &quot;LSA&quot; Plusieurs autres fonctions sont propos√©es par soiltexture afin de visualiser, classifier et transformer les donn√©es de texture du sol : Functions in soiltexture. Julien Moeys (2018) propose √©galement le tutoriel The soil texture wizard: a tutorial. 8.3.3.2 Profils de sols Le profil de sols est une entit√© d√©crite par une s√©quence de couches ou d‚Äôhorizons avec diff√©rentes caract√©ristiques morphologiques. Le module AQP, pour Algorithms for Quantitative Pedology, propose des fonctions de visualisation, d‚Äôagr√©gation et de classification permettant d‚Äôaborder la complexit√© inh√©rente aux informations p√©dologiques. 8.3.3.2.1 La visualisation de profils Vous devez d‚Äôabord structurer vos donn√©es dans un tableau (data.frame) incluant minimalement ces trois colonnes : Identifiant unique du profil (groupes d‚Äôhorizons) (id) Limites sup√©rieures de l‚Äôhorizon (top) Limites inf√©rieures de l‚Äôhorizon (down) Vos donn√©es morphologiques, physico-chimiques, etc., sont incluses dans les autres colonnes. Chargeons un fichier p√©dologique √† titre d‚Äôexemple. profils &lt;- read_csv(&quot;data/06_pedometric-profile.csv&quot;) ## Parsed with column specification: ## cols( ## id = col_double(), ## horizon = col_character(), ## top = col_double(), ## bottom = col_double(), ## hue = col_character(), ## value = col_double(), ## chroma = col_double(), ## pH.CaCl2 = col_double(), ## C.CNS.pc = col_double() ## ) head(profils) ## # A tibble: 6 x 9 ## id horizon top bottom hue value chroma pH.CaCl2 C.CNS.pc ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Ap1 0 23 10YR 2 3 4.78 2.71 ## 2 1 Ap2 23 34 10YR 2 2 4.74 2.2 ## 3 1 Bfcj 34 46 7.5YR 4 5 4.79 2.4 ## 4 1 BC 46 83 2.5Y 4 5 4.93 0.22 ## 5 1 C 83 100 2.5Y 5 4 4.82 0.18 ## 6 2 Ap 0 29 10YR 2 2 4.6 4.22 La fonction munsell2rgb permet de convertir le code de couleur Munsell en format RGB. library(&quot;aqp&quot;) ## This is aqp 1.19 ## ## Attaching package: &#39;aqp&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## slice, union ## The following object is masked from &#39;package:base&#39;: ## ## union profils$soil_color &lt;- with(profils, munsell2rgb(hue, value, chroma)) Pr√©alablement √† la visualisation, le tableau est transform√© en objet SoilProfileCollection par la fonction depths. Pour ce faire, le tableau doit √™tre un pur data.frame, non pas un tibble. profils &lt;- profils %&gt;% as.data.frame() depths(profils) &lt;- id ~ top + bottom La fonction plot d√©tectera le type d‚Äôobjet et appellera la fonction de visualisation en cons√©quence. par(mfrow = c(1, 3)) plot(profils, name=&quot;horizon&quot;) title(&#39;Couleur des horizons&#39;, cex.main=1) plot(profils, name=&quot;horizon&quot;, color=&#39;C.CNS.pc&#39;, col.label=&#39;C total (%)&#39;) plot(profils, name=&quot;horizon&quot;, color=&#39;pH.CaCl2&#39;, col.label=&#39;pH CaCl2&#39;) De multiples figures th√©matiques peuvent √™tre g√©n√©r√©es afin de repr√©senter les particuliarit√©s des profils. Pour aller plus loin, consultez les guides Introduction to SoilProfileCollection Objects et Generating Sketches from SPC Objects. 8.3.3.2.2 Les plans verticaux (depth functions) Les plans verticaux sont des diagrammes qui permettent d‚Äôinterpr√©ter les donn√©es en fonction de la profondeur. La fonction slab permet le calcul de statistiques descriptives par intervalles de profondeur r√©guliers, lesquelles permettent de visualiser la variabilit√© verticale des propri√©t√©s des sols. agg &lt;- slab(profils, fm = ~ C.CNS.pc + pH.CaCl2) La visualisation est g√©n√©r√©e par le module graphique ggplot2 agg %&gt;% ggplot(mapping = aes(x = -top, y = p.q50)) + facet_grid(. ~ variable, scale = &quot;free&quot;) + geom_ribbon(aes(ymin = p.q25, ymax = p.q75), fill = &quot;grey75&quot;, alpha = 0.5) + geom_path() + labs(x = &quot;Profondeur (cm)&quot;, y = &quot;M√©diane bord√©e des 25e and 75e percentiles&quot;) + coord_flip() 8.3.3.2.3 Le regroupement de profils Le calcul des distances de dissimilarit√© entre les profils avec profile_compare permet la construction de dendrogramme et le regroupement des profils. Notez que nous survolerons au chapitre 9 les concepts de dissimilarit√© et de partitionnement. library(&quot;cluster&quot;) library(&quot;mvtnorm&quot;) library(&quot;sharpshootR&quot;) # remotes::install_github(&quot;ncss-tech/sharpshootR&quot;) d &lt;- profile_compare(profils, vars=c(&#39;C.CNS.pc&#39;, &#39;pH.CaCl2&#39;), k=0, max_d=40) ## Computing dissimilarity matrices from 10 profiles [0.08 Mb] d_diana &lt;- diana(d) plotProfileDendrogram(profils, name=&quot;horizon&quot;, d_diana, scaling.factor = 0.3, y.offset = 5, color=&#39;pH.CaCl2&#39;, col.label=&#39;pH CaCl2&#39;) 8.3.3.2.4 Diagramme de relations entre les horizons Il est possible de visualiser les transitions d‚Äôhorizon les plus probables dans un groupe de profils de sols. tp &lt;- hzTransitionProbabilities(profils, name=&quot;horizon&quot;) ## Warning: ties in transition probability matrix par(mar = c(0, 0, 0, 0), mfcol = c(1, 2)) plot(profils, name=&quot;horizon&quot;) plotSoilRelationGraph(tp, graph.mode = &quot;directed&quot;, edge.arrow.size = 0.5, edge.scaling.factor = 2, vertex.label.cex = 0.75, vertex.label.family = &quot;sans&quot;) Consultez AQP project pour des pr√©sentations, des tutoriels et des exemples de figures qui montrent les nombreuses possibilit√©s du package AQP. 8.3.4 M√©ta-analyses en R Je conseille les livres Introduction to Meta-Analysis, Meta-analysis with R et Handbook of Meta-analysis in Ecology and Evolution pour les m√©ta-analyses sur des √©cosyst√®mes. Le module metafor est un ioncournable pour effectuer des m√©taanalyses en R. On ne passe pas tout √† fait √† c√¥t√© si l‚Äôon utilise le module meta, lui-m√™me bas√© en partie sur metafor. Le module meta a touttefois l‚Äôavantage d‚Äô√™tre simple d‚Äôutilisation. Par exemple, pour une m√©ta-analyse d‚Äôune r√©ponse continue, library(&quot;meta&quot;) ## Loading &#39;meta&#39; package (version 4.9-9). ## Type &#39;help(meta)&#39; for a brief overview. ## ## Attaching package: &#39;meta&#39; ## The following object is masked _by_ &#39;.GlobalEnv&#39;: ## ## ci meta_data &lt;- read_csv(&quot;https://portal.uni-freiburg.de/imbi/_SUPPRESS_ACCESSRULE/lehre/lehrbuecher/meta-analysis-with-r/dataset02.csv&quot;) ## Parsed with column specification: ## cols( ## author = col_character(), ## Ne = col_double(), ## Me = col_double(), ## Se = col_double(), ## Nc = col_double(), ## Mc = col_double(), ## Sc = col_double() ## ) meta_analyse &lt;- metacont(n.e = Ne, mean.e = Me, sd.e = Se, n.c = Nc, mean.c = Mc, sd.c = Sc, data = meta_data, sm = &quot;SMD&quot;) meta_analyse ## SMD 95%-CI %W(fixed) %W(random) ## 1 -0.5990 [-1.3300; 0.1320] 3.5 5.7 ## 2 -0.9518 [-1.6770; -0.2266] 3.6 5.7 ## 3 -0.5909 [-1.6301; 0.4483] 1.7 4.1 ## 4 -0.7064 [-1.7986; 0.3858] 1.6 3.9 ## 5 -0.2815 [-0.6076; 0.0445] 17.6 8.1 ## 6 -0.5375 [-1.0816; 0.0065] 6.3 6.8 ## 7 -1.3204 [-2.1896; -0.4513] 2.5 4.9 ## 8 -0.4800 [-1.3514; 0.3914] 2.5 4.9 ## 9 0.0918 [-0.2549; 0.4385] 15.6 8.0 ## 10 -3.2433 [-4.2035; -2.2831] 2.0 4.5 ## 11 0.0000 [-0.7427; 0.7427] 3.4 5.6 ## 12 -0.7061 [-1.2020; -0.2102] 7.6 7.1 ## 13 -0.4724 [-1.2537; 0.3089] 3.1 5.4 ## 14 -0.1849 [-0.5071; 0.1373] 18.0 8.2 ## 15 -0.0265 [-0.6045; 0.5515] 5.6 6.6 ## 16 -1.1648 [-2.0828; -0.2468] 2.2 4.7 ## 17 -0.2127 [-0.9651; 0.5397] 3.3 5.6 ## ## Number of studies combined: k = 17 ## ## SMD 95%-CI z p-value ## Fixed effect model -0.3915 [-0.5283; -0.2548] -5.61 &lt; 0.0001 ## Random effects model -0.5858 [-0.8703; -0.3013] -4.04 &lt; 0.0001 ## ## Quantifying heterogeneity: ## tau^2 = 0.2309 [0.1376; 0.9813]; tau = 0.4806 [0.3710; 0.9906]; ## I^2 = 72.5% [55.4%; 83.1%]; H = 1.91 [1.50; 2.43] ## ## Test of heterogeneity: ## Q d.f. p-value ## 58.27 16 &lt; 0.0001 ## ## Details on meta-analytical method: ## - Inverse variance method ## - DerSimonian-Laird estimator for tau^2 ## - Jackson method for confidence interval of tau^2 and tau ## - Hedges&#39; g (bias corrected standardised mean difference) Et pour effectuer un forest plot, forest(meta_analyse) 8.3.5 Cr√©er des applications avec R RStudio vous permet de d√©ployer vos r√©sultats sous forme d‚Äôapplications web gr√¢ce √† son module shiny. Pour ce faire, le seul pr√©alable est de savoir programmer en R. En agen√ßant une interface avec des inputs (listes de s√©lection, des bo√Ætes de dialogue, des s√©lecteurs, des boutons, etc.) avec des mod√®les que vous d√©veloppez, vous pourrez cr√©er des interfaces int√©ractives. Pour cr√©er une application shiny, vous devez cr√©er une partie pour l‚Äôinterface (ui) et une autre pour le calcul (server). Je n‚Äôirai pas dans les d√©tails, √©tant donn√©e qu‚Äôil s‚Äôagit d‚Äôun sujet √† part enti√®re. Pour aller plus loin, visitez le site du projet shiny. library(&quot;shiny&quot;) ui &lt;- basicPage( sliderInput(&quot;A&quot;, &quot;Asymptote:&quot;, min = 0, max = 100, value = 50), sliderInput(&quot;E&quot;, &quot;Environnement:&quot;, min = -10, max = 100, value = 20), sliderInput(&quot;R&quot;, &quot;Taux:&quot;, min = 0, max = 0.1, value = 0.035), sliderInput(&quot;prix_dose&quot;, &quot;Prix dose:&quot;, min = 0, max = 5, value = 1), sliderInput(&quot;prix_vente&quot;, &quot;Prix vente:&quot;, min = 0, max = 200, value = 100), sliderInput(&quot;dose&quot;, &quot;Dose:&quot;, min = 0, max = 300, value = c(0, 200)), plotOutput(&quot;distPlot&quot;) ) server &lt;- function(input, output) { mitsch_f &lt;- reactive({ input$A * (1 - exp(-input$R * (seq(input$dose[1], input$dose[2], length = 100) + input$E))) }) mitsch_opt &lt;- reactive({ (log((input$A * input$R * input$prix_vente) / input$prix_dose - input$E * input$R) / input$R ) }) output$distPlot &lt;- renderPlot({ plot(seq(input$dose[1], input$dose[2], length = 100), mitsch_f(), type = &quot;l&quot;, ylim = c(0, 100)) abline(v = mitsch_opt() ) text(mitsch_opt(), 2, paste(&quot;Dose optimale:&quot;, round(mitsch_opt(), 0))) }) } shinyApp(ui, server) Une fois l‚Äôapplication cr√©√©e, il est possible de la d√©ployer sur le site shninyapps.io. D‚Äôabord cr√©er une application shiny dans RStudio: File &gt; New File &gt; Shiny Web App. √âcrivez votre code dans le fichier app.R (dans ce cas, ce peut √™tre un copier-coller), puis cliquez sur Run App en haut √† droite de la fen√™tre d‚Äô√©dition du code. Lorsque l‚Äôapplication fonctionne, vous pourrez la publier via RStudio en cliquant sur le bouton Publish dans la fen√™tre Viewer (vous devez au pr√©alable avoir un comte sur shinyapp.io). Une application sera publique et sera ouverte. https://essicolo.shinyapps.io/Mitscherlich/ Pour d√©ployer en mode priv√©, vous devrez d√©bourser pour un forfait ou installer votre propre serveur. 8.3.6 Travailler en Python Le chapitre 7 a pr√©sent√© un module pour les statistiques bay√©siennes n√©cessitant un environnement Python. Il s‚Äôagissait de faire fonctionner un module en R qui, √† l‚Äôinterne, effectue ses calculs en Python. Rien ne vous emp√™che d‚Äôeffectuer des calculs directement en Python √† m√™me l‚Äôinterface de RStudio. Il vous faudra d‚Äôabord installer Python et les modules de calcul que vous d√©sirez. Il existe plusieurs distributions de Python. Parmi elles, Anaconda est probablement la plus intuitive √† installer. Choisissez d‚Äôabord Anaconda (~500 Mo) ou Miniconda pour une installation minimale (~60 Mo) - si vous installez Miniconda, vous devrez aussi installer les modules n√©cessaires pour le calcul. Installez aussi le module reticulate de R, de sortte que vous puissiez communiquer avec Python. Anaconda fonctionne avec des environnements de calcul. Chaque environnement poss√®de sa propre version de Python et ses propres modules: cela vous permet d‚Äôisoler vos environnements et de contr√¥ler la version des modules. Vous pouvez connecter R √† l‚Äôenvironnement de base cr√©√© lors de l‚Äôinstallation d‚ÄôAnaconda, ou bien en cr√©er un autre. Pour en cr√©er un nouveau, incluant une liste de modules de calcul, library(&quot;reticulate&quot;) conda_create(envname = &quot;monprojet&quot;, packages = c(&quot;python&quot;, &quot;numpy&quot;, &quot;scipy&quot;, &quot;matplotlib&quot;, &quot;pandas&quot;, &quot;scikit-learn&quot;)) Connectez-vous √† votre environnement Python. library(&quot;reticulate&quot;) use_condaenv(&quot;monprojet&quot;, required = TRUE) # use_python(&quot;home/essi/anaconda3/bin/&quot;) # ou le chemin vers l&#39;ex√©cutable pyhton, attention, non reproductible! Supposons que vous travailliez en R markdown. Pour lancer un bloc de code en Python, indiquez {python} au lieu de {r} dans l‚Äôent√™te. # ```{python} import numpy as np import matplotlib.pyplot as plt a = np.linspace(0, 30, 101) b = np.sin(a) plt.plot(a, b) plt.title(&quot;Un graphique en Matplotlib dans RStudio&quot;) # ``` Pour r√©cup√©rer une variable Python en R, pr√©c√©dez la variable de py$. plot(py$a, py$b, type = &quot;l&quot;, main = &quot;Un graphique en R avec \\n des variables d√©finies en Python&quot;) Idem, pour r√©cup√©rer un objet R en Python, . r.iris.head(6) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 0 5.1 3.5 1.4 0.2 setosa ## 1 4.9 3.0 1.4 0.2 setosa ## 2 4.7 3.2 1.3 0.2 setosa ## 3 4.6 3.1 1.5 0.2 setosa ## 4 5.0 3.6 1.4 0.2 setosa ## 5 5.4 3.9 1.7 0.4 setosa Vous aurez ainsi acc√®s aux fonctionnalit√©s de Python et R dans un m√™me flux de travail. "]
]
