[
["chapitre-explorer.html", "7 Explorer R 7.1 R sur le web 7.2 R en chaire et en os 7.3 Quelques outils en Ã©cologie mathÃ©matique avec R", " 7 Explorer R Lâ€™apprentissage de R peut Ãªtre Ã©tourdissant. Cette section est une petite pause fourre-tout qui vous introduira aux nombreuses possibilitÃ©s de R. ï¸Â Objectifs spÃ©cifiques: Ã€ la fin de ce chapitre, vous serez en mesure dâ€™identifier les sources dâ€™information principales sur le dÃ©veloppement de R et de ses modules comprendrez lâ€™importance du prÃ©traitement des donnÃ©es, en particulier dans le cadre de lâ€™analyse de donnÃ©es compositionnelles, et saurez effectuer un prÃ©traitement adÃ©quat saurez comment acquÃ©rir des donnÃ©es mÃ©tÃ©o dâ€™Environnement Canada avec le module weathercan saurez identifier les modules dâ€™analyse de sols (soiltexture et aqp) saurez crÃ©er des cartes etc. Pour certains, le langage R est un labyrinthe. Pour dâ€™autres, câ€™est une myriade de portes ouvertes. Si vous lisez ce manuel, vous vous Ãªtes peut-Ãªtre engagÃ© dans un labyrinthe dans lâ€™objectif dâ€™y trouver la clÃ© qui dÃ©vÃ©rouillera une porte bien prÃ©cise qui mÃ¨ne Ã  un trÃ©sor, un objet magiqueâ€¦ ou un diplÃ´me. Peut-Ãªtre aussi prendrez-vous le goÃ»t dâ€™errer dans ce labyrinthe, explorant ses dÃ©bouchÃ©s, pour y dÃ©nicher au hasard des petits outils et des dÃ©bouchÃ©s. SÃ©quence du jeu vidÃ©o The legend of Zelda. Cette section est un amalgame de plusieurs outils de R pertinents en analyse Ã©cologique. 7.1 R sur le web Dans un environnement de travail en Ã©volution rapide et constante, il est difficile de considÃ©rer que ses compÃ©tences sont abouties. Rester informÃ© sur le dÃ©veloppement de R vous permettra de dÃ©nicher de rÃ©soudre des problÃ¨mes persistants de maniÃ¨re plus efficace ou par de nouvelles avenues, et vous offrira mÃªme lâ€™occasion de dÃ©nicher des problÃ¨mes dont vous ne soupÃ§onniez pas lâ€™existance. Plusieurs sources dâ€™information vous permettront de vous tenir Ã  jour sur le dÃ©veloppement de R, de ses environnement de travail (RStudio, Jupyter, Atom, etc.) et des nouveaux modules qui sâ€™y greffent. Plus largement, vous gagnerez Ã  vous informer sur les derniÃ¨res tendances en calcul scientifique sur dâ€™autres plate-forme que R (Python, Javascript, Julia, etc.). Ã‰videmment, nos tÃ¢ches quotidiennes ne nous permettent pas de tout suivre. MÃªme si vous pouviez nâ€™attrapper quâ€™1% du dÃ©filement, ce sera dÃ©jÃ  1% de plus que rien du tout. Ã‰videmment, rester au courant aide parce que vous en apprenez davantage sur les outils et leurs applications. Mais Ã§a aide aussi parce que Ã§a vous permet de connaÃ®tre des gens et des organisations! Il est trÃ¨s utile de savoir qui travaille sur quoi et oÃ¹ se dÃ©roulent les dÃ©veloppements sur un sujet donnÃ©, car si vous cherchez consciemment quelque chose plus tard, Ã§a vous aidera Ã  trouver votre chemin plus facilement. - MaÃ«lle Salmon, Keeping up to date with R news (ma traduction) Je vous propose une liste de ressources. Ne vous y tenez surtout pas: discartez ce qui ne vous convient pas, et partez Ã  lâ€™aventure! The Hobbit: An Unexpected Journey, Peter Jackson (2012) 7.1.1 GitHub Nous verrons au chapitre 11 lâ€™importance dâ€™utilser des outils dâ€™archivage et de suivi de version, comme git, dans le dÃ©ploiement de la science ouverte. Pour lâ€™instant, retenons que GitHub est une plate-forme git en ligne acquise par Microsoft qui est devenue un rÃ©seau social de dÃ©veloppement informatique. De nombreux modules de R y sont dÃ©veloppÃ©s. Au chapitre 11, vous serez invitÃ©s Ã  y ouvrir un compte et Ã  y archiver du contenu. Vous pourrez alors suivre (dans le mÃªme sens que sur Facebook ou Twitter) le dÃ©veloppement de projets et suivre les travaux des personnes qui vous semblent dâ€™intÃ©rÃªt. 7.1.2 Nouvelles Le site dâ€™aggrÃ©gation R-bloggers, mis Ã  jour quotidiennement, republie des articles en anglais tirÃ©s dâ€™un peu partout sur la toile. On y trouve principalement des tutoriels et des annonces de nouveaux dÃ©veloppement. Deux fois par mois, lâ€™organisation rOpenSci offre un portrait de lâ€™univ-R (ğŸ’©), ce que R Weekely offre de maniÃ¨re hebdomadaire (lâ€™information sera probablement redondante). Le tidyverse a quant Ã  lui son propre blogue. 7.1.3 Twitter Le hashtag #rstats rassemble sur Twitter ce qui se tweete sur le sujet. On y retrouve les comptes de R-bloggers, RStudio et rOpenSci. Certaines communautÃ© y sont aussi actives, comme R4DS online learning community, qui partage des nouvelles sur R, et R-Ladies Global, qui vise Ã  amener davantage de diversitÃ© Ã  la communautÃ© de R. Des comptes thÃ©matiques comme Daily R Cheatsheets et One R Package a Day permettent de dÃ©couvrir quotidiennement de nouvelles possibilitÃ©s. Enfin, plusieurs personnes contribuent positivement Ã  la communautÃ© R. Hadley Wickham brille parmi les Ã©toiles de R. Les comptes de Mara Averick, Claus Wilke et David Robinson sont aussi intÃ©ressants. 7.1.4 Des questions? Bien que davantage vouÃ©s Ã  la rÃ©solution de problÃ¨me quâ€™ Ã  lâ€™exploration de nouvelles opportunitÃ©s, Stackoverflow et Cross Validated sont des plate-forme prisÃ©es. De plus, la liste de courriels r-sig-ecology permet des Ã©changes entre professionnels et novices en analyse de donnÃ©es Ã©cologiques avec R. 7.1.5 Participer R est un logiciel basÃ© sur une communautÃ© de dÃ©veloppement, dâ€™utilisation et de vulgarisation. Des personnes offrent gÃ©nÃ©reusement du temps de support. Si vous vous sentez Ã  lâ€™aise, offrez aussi le vÃ´tre! 7.1.6 Mise en garde Les modules de R sont dÃ©veloppÃ©s par quiconque le veut bien: leur qualitÃ© nâ€™est pas nÃ©cessairement auditÃ©e. Souvent, ils ne sont vÃ©rifiÃ©s que par une vigilance communautaire: dans ce cas, vous Ãªtes les cobailles. Ce qui nâ€™est pas nÃ©cessairement une mauvaise chose, mais cela nÃ©cessite de prendre ses prÃ©cautions. Dans sa confÃ©rence How to be a resilient R user, MaÃ«lle Salmon propose quelques guides pour juger de la qualitÃ© dâ€™un module. 1. Le module est-il activement dÃ©veloppÃ©? Bien! Attention! 2. Le module est-il bien testÃ©? VÃ©rifiez si le module a fait lâ€™objet dâ€™une publication scientifique, sâ€™il a Ã©tÃ© utilisÃ© avec succÃ¨s dans la litÃ©rature ou dans des documents crÃ©dibles. 3. Le module est-il bien documentÃ©? Un site internet dÃ©diÃ© est-il utilisÃ© pour documenter lâ€™utilisation du module? Les fichiers dâ€™aide sont-ils complets, et sont-ils de bonne qualitÃ©? 4. Le module est-il largement utilisÃ©? Un module peu populaire nâ€™est pas nÃ©cessaissairement de mauvaise qualitÃ©: peut-Ãªtre est-il seulement destinÃ© Ã  des applications de niche. Sâ€™il nâ€™est pas un indicateur Ã  lui seul de la soliditÃ© ou la validitÃ© dâ€™un module, une masse critique indique que le module a passÃ© sous la surveillance de plusieurs utilisateurs. Dans GitHub, ceci peu Ãªtre Ã©valuÃ© par le nombre dâ€™Ã©toiles attribuÃ© au module (Ã©quivalent Ã  un Jâ€™aime). 5. Le module est-il dÃ©veloppÃ© par une personne ou une organisation crÃ©dible? On peut affirmer sans trop se compromettre que lâ€™Ã©quipe de RStudio dÃ©veloppe des modules de confiance. Tout comme il faudrait se mÃ©fier dâ€™un module dÃ©veloppÃ© par une personne anonyme. Le module packagemetrics permet dâ€™Ã©valuer ces critÃ¨res. library(&quot;packagemetrics&quot;) pm &lt;- package_list_metrics(c(&quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;vegan&quot;, &quot;greta&quot;)) metrics_table(pm) package published dl_last_month stars tidyverse_happy has_tests vignette last_commit last_issue_closed contributors depends_count reverse_count dplyr 2018-11-10 694730 2807 0.0 167 1 1081 ggplot2 2018-10-25 744917 3607 0.0 173 1 1494 vegan 2019-02-04 45385 139 0.3 19 3 97 greta 2018-10-30 505 353 2.3 11 1 0 7.1.7 Prendre tout Ã§a en note Un logiciel de prise de notes (comme Evernote, OneNote, Notion, Simplenote, Turtl, etc.) pourrait vous Ãªtre utile pour retrouver lâ€™information soutirÃ©e de vos flux dâ€™information. Mais certaines personnes consignent simplement leurs informations dans un carnet ou un document de traitement de texte. 7.2 R en chaire et en os Lâ€™UniversitÃ© Laval (institution auprÃ¨s de laquelle ce manuel est dÃ©veloppÃ©) sera haute en mai 2019 de la confÃ©rence R Ã  QuÃ©bec 2019. Des ateliers seront offerts pour les utilisateurs novices et avancÃ©s. 7.3 Quelques outils en Ã©cologie mathÃ©matique avec R 7.3.1 PrÃ©traitement des donnÃ©es Il arrive souvent ques les donnÃ©es brutes ne soient pas exprimÃ©es de maniÃ¨re appropriÃ©e ou optimale pour lâ€™analyse statistique ou la modÃ©lisation. Vous devrez alors effectuer un prÃ©traitement sur ces donnÃ©es. Lors du chapitre 5, nous avons abordÃ© la mise Ã  lâ€™Ã©chelle, oÃ¹ des variables numÃ©riques Ã©taient transformÃ©es pour avoir une moyenne de zÃ©ro et un Ã©cart-type de 1. Cette opÃ©ration permettait dâ€™apprÃ©cier les coefficients et leur incertitude sur une mÃªme Ã©chelle. Lâ€™encodage catÃ©gorielle a quant Ã  lui permi dâ€™utiliser des mÃ©thodes quantitatives sur des donnÃ©es qualitatives. Dans les deux cas, nous nâ€™avons pas utilisÃ© le terme, mais il sâ€™agissait dâ€™un prÃ©traitement, câ€™est-Ã -dire une transformation des donnÃ©es prÃ©alable Ã  lâ€™analyse ou la modÃ©lisation. Un prÃ©traitement peut consister simplement en une transformation logarithmique ou exponentielle. En particulier, si vos donnÃ©es forment une partie dâ€™un tout (exprimÃ©es en pourcentages ou fractions), vous devriez probablement utiliser un prÃ©traitement grÃ¢ce aux outils de lâ€™analyse compositionnelle. Avant de les aborder, nous allons traiter des transformations de base. 7.3.1.1 Standardisation La standardisation consiste Ã  centrer vos donnÃ©es Ã  une moyenne de 0 et Ã  les Ã©chelonner Ã  une variance de 1, câ€™est-Ã -dire \\[x_{standard} = \\frac{x - \\bar{x}}{\\sigma}\\] oÃ¹ \\(\\bar{x}\\) est la moyenne du vecteur \\(x\\) et oÃ¹ \\(\\sigma\\) est son Ã©cart-type. Ce prÃ©traitement des donnÃ©es peut sâ€™avÃ©rÃ©r utile lorsque la modÃ©lisation tient compte de lâ€™Ã©chelle de vos mesures (par exemple, les paramÃ¨tres de rÃ©gression vus au chapitre 5 ou les distances que nous verrons au chapitre 8). En effet, les pentes dâ€™une rÃ©gression linÃ©aire multiple ne pourront Ãªtre comparÃ©es entre elles que si elles sont une mÃªme Ã©chelle. Par exemple, on veut modÃ©liser la consommation en miles au gallon (mpg) de voitures en fonction de leur puissance (hp), le temps en secondes pour parcourir un quart de mile (qsec) et le nombre de cylindre. data(mtcars) modl &lt;- lm(mpg ~ hp + qsec + cyl, mtcars) summary(modl) ## ## Call: ## lm(formula = mpg ~ hp + qsec + cyl, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.3223 -1.9483 -0.5656 1.5452 7.7773 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 55.30540 9.03697 6.120 1.33e-06 *** ## hp -0.03552 0.01622 -2.190 0.03700 * ## qsec -0.89424 0.42755 -2.092 0.04567 * ## cyl -2.26960 0.54505 -4.164 0.00027 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.003 on 28 degrees of freedom ## Multiple R-squared: 0.7757, Adjusted R-squared: 0.7517 ## F-statistic: 32.29 on 3 and 28 DF, p-value: 3.135e-09 Les pentes signifient que la distance parcourue par gallon dâ€™essence diminue de 0.03552 miles au gallon pour chaque HP, de 0.89242 par seconde au quart de mile et de 2.2696 par cyclindre additionnel. Lâ€™interprÃ©tation est conviviale Ã  cette Ã©chelle. Mais lequel de ces effets est le plus important? L t value indique que ce seraient les cylindres. Mais pour juger lâ€™importance en terme de pente, il vaudrait mieux standardiser. library(&quot;tidyverse&quot;) ## â”€â”€ Attaching packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.2.1 â”€â”€ ## âœ” ggplot2 3.1.0 âœ” purrr 0.3.0 ## âœ” tibble 2.0.1 âœ” dplyr 0.7.8 ## âœ” tidyr 0.8.2 âœ” stringr 1.4.0 ## âœ” readr 1.3.1 âœ” forcats 0.3.0 ## â”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€ ## âœ– dplyr::filter() masks stats::filter() ## âœ– dplyr::lag() masks stats::lag() standardise &lt;- function(x) (x-mean(x))/sd(x) mtcars_sc &lt;- mtcars %&gt;% mutate_if(is.numeric, standardise) # ou bien scale(mtcars, center = TRUE, scale = TRUE) modl_sc &lt;- lm(mpg ~ hp + qsec + cyl, mtcars_sc) summary(modl_sc) ## ## Call: ## lm(formula = mpg ~ hp + qsec + cyl, data = mtcars_sc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.71716 -0.32326 -0.09384 0.25639 1.29042 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.061e-16 8.808e-02 0.000 1.00000 ## hp -4.041e-01 1.845e-01 -2.190 0.03700 * ## qsec -2.651e-01 1.268e-01 -2.092 0.04567 * ## cyl -6.725e-01 1.615e-01 -4.164 0.00027 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4983 on 28 degrees of freedom ## Multiple R-squared: 0.7757, Adjusted R-squared: 0.7517 ## F-statistic: 32.29 on 3 and 28 DF, p-value: 3.135e-09 Les valeurs des pentes ne peuvent plus Ãªtre interprÃ©tÃ©es directement, mais peuvent maintenant Ãªtre comparÃ©es entre elles. Dans ce cas, le nombre de cilyndres a en effet une importance plus grande que la puissance et le temps pour parcourir un 1/4 de mile. Les algorithmes basÃ©s sur des distances auront, de mÃªme, avantage Ã  Ãªtre standardisÃ©s. 7.3.1.2 Ã€ lâ€™Ã©chelle de la plage Si vous dÃ©sirez prÃ©server le zÃ©ro dans le cas de donnÃ©es positives ou plus gÃ©nÃ©ralement vous voulez que vos donnÃ©es prÃ©traitÃ©es soient positives, vous pouvez les transformer Ã  lâ€™Ã©chelle de la plage, câ€™est-Ã -dire les forcer Ã  sâ€™Ã©taler de 0 Ã  1: \\[ x_{range01} = \\frac{x - x_{min}}{x_{max} - x_{min}} \\] Cette transformation est sensible aux valeurs aberrantes, et une fois le vecteur transformÃ© les valeurs aberrantes seront toutefois plus difficiles Ã  dÃ©tecter. range_01 &lt;- function(x) (x-min(x))/(max(x) - min(x)) mtcars %&gt;% mutate_if(is.numeric, range_01) %&gt;% # en fait, toutes les colonnes sont numÃ©riques, alors mutate_all aurait pu Ãªtre utilisÃ© au lieu de mutate_if sample_n(4) ## mpg cyl disp hp drat wt qsec vs am ## 11 0.3148936 0.5 0.2407084 0.2508834 0.5345622 0.4927129 0.5238095 1 0 ## 24 0.1234043 1.0 0.6956847 0.6819788 0.4470046 0.5949885 0.1083333 0 0 ## 23 0.2042553 1.0 0.5809429 0.3462898 0.1797235 0.4914344 0.3333333 0 0 ## 6 0.3276596 0.5 0.3838863 0.1872792 0.0000000 0.4978266 0.6809524 1 0 ## gear carb ## 11 0.5 0.4285714 ## 24 0.0 0.4285714 ## 23 0.0 0.1428571 ## 6 0.0 0.0000000 7.3.1.3 Normaliser Le terme normaliser est associer Ã  des opÃ©rations diffÃ©rentes dans la littÃ©rature. Nous prendrons la nomenclature de scikit-learn, pour qui la normalisation consiste Ã  faire en sorte que la longueur du vecteur (sa norme, dâ€™oÃ¹ normaliser) soit unitaire. Cette opÃ©ration est le plus souvent utilisÃ©e par observation (ligne), non pas par variable (colonne). Il existe plusieurs maniÃ¨res de mesures la distance dâ€™un vecteur, mais la plus commune est la distance euclidienne. La seule fois que jâ€™ai eu Ã  utiliser ce prÃ©traitement Ã©tait en analyse spectrale (Chemometrics with R, Ron Wehrens, 2011, chapitre 3.5). En R, library(&quot;pls&quot;) ## ## Attaching package: &#39;pls&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## loadings data(&quot;gasoline&quot;) spectro &lt;- gasoline$NIR %&gt;% unclass() %&gt;% as_tibble() normalise &lt;- function(x) x/sqrt(sum(x^2)) spectro_norm &lt;- spectro %&gt;% rowwise() %&gt;% # diffÃ©rentes approches possibles pour les opÃ©rations sur les lignes normalise() spectro_norm[1:4, 1:4] ## 900 nm 902 nm 904 nm 906 nm ## 1 -0.0011224834 -0.0010265446 -0.0009434425 -0.0008314021 ## 2 -0.0009890637 -0.0008856332 -0.0007977676 -0.0006912734 ## 3 -0.0010481029 -0.0009227116 -0.0008269742 -0.0007035061 ## 4 -0.0010444801 -0.0009446277 -0.0008623530 -0.0007718261 7.3.1.4 Analyse compositionnelle en R En 1898, le statisticien Karl Pearson nota que des corrÃ©lations Ã©taient induites lorsque lâ€™on effectuait des ratios par rapport Ã  une variable commune. Source Karl Pearson, 1897. Mathematical contributions to the theory of evolution.â€”on a form of spurious correlation which may arise when indices are used in the measurement of organs. Proceedings of the royal society of London Faisons lâ€™exercice! Nous gÃ©nÃ©rons au hasard 1000 donnÃ©es (comme le proposait Pearson) pour trois dimensions: le fÃ©mur, le tibia et lâ€™humÃ©rus. Ces dimensions ne sont pas gÃ©nÃ©rÃ©es par des distributions corrÃ©lÃ©es. set.seed(3570536) n &lt;- 1000 bones &lt;- tibble(femur = rnorm(n, 10, 3), tibia = rnorm(n, 8, 2), humerus = rnorm(n, 6, 2)) plot(bones) cor(bones) ## femur tibia humerus ## femur 1.000000000 -0.069006171 0.002652292 ## tibia -0.069006171 1.000000000 -0.008994704 ## humerus 0.002652292 -0.008994704 1.000000000 Pourtant, si jâ€™utilise des ratios allomÃ©triques avec lâ€™humÃ©rus comme base, bones_r &lt;- bones %&gt;% transmute(fh = femur/humerus, th = tibia/humerus) plot(bones_r) text(30, 20, paste(&quot;corrÃ©lation =&quot;, round(cor(bones_r$fh, bones_r$th), 2)), col = &quot;blue&quot;) Nous avons induit ce que Pearson appelait une fausse corrÃ©lation (spurious correlation). En 1960, Chayes proposa que de telles fausses corrÃ©lations sont induites non seulement sur des ratios de valeurs absolues, mais aussi sur des ratios dâ€™une somme totale. Par exemple, dans une composition simple de deux types dâ€™utilisation du territoire, si une proportion augmente, lâ€™autre doit nÃ©cessairement diminuer. n &lt;- 100 tibble(A = runif(n, 0, 1)) %&gt;% mutate(B = 1 - A) %&gt;% ggplot(aes(x=A, y=B)) + geom_point() Les variables exprimÃ©es relativement Ã  une somme totale sont dites compositionnelles. Elles possÃ¨dent les caractÃ©ristiques suivantes. Redondance dâ€™information. Un systÃ¨me de deux proportions ne contient quâ€™une seule variable du fait que lâ€™on puisse dÃ©duire lâ€™une en soutrayant lâ€™autre de la somme totale. Un vecteur compositionnel contient de lâ€™information redondante. Pourtant, effectuer des statistiques sur lâ€™une plutÃ´t que sur lâ€™autre donnera des rÃ©sultats diffÃ©rents. DÃ©pendance dâ€™Ã©chelle. Les statistiques devraient Ãªtre indÃ©pendantes de la somme totale utilisÃ©e. Pourtant, elles diffÃ©reront sur lâ€™on utilise par exemple, une proportion des mÃ¢les dâ€™une part et des femelles dâ€™autre part, ou la proportion de la somme des deux, de mÃªme que les rÃ©sultats dâ€™un test sanguin diffÃ©rera si lâ€™on utilise une base sÃ¨che ou une base humide. Distribution thÃ©orique des donnÃ©es. Ã‰tant donnÃ©e que les proportions sont confinÃ©es entre 0 et 1 (ou 100%, ou une somme totale quelconque), la distribution normale (qui sâ€™Ã©tend de -âˆ Ã  +âˆ) nâ€™est souvent pas appropriÃ©e. On pourra utiliser la distribution de Dirichlet, mais dâ€™autres approches sont souvent plus pratiques. Les consÃ©quences dâ€™effectuer des statistiques linÃ©aires sur des donnÃ©es compositionnelles brutes peuvent Ãªtre majeures. En outre, Pawlowksy-Glahn et Egozcue (2006), sâ€™appuyant en outre sur Rock (1988), note les problÃ¨mes suivants (exprimÃ©s en mes mots). les rÃ©gressions, les regroupements et les analyses en composantes principales peuvent avoit peu ou pas de signification les propriÃ©tÃ©s des distributions peuvent Ãªtre gÃ©nÃ©rÃ©es par lâ€™opÃ©ration de fermeture de la composition (sâ€™assurer que le total des proportions donne 100%) les rÃ©sultats dâ€™analyses discriminantes linÃ©aries sont propices Ã  Ãªtre illusoires tous les coefficients de corrÃ©lation seront affectÃ©s Ã  des degrÃ©s inconnus les rÃ©sultats des tests dâ€™hypothÃ¨ses seront intrinsÃ¨quement faussÃ©s Pour contourner ces problÃ¨mes, il faut dâ€™abord aborder les donnÃ©es compositionnelles pour ce quâ€™elles sont: des donnÃ©es intrinsÃ¨quement multivariÃ©es. Elles sont un nuage de point, et non pas une collection de variables individuelles. Ceci qui nâ€™empÃªche pas dâ€™effectuer des analyses consciencieusement sous des angles particuliers. En R, on pourra aisÃ©ment rapporter une composition en somme unitaire grÃ¢ce Ã  la fonction apply. Mais auparavant, chargeons le module compositions (nâ€™oubliez pas de lâ€™installer au prÃ©alable) pour accÃ©der Ã  des donnÃ©es fictives de proportions de sable, limon et argile dans des sÃ©diments. library(&quot;compositions&quot;) ## Loading required package: tensorA ## ## Attaching package: &#39;tensorA&#39; ## The following object is masked from &#39;package:base&#39;: ## ## norm ## Loading required package: robustbase ## Loading required package: energy ## Loading required package: bayesm ## Welcome to compositions, a package for compositional data analysis. ## Find an intro with &quot;? compositions&quot; ## ## Attaching package: &#39;compositions&#39; ## The following object is masked from &#39;package:pls&#39;: ## ## R2 ## The following objects are masked from &#39;package:stats&#39;: ## ## cor, cov, dist, var ## The following objects are masked from &#39;package:base&#39;: ## ## %*%, scale, scale.default data(&quot;ArcticLake&quot;) ArcticLake &lt;- ArcticLake %&gt;% as_tibble() head(ArcticLake) ## # A tibble: 6 x 4 ## sand silt clay depth ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 77.5 19.5 3 10.4 ## 2 71.9 24.9 3.2 11.7 ## 3 50.7 36.1 13.2 12.8 ## 4 52.2 40.9 6.6 13 ## 5 70 26.5 3.5 15.7 ## 6 66.5 32.2 1.3 16.3 comp &lt;- ArcticLake %&gt;% select(-depth) %&gt;% apply(., 1, function(x) x/sum(x)) %&gt;% t() comp[1:5, ] ## sand silt clay ## [1,] 0.7750000 0.1950000 0.0300000 ## [2,] 0.7190000 0.2490000 0.0320000 ## [3,] 0.5070000 0.3610000 0.1320000 ## [4,] 0.5235707 0.4102307 0.0661986 ## [5,] 0.7000000 0.2650000 0.0350000 On pourra aussi utiliser la fonction acomp (pour Aitchison-composition) pour fermer la composition Ã  une somme de 1. comp &lt;- ArcticLake %&gt;% select(-depth) %&gt;% acomp(.) comp[1:5, ] ## sand silt clay ## [1,] 0.7750000 0.1950000 0.0300000 ## [2,] 0.7190000 0.2490000 0.0320000 ## [3,] 0.5070000 0.3610000 0.1320000 ## [4,] 0.5235707 0.4102307 0.0661986 ## [5,] 0.7000000 0.2650000 0.0350000 Cette stratÃ©gie a pour avantage dâ€™attribuer Ã  la variable comp la classe acomp, qui automatise les opÃ©rations dans lâ€™espace compositionnel (que lâ€™on nomme aussi le simplex). La reprÃ©sentation ternaire est souvent utilisÃ©e pour prÃ©senter des compositions. Toutefois, il est difficile dâ€™interprÃ©ter les compositions de plus de trois parties. La classe acomp automatise aussi la reprÃ©sentation teranaire. plot(comp) Afin de transposer cet espace clÃ´t en un espace ouvert, on pourra diviser chaque proportion par une proportion de rÃ©fÃ©rence choisie parmi nâ€™importe quelle proportion. Du coup, on retire une dimension redondante! Dans ce ratio, on choisit dâ€™utiliser la proportion de rÃ©fÃ©rence au dÃ©nominateur, ce qui est arbitraire. En utilisant le log du ratio, lâ€™inverse du ratio ne sera quâ€™un changement de signe, ce qui est pratique en statistiques linÃ©aries. Cette solution, proposÃ©e par Aitchison (1986), sâ€™applique non seulement sur les compositions Ã  deux composantes, mais sur toute composition. Il sâ€™agit alors dâ€™utiliser une composition de rÃ©fÃ©rence pour effecteur les ratios. Pour une composition de \\(A\\), \\(B\\), \\(C\\), \\(D\\) et \\(E\\): \\[alr_A = log \\left( \\frac{A}{E} \\right), alr_B = log \\left( \\frac{B}{E} \\right), alr_C = log \\left( \\frac{C}{E} \\right), alr_D = log \\left( \\frac{D}{E} \\right)\\] Dans R, la colonne de rÃ©fÃ©rence est par dÃ©faut la derniÃ¨re colonne de la matrice des compositions. add_lr &lt;- alr(comp) Cette derniÃ¨re stratÃ©gie se nomme les log-ratios aditifs (\\(alr\\) pour additive log-ratio). Bien que valide pour effectuer des tests statistiques, cette stratÃ©gie a le dÃ©savantage de dÃ©pendre de la dÃ©cision arbitraire de la composante Ã  utiliser au numÃ©rateur. DeuxiÃ¨me restriction des alr: les axes de lâ€™espace des alr nâ€™Ã©tant pas orthogonaux, ils ne peuvent pas Ãªtre utilisÃ©s pour effectuer des statistiques basÃ©es sur les distances (que nous couvrirons au chapitre 8). Lâ€™autre stratÃ©gie proposÃ©e par Aitchison Ã©tait dâ€™effectuer un log-ratio entre chaque composante et la moyenne gÃ©omÃ©trique de toutes les composantes. Cette transformation se nomme le log-ratio centrÃ© (\\(clr\\), pour centered log-ratio) \\[clr_i = log \\left( \\frac{x_i}{g \\left( x \\right)} \\right)\\] En R, cen_lr &lt;- clr(comp) Avec des CLRs, les distances sont valides. Maisâ€¦ nous restons avec le problÃ¨me de la redondance dâ€™information. En fait, la somme de chacunes des lignes dâ€™une matrice de clr est de 0. Pas trÃ¨s pratique lorsque lâ€™on effectue des statistiques incluant une inversion de la matrice de covariance (distance de Mahalanobis, gÃ©ostatistiques, etc.) #cen_lr %&gt;% # cov() %&gt;% # solve() # Error in solve.default(.) : le systÃ¨me est numÃ©riquement singulier : conditionnement de la rÃ©ciproque = 4.44407e-17 Enfin, une autre mÃ©thode de transformation dÃ©veloppÃ©e par Egoscue et al. (2003), les log-ratios isomÃ©triques (ou isometric log-ratios, ilr) projette les compositions comprenant D composantes dans un espace restreint de D-1 dimensions orthonormÃ©es. Ces dimensions doivent doivent Ãªtre prÃ©alablement Ã©tablie dans un dendrogramme de bifurcation, oÃ¹ chaque composante ou groupe de composante est successivement divisÃ© en deux embranchement. La maniÃ¨re dâ€™arranger ces balances importe peu, mais on aura avantage Ã  crÃ©er des balances interprÃ©tables. Le diagramme de balances peut Ãªtre encodÃ© dans une partition binaire sÃ©quentielle (ou sequential bianry partition, sbp). Une sbp est une matrice de contraste ou chaque ligne reprÃ©sente une partition entre deux variables ou groupes de variables. Une composante Ã©tiquettÃ©e +1 correspondra au groupe du numÃ©rateur, une composante Ã©tiquettÃ©e -1 au dÃ©nominateur et une composante Ã©tiquettÃ©e 0 sera exclue de la partition (Parent et al., 2013). Jâ€™ai reformulÃ© la fonction CoDaDendrogram pour que lâ€™on puisse ajouter des informations intÃ©ressantes sur les balants horizontaux. Cette fonction est disponible sur github. source(&quot;https://raw.githubusercontent.com/essicolo/AgFun/master/codadend2.R&quot;) sbp &lt;- matrix(c(1, 1,-1, 1,-1, 0), byrow = TRUE, ncol = 3) CoDaDendrogram2(comp, V = gsi.buildilrBase(t(sbp)), ylim = c(0, 1), equal.height = TRUE) Si la SBP est plus imposante, il pourrait Ãªtre plus aisÃ© de monter dans un chiffrier, puis de lâ€™importer dans R via un fichier csv. Le calcul des ILRs est effectuÃ© comme suit. \\[ ilr_i = \\sqrt{\\frac{n_i^+ n_i^-}{n_i^+ + n_i^-}} ln \\left( \\frac{g \\left( c_i^+ \\right)}{g \\left( c_i^+ \\right)} \\right) \\] ou, Ã  la ligne \\(i\\) de la SBP, \\(n_i^+\\) et \\(n_i^-\\) sont respectivement le nombre de composantes au numÃ©rateur et au dÃ©nominateur, \\(g \\left( c_i^+ \\right)\\) est la moyenne gÃ©omÃ©trique des composantes au numÃ©rateur et \\(g \\left( c_i^- \\right)\\) est la moyenne gÃ©omÃ©trique des composantes au dÃ©nominateur. Les balances sont conventionnellement notÃ©es [A,B | C,D], ou les composantes A et B au dÃ©nominateur sont balancÃ©es avec les composantes C and D au numÃ©rateur. Une balance positive signifie que la moyenne gÃ©omÃ©trique des concentrations au numÃ©rateur est supÃ©rieur Ã  celle au dÃ©nominateur, et inversement, alors quâ€™une balance nulle signifie que les moyennes gÃ©omÃ©triques sont Ã©gales (Ã©quilibre). Ainsi, en modÃ©lisation linÃ©aire, un coefficient positif sur [A,B | C,D] signifie que lâ€™augmentation de lâ€™importance de C et D comparativement Ã  A et B est associÃ© Ã  une augmentation de la variable rÃ©ponse du modÃ¨le. En R, iso_lr &lt;- ilr(comp, V = gsi.buildilrBase(t(sbp))) Notez la forme gsi.buildilrBase(t(sbp)) est une opÃ©ration pour obtenir la matrice dâ€™orthonormalitÃ© Ã  partir de la SBP. Les ILRs sont des balances multivariÃ©es sur lesquelles on pourra effectuer des statistiques linÃ©aries. Bien que ni les statistiques linÃ©aires multivariÃ©es, la distance entre les points ne seront affectÃ©s par la structure de la SBP, lâ€™interprÃ©tation des rÃ©sultats comme collection dâ€™interprÃ©tation univariÃ©e pourra Ãªtre affectÃ©e. Pour les transformations inverses, vous pourrez utiliser les fonctions alrInv, clrInv et ilrInv. Dans tous les cas, si vous tenez Ã  garder la trace de vos donnÃ©es dans leur format original, vous aurez avantage Ã  ajouter Ã  votre vecteur compositionnel la valeur de remplissage, constituÃ© dâ€™un amalgame des composantes non mesurÃ©es. Par exemple, pourc &lt;- c(N = 0.03, P = 0.001, K = 0.01) acomp(pourc) # vous perdez la trace des proportions originales ## N P K ## 0.73170732 0.02439024 0.24390244 ## attr(,&quot;class&quot;) ## [1] acomp pourc &lt;- c(N = 0.03, P = 0.001, K = 0.01) Fv &lt;- 1 - sum(pourc) comp &lt;- acomp(c(pourc, Fv = Fv)) comp ## N P K Fv ## 0.030 0.001 0.010 0.959 ## attr(,&quot;class&quot;) ## [1] acomp iso_lr &lt;- ilr(comp) # avec une sbp par dÃ©faut ilrInv(iso_lr) ## 1 2 3 4 ## [1,] 0.03 0.001 0.01 0.959 ## attr(,&quot;class&quot;) ## [1] acomp Si vos donnÃ©es font partie dâ€™un tout, je vous recommande chaudement dâ€™utiliser des mÃ©thodes compositionnelles autant pour lâ€™analyse que la modÃ©lisation. Pour en savoir davantage, le livre Compositional data analysis with R, de van den Boogart et Tolosana-Delgado, est disponible en format Ã©lectronique Ã  la bibliothÃ¨que de lâ€™UniversitÃ© Laval. Pour aller plus loin, jâ€™ai Ã©cri un billet Ã  ce sujet (auquel Ã  ce jour il manque toujours un cas dâ€™Ã©tude): We should use balances and machine learning to diagnose ionomes. 7.3.2 AcquÃ©rir des donnÃ©es mÃ©tÃ©o Une tÃ¢che commune en Ã©cologie est de lier des observations Ã  la mÃ©tÃ©oâ€¦ qui sont rarement collectÃ©s lors dâ€™expÃ©riences. Environnement Canada possÃ¨de sont rÃ©seau de stations. Les donnÃ©es sont disponibles sur internet en libre accÃ¨s. Vous pouvez chercher des stations, effectuer des requÃªtes et tÃ©lÃ©charger des fichiers csv. Pour un petit tableau, la tÃ¢che est plutÃ´t triviale. Mais Ã§a devient rapidement laborieux Ã  mesure que lâ€™on doit rechercher de nombreuses donnÃ©es. Le module weathercan, dÃ©veloppÃ© par Steffi LaZerte, permet dâ€™effectuer des requÃªtes rapidement Ã  partir des coordonnÃ©es de votre site expÃ©rimental. Par exemple, si je cherche une station mÃ©tÃ©o sfournissant des donnÃ©es horaires situÃ© Ã  moins de 20 km du sommet du Mont-Bellevue, Ã  Sherbrooke, aux coordonnÃ©es [latitude 45.35, longitude -71.90], library(&quot;weathercan&quot;) station_site &lt;- stations_search(coords = c(45.35, -71.90), dist = 20, interval = &quot;hour&quot;) station_site ## # A tibble: 4 x 14 ## prov station_name station_id climate_id WMO_id TC_id lat lon elev ## &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 QC LENNOXVILLE 5397 7024280 71611 WQH 45.4 -71.8 181 ## 2 QC SHERBROOKE 48371 7028123 71610 YSC 45.4 -71.7 241. ## 3 QC SHERBROOKE A 5530 7028124 71610 YSC 45.4 -71.7 241. ## 4 QC SHERBROOKE A 30171 7028126 &lt;NA&gt; GSC 45.4 -71.7 241. ## # â€¦ with 5 more variables: tz &lt;chr&gt;, interval &lt;chr&gt;, start &lt;int&gt;, ## # end &lt;int&gt;, distance &lt;dbl&gt; Je prends en note lâ€™identifiant de la station dÃ©sirÃ©e (ou des stations, disons 5397 et 48371), puis je lance une requÃªte pour obtenir la mÃ©tÃ©o horaire entre les dates dÃ©sirÃ©es. mont_bellevue &lt;- weather_dl(station_ids = c(5397, 48371), start = &quot;2019-01-01&quot;, end = &quot;2019-01-07&quot;) mont_bellevue %&gt;% head(5) ## # A tibble: 5 x 35 ## station_name station_id station_operator prov lat lon elev ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 LENNOXVILLE 5397 Environment andâ€¦ QC 45.4 -71.8 181 ## 2 LENNOXVILLE 5397 Environment andâ€¦ QC 45.4 -71.8 181 ## 3 LENNOXVILLE 5397 Environment andâ€¦ QC 45.4 -71.8 181 ## 4 LENNOXVILLE 5397 Environment andâ€¦ QC 45.4 -71.8 181 ## 5 LENNOXVILLE 5397 Environment andâ€¦ QC 45.4 -71.8 181 ## # â€¦ with 28 more variables: climate_id &lt;chr&gt;, WMO_id &lt;chr&gt;, TC_id &lt;chr&gt;, ## # date &lt;date&gt;, time &lt;dttm&gt;, year &lt;chr&gt;, month &lt;chr&gt;, day &lt;chr&gt;, ## # hour &lt;chr&gt;, weather &lt;chr&gt;, hmdx &lt;dbl&gt;, hmdx_flag &lt;chr&gt;, ## # pressure &lt;dbl&gt;, pressure_flag &lt;chr&gt;, rel_hum &lt;dbl&gt;, ## # rel_hum_flag &lt;chr&gt;, temp &lt;dbl&gt;, temp_dew &lt;dbl&gt;, temp_dew_flag &lt;chr&gt;, ## # temp_flag &lt;chr&gt;, visib &lt;dbl&gt;, visib_flag &lt;chr&gt;, wind_chill &lt;dbl&gt;, ## # wind_chill_flag &lt;chr&gt;, wind_dir &lt;dbl&gt;, wind_dir_flag &lt;chr&gt;, ## # wind_spd &lt;dbl&gt;, wind_spd_flag &lt;chr&gt; Et voilÃ . mont_bellevue %&gt;% ggplot(aes(x = time, y = temp)) + geom_line(aes(colour = station_name)) 7.3.3 PÃ©domÃ©trie avec R Cette section a Ã©tÃ© Ã©crite par Michael Leblanc. Plusieurs fonctionnalitÃ©s ont Ã©tÃ© dÃ©veloppÃ©es sur R afin dâ€™aider les pÃ©domÃ©triciens Ã  visualiser, explorer et traiter les donnÃ©es numÃ©riques en science des sols. Voici quelques exemples. 7.3.3.1 Texture du sol La texture du sol est dÃ©finie par sa composition granulomÃ©trique, habituellement reprÃ©sentÃ©e par trois fractions (sable, limon, argile), laquelle peut Ãªtre gÃ©nÃ©ralisÃ©e en classe texturale. La dÃ©finition des classes texturales diffÃ¨re dâ€™un systÃ¨me ou dâ€™un pays Ã  lâ€™autre comme en tÃ©moigne lâ€™article Perdus dans le triangle des textures (Richer de Forges et al.Â 2008). La dÃ©finition des fractions granulomÃ©triques peut Ã©galement diffÃ©rer selon le domaine dâ€™Ã©tude (ingÃ©nierie, pÃ©dologie) ou le pays. Par exemple, le diamÃ¨tre du limon est de 0,002 mm Ã  0,05 mm dans le systÃ¨me canadien, amÃ©ricain et franÃ§ais alors quâ€™il est de 0,002 mm Ã  0,02 mm dans le systÃ¨me australien et de 0,002 mm Ã  0,063 mm dans le systÃ¨me allemand. Il est donc important de vÃ©rifier la mÃ©thodologie et le systÃ¨me de classification utilisÃ©s pour interprÃ©ter les donnÃ©es de texture du sol. Le module soilTexture propose des fonctions permettant dâ€™aborder ces multiples dÃ©finitions. library(&quot;soiltexture&quot;) Les triangles texturaux Avec la fonction TT.plot, vous pouvez prÃ©senter vos donnÃ©es granulomÃ©triques dans un triangle textural tel que dÃ©fini par les diffÃ©rents systÃ¨mes nationaux. Auparavant, crÃ©ons un objet comprenant des textures alÃ©atoires. set.seed(848341) # random.org rand_text &lt;- TT.dataset(n=100, seed.val=29) head(rand_text) ## CLAY SILT SAND Z ## 1 54.650857 40.37101 4.978129 13.2477582 ## 2 44.745954 40.81782 14.436221 20.8433109 ## 3 18.192509 48.26752 33.539970 7.1814626 ## 4 17.750492 40.14405 42.105458 -0.2077358 ## 5 65.518360 23.36110 11.120538 10.8656027 ## 6 6.610293 22.45353 70.936173 3.7108567 Avec le module soiltexture, les tableaux de texture doivent inclure les intitullÃ©s exactes CLAY, SILT et SAND (notez les majuscules). Les points des textures gÃ©nÃ©rÃ©es peuvent Ãªtre portÃ©s dans des diagrammes ternaires texturaux de diffÃ©rents systÃ¨mes de classification, par exemple le systÃ¨me canadioen et le systÃ¨me USDA. par(mfrow=c(1, 2)) TT.plot(class.sys = &quot;CA.FR.TT&quot;, tri.data = rand_text, col = &quot;blue&quot;) TT.plot(class.sys = &quot;USDA.TT&quot;, tri.data = rand_text, col = &quot;blue&quot;) Les paramÃ¨tres de la figure (titres, polices, style de la grille, etc.) peuvent Ãªtre personnalisÃ©s avec les arguments TT.plot. Les classes texturales La fonction TT.points.in.classes est utile pour dÃ©signer la classe texturale Ã  partir des donnÃ©es granulomÃ©triques, en spÃ©cifiant bien le systÃ¨me de classification dÃ©sirÃ©. TT.points.in.classes( tri.data = rand_text[1:10, ], # class.sys = &quot;CA.FR.TT&quot;, PiC.type = &quot;t&quot; ) ## [1] &quot;ALi&quot; &quot;ALi&quot; &quot;L&quot; &quot;L&quot; &quot;ALo&quot; &quot;LS&quot; &quot;ALo&quot; &quot;A&quot; &quot;LLi&quot; &quot;LSA&quot; Plusieurs autres fonctions sont proposÃ©es par soiltexture afin de visualiser, classifier et transformer les donnÃ©es de texture du sol : Functions in soiltexture. Julien Moeys (2018) propose Ã©galement le tutoriel The soil texture wizard: a tutorial. 7.3.3.2 Profils de sols Le profil de sols est une entitÃ© dÃ©crite par une sÃ©quence de couches ou dâ€™horizons avec diffÃ©rentes caractÃ©ristiques morphologiques. Le module AQP, pour Algorithms for Quantitative Pedology, propose des fonctions de visualisation, dâ€™agrÃ©gation et de classification permettant dâ€™aborder la complexitÃ© inhÃ©rente aux informations pÃ©dologiques. 7.3.3.2.1 La visualisation de profils Vous devez dâ€™abord structurer vos donnÃ©es dans un tableau (data.frame) incluant minimalement ces trois colonnes : Identifiant unique du profil (groupes dâ€™horizons) (id) Limites supÃ©rieures de lâ€™horizon (top) Limites infÃ©rieures de lâ€™horizon (down) Vos donnÃ©es morphologiques, physico-chimiques, etc., sont incluses dans les autres colonnes. Chargeons un fichier pÃ©dologique Ã  titre dâ€™exemple. profils &lt;- read_csv(&quot;data/06_pedometric-profile.csv&quot;) ## Parsed with column specification: ## cols( ## id = col_double(), ## horizon = col_character(), ## top = col_double(), ## bottom = col_double(), ## hue = col_character(), ## value = col_double(), ## chroma = col_double(), ## pH.CaCl2 = col_double(), ## C.CNS.pc = col_double() ## ) head(profils) ## # A tibble: 6 x 9 ## id horizon top bottom hue value chroma pH.CaCl2 C.CNS.pc ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Ap1 0 23 10YR 2 3 4.78 2.71 ## 2 1 Ap2 23 34 10YR 2 2 4.74 2.2 ## 3 1 Bfcj 34 46 7.5YR 4 5 4.79 2.4 ## 4 1 BC 46 83 2.5Y 4 5 4.93 0.22 ## 5 1 C 83 100 2.5Y 5 4 4.82 0.18 ## 6 2 Ap 0 29 10YR 2 2 4.6 4.22 La fonction munsell2rgb permet de convertir le code de couleur Munsell en format RGB. library(&quot;aqp&quot;) ## This is aqp 1.17 ## ## Attaching package: &#39;aqp&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## slice, union ## The following object is masked from &#39;package:base&#39;: ## ## union profils$soil_color &lt;- with(profils, munsell2rgb(hue, value, chroma)) PrÃ©alablement Ã  la visualisation, le tableau est transformÃ© en objet SoilProfileCollection par la fonction depths. Pour ce faire, le tableau doit Ãªtre un pur data.frame, non pas un tibble. profils &lt;- profils %&gt;% as.data.frame() depths(profils) &lt;- id ~ top + bottom La fonction plot dÃ©tectera le type dâ€™objet et appellera la fonction de visualisation en consÃ©quence. par(mfrow = c(1, 3)) plot(profils, name=&quot;horizon&quot;) title(&#39;Couleur des horizons&#39;, cex.main=1) plot(profils, name=&quot;horizon&quot;, color=&#39;C.CNS.pc&#39;, col.label=&#39;C total (%)&#39;) plot(profils, name=&quot;horizon&quot;, color=&#39;pH.CaCl2&#39;, col.label=&#39;pH CaCl2&#39;) De multiples figures thÃ©matiques peuvent Ãªtre gÃ©nÃ©rÃ©es afin de reprÃ©senter les particuliaritÃ©s des profils. Pour aller plus loin, consultez les guides Introduction to SoilProfileCollection Objects et Generating Sketches from SPC Objects. 7.3.3.2.2 Les plans verticaux (depth functions) Les plans verticaux sont des diagrammes qui permettent dâ€™interprÃ©ter les donnÃ©es en fonction de la profondeur. La fonction slab permet le calcul de statisques descriptives par interval de profondeur rÃ©gulier lesquelles permettent de figurer la variabilitÃ© verticale des propriÃ©tÃ©s de sols. agg &lt;- slab(profils, fm = ~ C.CNS.pc + pH.CaCl2) La visualisation est gÃ©nÃ©rÃ©e par le module graphique ggplot2 agg %&gt;% ggplot(mapping = aes(x = -top, y = p.q50)) + facet_grid(. ~ variable, scale = &quot;free&quot;) + geom_ribbon(aes(ymin = p.q25, ymax = p.q75), fill = &quot;grey75&quot;, alpha = 0.5) + geom_path() + labs(x = &quot;Profondeur (cm)&quot;, y = &quot;MÃ©diane bordÃ©e des 25e and 75e percentiles&quot;) + coord_flip() 7.3.3.2.3 Le regroupement de profils Le calcul des distances de dissimilaritÃ© entre les profils avec profile_compare permet la construction de dendrogramme et le regroupement des profils. Notez que nous survolerons au chapitre 8 les concepts de dissimilaritÃ© et de partitionnement. library(&quot;cluster&quot;) library(&quot;sharpshootR&quot;) d &lt;- profile_compare(profils, vars=c(&#39;C.CNS.pc&#39;, &#39;pH.CaCl2&#39;), k=0, max_d=40) ## Computing dissimilarity matrices from 10 profiles [0.08 Mb] d_diana &lt;- diana(d) plotProfileDendrogram(profils, name=&quot;horizon&quot;, d_diana, scaling.factor = 0.3, y.offset = 5, color=&#39;pH.CaCl2&#39;, col.label=&#39;pH CaCl2&#39;) 7.3.3.2.4 Diagramme de relations entre les horizons Il est possible de visualiser les transitions dâ€™horizon les plus probables dans un groupe de profils de sols. tp &lt;- hzTransitionProbabilities(profils, name=&quot;horizon&quot;) ## Warning: ties in transition probability matrix par(mar = c(0, 0, 0, 0), mfcol = c(1, 2)) plot(profils, name=&quot;horizon&quot;) plotSoilRelationGraph(tp, graph.mode = &quot;directed&quot;, edge.arrow.size = 0.5, edge.scaling.factor = 2, vertex.label.cex = 0.75, vertex.label.family = &quot;sans&quot;) Consultez AQP project pour des prÃ©sentations, des tutoriels et des exemples de figures qui montrent les nombreuses possibilitÃ©s du package AQP. 7.3.4 CrÃ©er des applications avec R RStudio vous permet de dÃ©ployer vos rÃ©sultats sous forme dâ€™applications web grÃ¢ce Ã  son module shiny. Pour ce faire, le seul prÃ©alable est de savoir programmer en R. En agenÃ§ant une interface avec des inputs (listes de sÃ©lection, des boÃ®tes de dialogue, des sÃ©lecteurs, des boutons, etc.) avec des modÃ¨les que vous dÃ©veloppez, vous pourrez crÃ©er des interfaces intÃ©ractives. Pour crÃ©er une application shiny, vous devez crÃ©er une partie pour lâ€™interface (ui) et une autre pour le calcul (server). Je nâ€™irai pas dans les dÃ©tails, Ã©tant donnÃ©e quâ€™il sâ€™agit dâ€™un sujet Ã  part entiÃ¨re. Pour aller plus loin, visitez le site du projet shiny. library(&quot;shiny&quot;) ui &lt;- basicPage( sliderInput(&quot;A&quot;, &quot;Asymptote:&quot;, min = 0, max = 100, value = 50), sliderInput(&quot;E&quot;, &quot;Environnement:&quot;, min = -10, max = 100, value = 20), sliderInput(&quot;R&quot;, &quot;Taux:&quot;, min = 0, max = 0.1, value = 0.035), sliderInput(&quot;prix_dose&quot;, &quot;Prix dose:&quot;, min = 0, max = 5, value = 1), sliderInput(&quot;prix_vente&quot;, &quot;Prix vente:&quot;, min = 0, max = 200, value = 100), sliderInput(&quot;dose&quot;, &quot;Dose:&quot;, min = 0, max = 300, value = c(0, 200)), plotOutput(&quot;distPlot&quot;) ) server &lt;- function(input, output) { mitsch_f &lt;- reactive({ input$A * (1 - exp(-input$R * (seq(input$dose[1], input$dose[2], length = 100) + input$E))) }) mitsch_opt &lt;- reactive({ (log((input$A * input$R * input$prix_vente) / input$prix_dose - input$E * input$R) / input$R ) }) output$distPlot &lt;- renderPlot({ plot(seq(input$dose[1], input$dose[2], length = 100), mitsch_f(), type = &quot;l&quot;, ylim = c(0, max(mitsch_f()) * 1.1)) abline(v = mitsch_opt() ) text(mitsch_opt(), 2, paste(&quot;Dose optimale:&quot;, round(mitsch_opt(), 0))) }) } shinyApp(ui, server) Une fois lâ€™application crÃ©Ã©e, il est possible de la dÃ©ployer sur le site shninyapps.io. Dâ€™abord crÃ©er une application shiny dans RStudio: File &gt; New File &gt; Shiny Web App. Ã‰crivez votre code dans le fichier app.R (dans ce cas, ce peut Ãªtre un copier-coller), puis cliquez sur Run App en haut Ã  droite de la fenÃªtre dâ€™Ã©dition du code. Lorsque lâ€™application fonctionne, vous pourrez la publier via RStudio en cliquant sur le bouton Publish dans la fenÃªtre Viewer (vous devez au prÃ©alable avoir un comte sur shinyapp.io). Une application sera publique et sera ouverte. https://essicolo.shinyapps.io/Mitscherlich/ Pour dÃ©ployer en mode privÃ©, vous devrez dÃ©bourser pour un forfait ou installer votre propre serveur. "]
]
