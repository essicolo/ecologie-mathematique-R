<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>12 Autoapprentissage | Analyse et mod√©lisation d‚Äôagro√©cosyst√®mes</title>
  <meta name="description" content="Ce cours a pour objectif de former les √©tudiants gradu√©s en g√©nie agroenvironnemental, g√©nie civil, g√©nie √©cologique, agronomie, biologie, foresterie et √©cologie en analyse et mod√©lisation de syst√®mes vivants. Les sujets trait√©s sont l‚Äôintroduction au langage de programmation R, l‚Äôanalyse statistique descriptive, la visualisation, la mod√©lisation inf√©rentielle, pr√©dictive et d√©terministe.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="12 Autoapprentissage | Analyse et mod√©lisation d‚Äôagro√©cosyst√®mes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce cours a pour objectif de former les √©tudiants gradu√©s en g√©nie agroenvironnemental, g√©nie civil, g√©nie √©cologique, agronomie, biologie, foresterie et √©cologie en analyse et mod√©lisation de syst√®mes vivants. Les sujets trait√©s sont l‚Äôintroduction au langage de programmation R, l‚Äôanalyse statistique descriptive, la visualisation, la mod√©lisation inf√©rentielle, pr√©dictive et d√©terministe." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="12 Autoapprentissage | Analyse et mod√©lisation d‚Äôagro√©cosyst√®mes" />
  
  <meta name="twitter:description" content="Ce cours a pour objectif de former les √©tudiants gradu√©s en g√©nie agroenvironnemental, g√©nie civil, g√©nie √©cologique, agronomie, biologie, foresterie et √©cologie en analyse et mod√©lisation de syst√®mes vivants. Les sujets trait√©s sont l‚Äôintroduction au langage de programmation R, l‚Äôanalyse statistique descriptive, la visualisation, la mod√©lisation inf√©rentielle, pr√©dictive et d√©terministe." />
  

<meta name="author" content="Serge-√âtienne Parent">


<meta name="date" content="2019-03-21">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapitre-git.html">
<link rel="next" href="chapitre-geo.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#definitions"><i class="fa fa-check"></i><b>1.1</b> D√©finitions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#a-qui-sadresse-ce-manuel"><i class="fa fa-check"></i><b>1.2</b> √Ä qui s‚Äôadresse ce manuel?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#les-logiciels-libres"><i class="fa fa-check"></i><b>1.3</b> Les logiciels libres</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#langage-de-programmation"><i class="fa fa-check"></i><b>1.4</b> Langage de programmation</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#r"><i class="fa fa-check"></i><b>1.4.1</b> R</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#pourquoi-pas-python"><i class="fa fa-check"></i><b>1.4.2</b> Pourquoi pas Python?</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#pourquoi-pas-matlab"><i class="fa fa-check"></i><b>1.4.3</b> Pourquoi pas Matlab?</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#et-sas"><i class="fa fa-check"></i><b>1.4.4</b> Et‚Ä¶ SAS?</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#mais-pourquoi-pas-______"><i class="fa fa-check"></i><b>1.4.5</b> Mais pourquoi pas ______ ?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#contenu-du-manuel"><i class="fa fa-check"></i><b>1.5</b> Contenu du manuel</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#objectifs-generaux"><i class="fa fa-check"></i><b>1.6</b> Objectifs g√©n√©raux</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#lectures-complementaires"><i class="fa fa-check"></i><b>1.7</b> Lectures compl√©mentaires</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#ecologie-mathematique"><i class="fa fa-check"></i><b>1.7.1</b> √âcologie math√©matique</a></li>
<li class="chapter" data-level="1.7.2" data-path="index.html"><a href="index.html#programmation"><i class="fa fa-check"></i><b>1.7.2</b> Programmation</a></li>
<li class="chapter" data-level="1.7.3" data-path="index.html"><a href="index.html#divers"><i class="fa fa-check"></i><b>1.7.3</b> Divers</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#besoin-daide"><i class="fa fa-check"></i><b>1.8</b> Besoin d‚Äôaide?</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#a-propos-de-lauteur"><i class="fa fa-check"></i><b>1.9</b> √Ä propos de l‚Äôauteur</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#un-cours-complementaire-a-dautres-cours"><i class="fa fa-check"></i><b>1.10</b> Un cours compl√©mentaire √† d‚Äôautres cours</a></li>
<li class="chapter" data-level="1.11" data-path="index.html"><a href="index.html#contribuer-au-manuel"><i class="fa fa-check"></i><b>1.11</b> Contribuer au manuel</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html"><i class="fa fa-check"></i><b>2</b> La science des donn√©es avec R</a><ul>
<li class="chapter" data-level="2.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#statistiques-ou-science-des-donnees"><i class="fa fa-check"></i><b>2.1</b> Statistiques ou Science des donn√©es?</a></li>
<li class="chapter" data-level="2.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#organiser-son-environnement-de-travail-en-r"><i class="fa fa-check"></i><b>2.2</b> Organiser son environnement de travail en R</a></li>
<li class="chapter" data-level="2.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#preparer-son-flux-de-travail"><i class="fa fa-check"></i><b>2.3</b> Pr√©parer son flux de travail</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-classique"><i class="fa fa-check"></i><b>2.3.1</b> Installation classique</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#r-notebooks"><i class="fa fa-check"></i><b>2.3.2</b> R notebooks</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-avec-anaconda"><i class="fa fa-check"></i><b>2.3.3</b> Installation avec Anaconda</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#premiers-pas-avec-r"><i class="fa fa-check"></i><b>2.4</b> Premiers pas avec R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#types-de-donnees"><i class="fa fa-check"></i><b>2.4.1</b> Types de donn√©es</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-collections-de-donnees"><i class="fa fa-check"></i><b>2.4.2</b> Les collections de donn√©es</a></li>
<li class="chapter" data-level="2.4.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-fonctions"><i class="fa fa-check"></i><b>2.4.3</b> Les fonctions</a></li>
<li class="chapter" data-level="2.4.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-boucles"><i class="fa fa-check"></i><b>2.4.4</b> Les boucles</a></li>
<li class="chapter" data-level="2.4.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#conditions-if-else-if-else"><i class="fa fa-check"></i><b>2.4.5</b> Conditions: if, else if, else</a></li>
<li class="chapter" data-level="2.4.6" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installer-et-charger-un-module"><i class="fa fa-check"></i><b>2.4.6</b> Installer et charger un module</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#enfin"><i class="fa fa-check"></i><b>2.5</b> Enfin‚Ä¶</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html"><i class="fa fa-check"></i><b>3</b> Organisation des donn√©es et op√©rations sur des tableaux</a><ul>
<li class="chapter" data-level="3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#les-collections-de-donnees-1"><i class="fa fa-check"></i><b>3.1</b> Les collections de donn√©es</a></li>
<li class="chapter" data-level="3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#organiser-un-tableau-de-donnees"><i class="fa fa-check"></i><b>3.2</b> Organiser un tableau de donn√©es</a></li>
<li class="chapter" data-level="3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#formats-de-tableau"><i class="fa fa-check"></i><b>3.3</b> Formats de tableau</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#xls-ou-xlsx"><i class="fa fa-check"></i><b>3.3.1</b> <em>xls</em> ou <em>xlsx</em></a></li>
<li class="chapter" data-level="3.3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#csv"><i class="fa fa-check"></i><b>3.3.2</b> <em>csv</em></a></li>
<li class="chapter" data-level="3.3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#json"><i class="fa fa-check"></i><b>3.3.3</b> <em>json</em></a></li>
<li class="chapter" data-level="3.3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#sqlite"><i class="fa fa-check"></i><b>3.3.4</b> SQLite</a></li>
<li class="chapter" data-level="3.3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#suggestion"><i class="fa fa-check"></i><b>3.3.5</b> Suggestion</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#entreposer-ses-donnees"><i class="fa fa-check"></i><b>3.4</b> Entreposer ses donn√©es</a></li>
<li class="chapter" data-level="3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#manipuler-des-donnees-en-mode-tidyverse"><i class="fa fa-check"></i><b>3.5</b> Manipuler des donn√©es en mode tidyverse</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#importer-vos-donnees-dans-voter-session-de-travail"><i class="fa fa-check"></i><b>3.5.1</b> Importer vos donn√©es dans voter session de travail</a></li>
<li class="chapter" data-level="3.5.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#comment-selectionner-et-filtrer-des-donnees"><i class="fa fa-check"></i><b>3.5.2</b> Comment s√©lectionner et filtrer des donn√©es?</a></li>
<li class="chapter" data-level="3.5.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#le-format-long-et-le-format-large"><i class="fa fa-check"></i><b>3.5.3</b> Le format long et le format large</a></li>
<li class="chapter" data-level="3.5.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#combiner-des-tableaux"><i class="fa fa-check"></i><b>3.5.4</b> Combiner des tableaux</a></li>
<li class="chapter" data-level="3.5.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#operations-sur-les-tableaux"><i class="fa fa-check"></i><b>3.5.5</b> Op√©rations sur les tableaux</a></li>
<li class="chapter" data-level="3.5.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exemple-difficile"><i class="fa fa-check"></i><b>3.5.6</b> Exemple (difficile)</a></li>
<li class="chapter" data-level="3.5.7" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exporter-un-tableau"><i class="fa fa-check"></i><b>3.5.7</b> Exporter un tableau</a></li>
<li class="chapter" data-level="3.5.8" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#aller-plus-loin-dans-le-tidyverse"><i class="fa fa-check"></i><b>3.5.8</b> Aller plus loin dans le tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#references"><i class="fa fa-check"></i><b>3.6</b> R√©f√©rences</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html"><i class="fa fa-check"></i><b>4</b> Visualisation</a><ul>
<li class="chapter" data-level="4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#pourquoi-explorer-graphiquement"><i class="fa fa-check"></i><b>4.1</b> Pourquoi explorer graphiquement?</a></li>
<li class="chapter" data-level="4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publier-un-graphique"><i class="fa fa-check"></i><b>4.2</b> Publier un graphique</a><ul>
<li class="chapter" data-level="4.2.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#cinq-qualites-dun-bon-graphique"><i class="fa fa-check"></i><b>4.2.1</b> Cinq qualit√©s d‚Äôun bon graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-le-type-de-graphique-le-plus-approprie"><i class="fa fa-check"></i><b>4.3</b> Choisir le type de graphique le plus appropri√©</a></li>
<li class="chapter" data-level="4.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-son-outils-de-visualisation"><i class="fa fa-check"></i><b>4.4</b> Choisir son outils de visualisation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-imperative"><i class="fa fa-check"></i><b>4.4.1</b> Approche imp√©rative</a></li>
<li class="chapter" data-level="4.4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-declarative"><i class="fa fa-check"></i><b>4.4.2</b> Approche d√©clarative</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visualisation-en-r"><i class="fa fa-check"></i><b>4.5</b> Visualisation en R</a></li>
<li class="chapter" data-level="4.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#module-de-base-pour-les-graphiques"><i class="fa fa-check"></i><b>4.6</b> Module de base pour les graphiques</a></li>
<li class="chapter" data-level="4.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#la-grammaire-graphique-ggplot2"><i class="fa fa-check"></i><b>4.7</b> La grammaire graphique ggplot2</a></li>
<li class="chapter" data-level="4.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#mon-premier-ggplot"><i class="fa fa-check"></i><b>4.8</b> Mon premier ggplot</a><ul>
<li class="chapter" data-level="4.8.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#plusieurs-sources-de-donnees"><i class="fa fa-check"></i><b>4.8.1</b> Plusieurs sources de donn√©es</a></li>
<li class="chapter" data-level="4.8.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-avec-style"><i class="fa fa-check"></i><b>4.8.2</b> Exporter avec style</a></li>
<li class="chapter" data-level="4.8.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#nuages-de-points"><i class="fa fa-check"></i><b>4.8.3</b> Nuages de points</a></li>
<li class="chapter" data-level="4.8.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#diagrammes-en-lignes"><i class="fa fa-check"></i><b>4.8.4</b> Diagrammes en lignes</a></li>
<li class="chapter" data-level="4.8.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-histogrammes"><i class="fa fa-check"></i><b>4.8.5</b> Les histogrammes</a></li>
<li class="chapter" data-level="4.8.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#boxplots"><i class="fa fa-check"></i><b>4.8.6</b> Boxplots</a></li>
<li class="chapter" data-level="4.8.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-diagrammes-en-barre"><i class="fa fa-check"></i><b>4.8.7</b> Les diagrammes en barre</a></li>
<li class="chapter" data-level="4.8.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-un-graphique"><i class="fa fa-check"></i><b>4.8.8</b> Exporter un graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-graphiques-comme-outil-dexploration-des-donnees"><i class="fa fa-check"></i><b>4.9</b> Les graphiques comme outil d‚Äôexploration des donn√©es</a><ul>
<li class="chapter" data-level="4.9.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-graphiques-interactifs"><i class="fa fa-check"></i><b>4.9.1</b> Des graphiques interactifs!</a></li>
<li class="chapter" data-level="4.9.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-extensions-de-ggplot2"><i class="fa fa-check"></i><b>4.9.2</b> Des extensions de ggplot2</a></li>
<li class="chapter" data-level="4.9.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#aller-plus-loin-avec-ggplot2"><i class="fa fa-check"></i><b>4.9.3</b> Aller plus loin avec ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-les-bonnes-couleurs"><i class="fa fa-check"></i><b>4.10</b> Choisir les bonnes couleurs</a></li>
<li class="chapter" data-level="4.11" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#regles-particulieres"><i class="fa fa-check"></i><b>4.11</b> R√®gles particuli√®res</a><ul>
<li class="chapter" data-level="4.11.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#ne-tronquez-pas-inutilement-laxe-des-y"><i class="fa fa-check"></i><b>4.11.1</b> Ne tronquez pas inutilement l‚Äôaxe des <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="4.11.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#utilisez-un-encrage-proportionnel"><i class="fa fa-check"></i><b>4.11.2</b> Utilisez un encrage proportionnel</a></li>
<li class="chapter" data-level="4.11.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publiez-vos-donnees"><i class="fa fa-check"></i><b>4.11.3</b> Publiez vos donn√©es</a></li>
<li class="chapter" data-level="4.11.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visitez-www.junkcharts.typepad.com-de-temps-a-autre"><i class="fa fa-check"></i><b>4.11.4</b> Visitez www.junkcharts.typepad.com de temps √† autre</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html"><i class="fa fa-check"></i><b>5</b> Biostatistiques</a><ul>
<li class="chapter" data-level="5.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#populations-et-echantillons"><i class="fa fa-check"></i><b>5.1</b> Populations et √©chantillons</a></li>
<li class="chapter" data-level="5.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-variables"><i class="fa fa-check"></i><b>5.2</b> Les variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-quantitatives"><i class="fa fa-check"></i><b>5.2.1</b> Variables quantitatives</a></li>
<li class="chapter" data-level="5.2.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-qualitatives"><i class="fa fa-check"></i><b>5.2.2</b> Variables qualitatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-probabilites"><i class="fa fa-check"></i><b>5.3</b> Les probabilit√©s</a></li>
<li class="chapter" data-level="5.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-distributions"><i class="fa fa-check"></i><b>5.4</b> Les distributions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-binomiale"><i class="fa fa-check"></i><b>5.4.1</b> Distribution binomiale</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-de-poisson"><i class="fa fa-check"></i><b>5.4.2</b> Distribution de Poisson</a></li>
<li class="chapter" data-level="5.4.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-uniforme"><i class="fa fa-check"></i><b>5.4.3</b> Distribution uniforme</a></li>
<li class="chapter" data-level="5.4.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-normale"><i class="fa fa-check"></i><b>5.4.4</b> Distribution normale</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#statistiques-descriptives"><i class="fa fa-check"></i><b>5.5</b> Statistiques descriptives</a></li>
<li class="chapter" data-level="5.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-dhypotheses-a-un-et-deux-echantillons"><i class="fa fa-check"></i><b>5.6</b> Tests d‚Äôhypoth√®ses √† un et deux √©chantillons</a><ul>
<li class="chapter" data-level="5.6.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-t-a-un-seul-echantillon"><i class="fa fa-check"></i><b>5.6.1</b> Test de t √† un seul √©chantillon</a></li>
<li class="chapter" data-level="5.6.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#attention-mauvaises-interpretations-des-p-values"><i class="fa fa-check"></i><b>5.6.2</b> Attention: mauvaises interpr√©tations des <em>p-values</em></a></li>
<li class="chapter" data-level="5.6.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-wilcoxon-a-un-seul-echantillon"><i class="fa fa-check"></i><b>5.6.3</b> Test de Wilcoxon √† un seul √©chantillon</a></li>
<li class="chapter" data-level="5.6.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-t-a-deux-echantillons"><i class="fa fa-check"></i><b>5.6.4</b> Tests de t √† deux √©chantillons</a></li>
<li class="chapter" data-level="5.6.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#comparaison-des-variances"><i class="fa fa-check"></i><b>5.6.5</b> Comparaison des variances</a></li>
<li class="chapter" data-level="5.6.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-wilcoxon-a-deux-echantillons"><i class="fa fa-check"></i><b>5.6.6</b> Tests de Wilcoxon √† deux √©chantillons</a></li>
<li class="chapter" data-level="5.6.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-tests-paires"><i class="fa fa-check"></i><b>5.6.7</b> Les tests pair√©s</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#lanalyse-de-variance"><i class="fa fa-check"></i><b>5.7</b> L‚Äôanalyse de variance</a></li>
<li class="chapter" data-level="5.8" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-modeles-statistiques"><i class="fa fa-check"></i><b>5.8</b> Les mod√®les statistiques</a><ul>
<li class="chapter" data-level="5.8.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modeles-a-effets-fixes"><i class="fa fa-check"></i><b>5.8.1</b> Mod√®les √† effets fixes</a></li>
<li class="chapter" data-level="5.8.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modeles-a-effets-mixtes"><i class="fa fa-check"></i><b>5.8.2</b> Mod√®les √† effets mixtes</a></li>
<li class="chapter" data-level="5.8.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#aller-plus-loin"><i class="fa fa-check"></i><b>5.8.3</b> Aller plus loin</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html"><i class="fa fa-check"></i><b>6</b> Introduction √† l‚Äôanalyse bay√©sienne en √©cologie</a><ul>
<li class="chapter" data-level="6.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#quest-ce-que-cest"><i class="fa fa-check"></i><b>6.1</b> Qu‚Äôest-ce que c‚Äôest?</a></li>
<li class="chapter" data-level="6.2" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pourquoi-lutiliser"><i class="fa fa-check"></i><b>6.2</b> Pourquoi l‚Äôutiliser?</a></li>
<li class="chapter" data-level="6.3" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#comment-lutiliser"><i class="fa fa-check"></i><b>6.3</b> Comment l‚Äôutiliser?</a></li>
<li class="chapter" data-level="6.4" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#faucons-pelerins"><i class="fa fa-check"></i><b>6.4</b> Faucons p√©lerins</a></li>
<li class="chapter" data-level="6.5" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#statistiques-dune-population"><i class="fa fa-check"></i><b>6.5</b> Statistiques d‚Äôune population</a><ul>
<li class="chapter" data-level="6.5.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#greta"><i class="fa fa-check"></i><b>6.5.1</b> greta</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#test-de-t-difference-entre-des-groupes"><i class="fa fa-check"></i><b>6.6</b> Test de t: Diff√©rence entre des groupes</a></li>
<li class="chapter" data-level="6.7" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pour-aller-plus-loin"><i class="fa fa-check"></i><b>6.7</b> Pour aller plus loin</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html"><i class="fa fa-check"></i><b>7</b> Explorer R</a><ul>
<li class="chapter" data-level="7.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-sur-le-web"><i class="fa fa-check"></i><b>7.1</b> R sur le web</a><ul>
<li class="chapter" data-level="7.1.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#github"><i class="fa fa-check"></i><b>7.1.1</b> GitHub</a></li>
<li class="chapter" data-level="7.1.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#twitter"><i class="fa fa-check"></i><b>7.1.2</b> Twitter</a></li>
<li class="chapter" data-level="7.1.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#nouvelles"><i class="fa fa-check"></i><b>7.1.3</b> Nouvelles</a></li>
<li class="chapter" data-level="7.1.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#des-questions"><i class="fa fa-check"></i><b>7.1.4</b> Des questions?</a></li>
<li class="chapter" data-level="7.1.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#participer"><i class="fa fa-check"></i><b>7.1.5</b> Participer</a></li>
<li class="chapter" data-level="7.1.6" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#mise-en-garde"><i class="fa fa-check"></i><b>7.1.6</b> Mise en garde</a></li>
<li class="chapter" data-level="7.1.7" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#prendre-tout-ca-en-note"><i class="fa fa-check"></i><b>7.1.7</b> Prendre tout √ßa en note</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-en-chaire-et-en-os"><i class="fa fa-check"></i><b>7.2</b> R en chaire et en os</a></li>
<li class="chapter" data-level="7.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#quelques-outils-en-ecologie-mathematique-avec-r"><i class="fa fa-check"></i><b>7.3</b> Quelques outils en √©cologie math√©matique avec R</a><ul>
<li class="chapter" data-level="7.3.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#pretraitement-des-donnees"><i class="fa fa-check"></i><b>7.3.1</b> Pr√©traitement des donn√©es</a></li>
<li class="chapter" data-level="7.3.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#acquerir-des-donnees-meteo"><i class="fa fa-check"></i><b>7.3.2</b> Acqu√©rir des donn√©es m√©t√©o</a></li>
<li class="chapter" data-level="7.3.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#pedometrie-avec-r"><i class="fa fa-check"></i><b>7.3.3</b> P√©dom√©trie avec R</a></li>
<li class="chapter" data-level="7.3.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#meta-analyses-en-r"><i class="fa fa-check"></i><b>7.3.4</b> M√©ta-analyses en R</a></li>
<li class="chapter" data-level="7.3.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#creer-des-applications-avec-r"><i class="fa fa-check"></i><b>7.3.5</b> Cr√©er des applications avec R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html"><i class="fa fa-check"></i><b>8</b> Association, partitionnement et ordination</a><ul>
<li class="chapter" data-level="8.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#espaces-danalyse"><i class="fa fa-check"></i><b>8.1</b> Espaces d‚Äôanalyse</a><ul>
<li class="chapter" data-level="8.1.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#abondance-et-occurence"><i class="fa fa-check"></i><b>8.1.1</b> Abondance et occurence</a></li>
<li class="chapter" data-level="8.1.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#environnement"><i class="fa fa-check"></i><b>8.1.2</b> Environnement</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#analyse-dassociation"><i class="fa fa-check"></i><b>8.2</b> Analyse d‚Äôassociation</a><ul>
<li class="chapter" data-level="8.2.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#association-entre-objets-mode-q"><i class="fa fa-check"></i><b>8.2.1</b> Association entre objets (mode Q)</a></li>
<li class="chapter" data-level="8.2.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#associations-entre-variables-mode-r"><i class="fa fa-check"></i><b>8.2.2</b> Associations entre variables (mode R)</a></li>
<li class="chapter" data-level="8.2.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-les-associations"><i class="fa fa-check"></i><b>8.2.3</b> Conclusion sur les associations</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement"><i class="fa fa-check"></i><b>8.3</b> Partitionnement</a><ul>
<li class="chapter" data-level="8.3.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#evaluation-dun-partitionnement"><i class="fa fa-check"></i><b>8.3.1</b> √âvaluation d‚Äôun partitionnement</a></li>
<li class="chapter" data-level="8.3.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-non-hierarchique"><i class="fa fa-check"></i><b>8.3.2</b> Partitionnement non hi√©rarchique</a></li>
<li class="chapter" data-level="8.3.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hierarchique"><i class="fa fa-check"></i><b>8.3.3</b> Partitionnement hi√©rarchique</a></li>
<li class="chapter" data-level="8.3.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hierarchique-basee-sur-la-densite-des-points"><i class="fa fa-check"></i><b>8.3.4</b> Partitionnement hi√©rarchique bas√©e sur la densit√© des points</a></li>
<li class="chapter" data-level="8.3.5" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-le-partitionnement"><i class="fa fa-check"></i><b>8.3.5</b> Conclusion sur le partitionnement</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination"><i class="fa fa-check"></i><b>8.4</b> Ordination</a><ul>
<li class="chapter" data-level="8.4.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-non-contraignante"><i class="fa fa-check"></i><b>8.4.1</b> Ordination non contraignante</a></li>
<li class="chapter" data-level="8.4.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-contraignante"><i class="fa fa-check"></i><b>8.4.2</b> Ordination contraignante</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html"><i class="fa fa-check"></i><b>9</b> D√©tection de valeurs aberrantes et imputation de donn√©es manquantes</a><ul>
<li class="chapter" data-level="9.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#donnees-manquantes-definition-origine-typologie-et-traitement"><i class="fa fa-check"></i><b>9.1</b> Donn√©es manquantes, d√©finition, origine, typologie et traitement</a><ul>
<li class="chapter" data-level="9.1.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#definition"><i class="fa fa-check"></i><b>9.1.1</b> D√©finition</a></li>
<li class="chapter" data-level="9.1.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#origines-des-donnees-manquantes"><i class="fa fa-check"></i><b>9.1.2</b> Origines des donn√©es manquantes</a></li>
<li class="chapter" data-level="9.1.3" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#profils-des-donnees-manquantes"><i class="fa fa-check"></i><b>9.1.3</b> Profils des donn√©es manquantes</a></li>
<li class="chapter" data-level="9.1.4" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#traitement-des-donnees-manquantes"><i class="fa fa-check"></i><b>9.1.4</b> Traitement des donn√©es manquantes</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#valeurs-et-echantillons-aberrants-definition-origines-methodes-de-detection-et-traitement"><i class="fa fa-check"></i><b>9.2</b> Valeurs et √©chantillons aberrants: d√©finition, origines, m√©thodes de d√©tection et traitement</a><ul>
<li class="chapter" data-level="9.2.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#definitions-1"><i class="fa fa-check"></i><b>9.2.1</b> D√©finitions</a></li>
<li class="chapter" data-level="9.2.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#origines"><i class="fa fa-check"></i><b>9.2.2</b> Origines</a></li>
<li class="chapter" data-level="9.2.3" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#detection-et-traitement-des-echantillons-aberrants-multivaries"><i class="fa fa-check"></i><b>9.2.3</b> D√©tection et traitement des √©chantillons aberrants multivari√©s</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapitre-temps.html"><a href="chapitre-temps.html"><i class="fa fa-check"></i><b>10</b> Les s√©ries temporelles</a><ul>
<li class="chapter" data-level="10.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#operations-sur-les-donnees-temporelles"><i class="fa fa-check"></i><b>10.1</b> Op√©rations sur les donn√©es temporelles</a></li>
<li class="chapter" data-level="10.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#analyse-de-series-temporelles"><i class="fa fa-check"></i><b>10.2</b> Analyse de s√©ries temporelles</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#creer-et-visualiser-des-series-temporelles"><i class="fa fa-check"></i><b>10.2.1</b> Cr√©er et visualiser des s√©ries temporelles</a></li>
<li class="chapter" data-level="10.2.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#structures-dans-les-series-temporelles"><i class="fa fa-check"></i><b>10.2.2</b> Structures dans les s√©ries temporelles</a></li>
<li class="chapter" data-level="10.2.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#lautocorrelation"><i class="fa fa-check"></i><b>10.2.3</b> L‚Äôautocorr√©lation</a></li>
<li class="chapter" data-level="10.2.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#signification-statistique-dune-serie-temporelle"><i class="fa fa-check"></i><b>10.2.4</b> Signification statistique d‚Äôune s√©rie temporelle</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#modelisation-de-series-temporelles"><i class="fa fa-check"></i><b>10.3</b> Mod√©lisation de s√©ries temporelles</a><ul>
<li class="chapter" data-level="10.3.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#methode-naive"><i class="fa fa-check"></i><b>10.3.1</b> M√©thode na√Øve</a></li>
<li class="chapter" data-level="10.3.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#methode-ses"><i class="fa fa-check"></i><b>10.3.2</b> M√©thode SES</a></li>
<li class="chapter" data-level="10.3.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#la-methode-arima"><i class="fa fa-check"></i><b>10.3.3</b> La m√©thode ARIMA</a></li>
<li class="chapter" data-level="10.3.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#les-modeles-dynamiques"><i class="fa fa-check"></i><b>10.3.4</b> Les mod√®les dynamiques</a></li>
<li class="chapter" data-level="10.3.5" data-path="chapitre-temps.html"><a href="chapitre-temps.html#les-modeles-tbats"><i class="fa fa-check"></i><b>10.3.5</b> Les mod√®les TBATS</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#pour-terminer"><i class="fa fa-check"></i><b>10.4</b> Pour terminer‚Ä¶</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chapitre-git.html"><a href="chapitre-git.html"><i class="fa fa-check"></i><b>11</b> Science ouverte et reproductibilit√©</a><ul>
<li class="chapter" data-level="11.1" data-path="chapitre-git.html"><a href="chapitre-git.html#un-code-reproductible"><i class="fa fa-check"></i><b>11.1</b> Un code reproductible</a><ul>
<li class="chapter" data-level="11.1.1" data-path="chapitre-git.html"><a href="chapitre-git.html#structure-dun-projet"><i class="fa fa-check"></i><b>11.1.1</b> Structure d‚Äôun projet</a></li>
<li class="chapter" data-level="11.1.2" data-path="chapitre-git.html"><a href="chapitre-git.html#le-format-r-markdown"><i class="fa fa-check"></i><b>11.1.2</b> Le format <span>R markdown</span></a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="chapitre-git.html"><a href="chapitre-git.html#introduction-a-github"><i class="fa fa-check"></i><b>11.2</b> Introduction √† GitHub</a></li>
<li class="chapter" data-level="11.3" data-path="chapitre-git.html"><a href="chapitre-git.html#introduction-a-pakrat"><i class="fa fa-check"></i><b>11.3</b> Introduction √† Pakrat üì¶üêÄ</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chapitre-ml.html"><a href="chapitre-ml.html"><i class="fa fa-check"></i><b>12</b> Autoapprentissage</a><ul>
<li class="chapter" data-level="12.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#objectifs"><i class="fa fa-check"></i><b>12.1</b> Objectifs</a></li>
<li class="chapter" data-level="12.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lexique"><i class="fa fa-check"></i><b>12.2</b> Lexique</a></li>
<li class="chapter" data-level="12.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#demarche"><i class="fa fa-check"></i><b>12.3</b> D√©marche</a><ul>
<li class="chapter" data-level="12.3.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#pretraitement"><i class="fa fa-check"></i><b>12.3.1</b> Pr√©traitement</a></li>
<li class="chapter" data-level="12.3.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#entrainement-et-test"><i class="fa fa-check"></i><b>12.3.2</b> Entra√Ænement et test</a></li>
<li class="chapter" data-level="12.3.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#sousapprentissage-et-surapprentissage"><i class="fa fa-check"></i><b>12.3.3</b> Sousapprentissage et surapprentissage</a></li>
<li class="chapter" data-level="12.3.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#validation-croisee"><i class="fa fa-check"></i><b>12.3.4</b> Validation crois√©e</a></li>
<li class="chapter" data-level="12.3.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#choix-de-lalgorithme-dapprentissage"><i class="fa fa-check"></i><b>12.3.5</b> Choix de l‚Äôalgorithme d‚Äôapprentissage</a></li>
<li class="chapter" data-level="12.3.6" data-path="chapitre-ml.html"><a href="chapitre-ml.html#deploiement"><i class="fa fa-check"></i><b>12.3.6</b> D√©ploiement</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#algorithmes"><i class="fa fa-check"></i><b>12.4</b> Algorithmes</a></li>
<li class="chapter" data-level="12.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lautoapprentissage-en-r"><i class="fa fa-check"></i><b>12.5</b> L‚Äôautoapprentissage en R</a></li>
<li class="chapter" data-level="12.6" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-k-plus-proches-voisins"><i class="fa fa-check"></i><b>12.6</b> Les <em>k</em> plus proches voisins</a><ul>
<li class="chapter" data-level="12.6.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#exemple-dapplication-1"><i class="fa fa-check"></i><b>12.6.1</b> Exemple d‚Äôapplication</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-arbres-decisionnels"><i class="fa fa-check"></i><b>12.7</b> Les arbres d√©cisionnels</a></li>
<li class="chapter" data-level="12.8" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-reseaux-neuronaux"><i class="fa fa-check"></i><b>12.8</b> Les r√©seaux neuronaux</a><ul>
<li class="chapter" data-level="12.8.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-reseaux-neuronaux-sur-r-avec-neuralnet"><i class="fa fa-check"></i><b>12.8.1</b> Les r√©seaux neuronaux sur R avec neuralnet</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens"><i class="fa fa-check"></i><b>12.9</b> Les processus gaussiens</a><ul>
<li class="chapter" data-level="12.9.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#un-approche-intuitive"><i class="fa fa-check"></i><b>12.9.1</b> Un approche intuitive</a></li>
<li class="chapter" data-level="12.9.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens-en-r"><i class="fa fa-check"></i><b>12.9.2</b> Les processus gaussiens en <code>R</code></a></li>
<li class="chapter" data-level="12.9.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#application-pratique"><i class="fa fa-check"></i><b>12.9.3</b> Application pratique</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapitre-geo.html"><a href="chapitre-geo.html"><i class="fa fa-check"></i><b>13</b> Les donn√©es spatiales</a></li>
<li class="chapter" data-level="14" data-path="chapitre-ode.html"><a href="chapitre-ode.html"><i class="fa fa-check"></i><b>14</b> Mod√©lisation d√©terministe</a><ul>
<li class="chapter" data-level="14.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#equations-differentielles"><i class="fa fa-check"></i><b>14.1</b> √âquations diff√©rentielles</a></li>
<li class="chapter" data-level="14.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#les-equations-differentielles-ordinaires-en-modelisation-ecologique"><i class="fa fa-check"></i><b>14.2</b> Les √©quations diff√©rentielles ordinaires en mod√©lisation √©cologique</a><ul>
<li class="chapter" data-level="14.2.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#evolution-dune-seule-population-en-fonction-du-temps"><i class="fa fa-check"></i><b>14.2.1</b> √âvolution d‚Äôune seule population en fonction du temps</a></li>
<li class="chapter" data-level="14.2.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#population-exploitee"><i class="fa fa-check"></i><b>14.2.2</b> Population exploit√©e</a></li>
<li class="chapter" data-level="14.2.3" data-path="chapitre-ode.html"><a href="chapitre-ode.html#interactions-biologiques"><i class="fa fa-check"></i><b>14.2.3</b> Interactions biologiques</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="chapitre-ode.html"><a href="chapitre-ode.html#les-equations-differentielles-partielles-en-modelisation-ecologique"><i class="fa fa-check"></i><b>14.3</b> Les √©quations diff√©rentielles partielles en mod√©lisation √©cologique</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse et mod√©lisation d‚Äôagro√©cosyst√®mes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapitre-ml" class="section level1">
<h1><span class="header-section-number">12</span> Autoapprentissage</h1>
<hr />
<p>Ô∏è¬†<strong>Objectifs sp√©cifiques</strong>:</p>
<p>√Ä la fin de ce chapitre, vous</p>
<ul>
<li>saurez √©tablir un plan de mod√©lisation par autoapprentissage</li>
<li>saurez d√©finir le sous-apprentissage et le surapprentissage</li>
<li>serez en mesure d‚Äôeffectuer un autoapprentissage avec les techniques des <em>k</em>-proches voisins, les arbres de d√©cision, les for√™ts al√©atoires, les r√©seaux neuronnaux et les processus gaussiens</li>
</ul>
<hr />
<p>Plusieurs cas d‚Äôesp√®ces en sciences et g√©nies peuvent √™tre approch√©s en liant un variable avec une ou plusieurs autres √† l‚Äôaide de r√©gressions lin√©aires, polynomiales, sinuso√Ødales, exponentielle, sigmo√Ødales, <a href="https://dl.sciencesocieties.org/publications/aj/pdfs/107/2/786">etc</a>. Encore faut-il s‚Äôassurer que ces formes pr√©√©tablies repr√©sentent le ph√©nom√®ne de mani√®re fiable.</p>
<p>Lorsque la forme de la r√©ponse est difficile √† envisager, en particulier dans des cas non-lin√©aires ou impliquant plusieurs variables, on pourra faire appel √† des mod√®les dont la structure n‚Äôest pas contr√¥l√©e par une √©quation rigide gouvern√©e par des param√®tres (comme la pente ou l‚Äôintercept).</p>
<p>L‚Äô<strong>autoapprentissage</strong>, apprentissage automatique, ou <em>machine learning</em>, vise √† d√©tecter des structures complexes √©mergeant d‚Äôensembles de donn√©es √† l‚Äôaide des math√©matiques et de processus automatis√©s afin de pr√©dire l‚Äô√©mergence de futures occurrences. Comme ensemble de techniques empiriques, l‚Äôautoapprentissage est un cas particulier de l‚Äô<strong>intelligence artificielle</strong>, qui elle inclut aussi les m√©canismes d√©terministes et des ensembles d‚Äôop√©rations logiques. Par exemple, les premiers ordinateurs √† comp√©titionner aux √©checs se basaient sur des r√®gles de logique (si la reine noire est positionn√©e en c3 et qu‚Äôun le fou blanc est en position f6 et que ‚Ä¶ alors bouge la tour en g5 - j‚Äô√©cris n‚Äôimporte quoi). Il s‚Äôagissait d‚Äôintelligence artificielle, mais pas d‚Äôautoapprentissage. L‚Äôautoapprentissage passera davantage par la simulation de nombreuses parties et d√©gagera la structure optimale pour l‚Äôemporter consid√©rant les positions des pi√®ces sur l‚Äô√©chiquier.</p>
<div id="objectifs" class="section level2">
<h2><span class="header-section-number">12.1</span> Objectifs</h2>
<ul>
<li>Comprendre les applications possibles de l‚Äôautoapprentissage</li>
<li>Comprendre le flux de travail d‚Äôune op√©ration d‚Äôautoapprentissage</li>
<li>Comprendre les principes soutenant les techniques des <em>k</em> plus proches voisins, des arbres d√©cisionnels, des r√©seaux neuronaux et des processus gaussiens.</li>
</ul>
<p>Plus sp√©cifiquement, vous devrez √† la fin de cette section √™tre en mesure de pr√©dire une variable cat√©gorie ou num√©rique √† partir de donn√©es observ√©es.</p>
</div>
<div id="lexique" class="section level2">
<h2><span class="header-section-number">12.2</span> Lexique</h2>
<p>L‚Äôautoapprentissage poss√®de son jargon particulier. Puisque certains termes peuvent porter √† confusion, voici quelques d√©finitions de termes que j‚Äôutiliserai dans ce chapitre.</p>
<ul>
<li><strong>R√©ponse</strong>. La variable que l‚Äôon cherche √† obtenir. Il peut s‚Äôagir d‚Äôune variable continue comme d‚Äôune variable cat√©gorielle. On la nomme aussi la <em>cible</em>.</li>
<li><strong>Pr√©dicteur</strong>. Une variable utilis√©e pour pr√©dire une r√©ponse. Les pr√©dicteurs sont des variables continues. Les pr√©dicteurs de type cat√©goriel doivent pr√©alablement √™tre dummifi√©s (voir chapitre 5). On nomme les pr√©dicteurs les <em>entr√©es</em>.</li>
<li><strong>Apprentissage supervis√©</strong> et <strong>non-supervis√©</strong>. Si vous avez suivi le cours jusqu‚Äôici, vous avez d√©j√† utilis√© des outils entrant dans la grande famille de l‚Äôapprentissage automatique. La r√©gression lin√©aire, par exemple, vise √† minimiser l‚Äôerreur sur la r√©ponse en optimisant les coefficients de pente et l‚Äôintercept. Un apprentissage supervis√© a une cible, comme c‚Äôest le cas de la r√©gression lin√©aire. En revanche, un apprentissage non supervis√© n‚Äôen a pas: on laisse l‚Äôalgorithme le soin de d√©tecter des structures int√©ressantes. Nous avons d√©j√† utilis√© cette approche. Pensez-y un peu‚Ä¶ l‚Äôanalyse en composante principale ou en coordonn√©es principales, ainsi que le partitionnement hi√©rarchique ou non sont des exemples d‚Äôapprentissage non supervis√©. En revanche, l‚Äôanalyse de redondance a une r√©ponse. L‚Äôanalyse discriminante aussi, bien que sa r√©ponse soit cat√©gorielle. L‚Äôapprentissage non supervis√© ayant d√©j√† √©t√© couvert au chapitre 7, ce chapitre ne s‚Äôint√©resse qu‚Äô√† l‚Äôapprentissage supervis√©.</li>
<li><strong>R√©gression</strong> et <strong>Classification</strong>. Alors que la r√©gression est un type d‚Äôapprentissage automatique pour les r√©ponses continues, la classification vise √† pr√©dire une r√©ponse cat√©gorielle. Il existe des algorithmes uniquement application √† la r√©gression, uniquement applicables √† la classification, et plusieurs autres adaptable aux deux situations.</li>
<li><strong>Donn√©es d‚Äôentra√Ænement</strong> et <strong>donn√©es de test</strong>. Lorsque l‚Äôon g√©n√®re un mod√®le, on d√©sire qu‚Äôil sache comment r√©agir √† ses pr√©dicteurs. Cela se fait avec des donn√©es d‚Äôentra√Ænement, sur lesquelles on <strong>calibre</strong> et <strong>valide</strong> le mod√®le. Les donn√©es de test servent √† v√©rifier si le mod√®le est en mesure de pr√©dire des r√©ponses sur lesquelles il n‚Äôa pas √©t√© entra√Æn√©.</li>
<li><strong>Fonction de perte</strong>. Une fonction qui mesure l‚Äôerreur d‚Äôun mod√®le.</li>
</ul>
</div>
<div id="demarche" class="section level2">
<h2><span class="header-section-number">12.3</span> D√©marche</h2>
<p>La premi√®re t√¢che est d‚Äôexplorer les donn√©es, ce que nous avons couvert au chapitres 3 et 4.</p>
<div id="pretraitement" class="section level3">
<h3><span class="header-section-number">12.3.1</span> Pr√©traitement</h3>
<p>Pour la plupart des techniques d‚Äôautoapprentissage, le choix de l‚Äô√©chelle de mesure est d√©terminant sur la mod√©lisation subs√©quente. Par exemple, un algorithme bas√© sur la distance comme les <em>k</em> plus proches voisins ne mesurera pas les m√™mes distances entre deux observations si l‚Äôon change l‚Äôunit√© de mesure d‚Äôune variable du m√®tre au kilom√®tre. Il est donc important d‚Äôeffectuer, ou d‚Äôenvisager la possibilit√© d‚Äôeffectuer un pr√©traitement sur les donn√©es. Je vous r√©f√®re au chapitre 6 (en d√©veloppement) pour plus de d√©tails sur le pr√©traitement.</p>
</div>
<div id="entrainement-et-test" class="section level3">
<h3><span class="header-section-number">12.3.2</span> Entra√Ænement et test</h3>
<p>Vous connaissez peut-√™tre l‚Äôexpression sportive ‚Äúavoir l‚Äôavantage du terrain‚Äù. Il s‚Äôagit d‚Äôun principe pr√©tendant que les athl√®tes performent mieux en terrain connu. Idem pour les mod√®les ph√©nom√©nologiques. Il est possible qu‚Äôun mod√®le fonctionne tr√®s bien sur les donn√©es avec lesquelles il a √©t√© entra√Æn√©, mais tr√®s mal sur des donn√©es externes. De mauvaises pr√©dictions effectu√©es √† partir d‚Äôun mod√®le qui semblait bien se comporter peut mener √† des d√©cisions qui, pourtant prises de mani√®re confiante, se r√©v√®lent fallacieuses au point d‚Äôaboutir √† de graves cons√©quences. C‚Äôest pourquoi, <strong>en mode pr√©dictif, on doit √©valuer la pr√©cision et la justesse d‚Äôun mod√®le sur des donn√©es qui n‚Äôont pas √©t√© utilis√©s dans son entra√Ænement</strong>.</p>
<p>En pratique, il convient de s√©parer un tableau de donn√©es en deux: un tableau d‚Äôentra√Ænement et un tableau de test. Il n‚Äôexiste pas de standards sur le ratio √† utiliser. Cela d√©pend de la prudence de l‚Äôanalyse et de l‚Äôampleur de son tableau de donn√©es. Certaines personnes pr√©f√©rerons couper le tableau √† 50%. D‚Äôautres pr√©f√©rerons r√©server le deux-tiers des donn√©es pour l‚Äôentra√Ænement, ou 70%, 75%. Rarement, r√©servera-t-on moins plus de 50% et moins de 20% √† la phase de test.</p>
<p>Si les donn√©es sont peu √©quilibr√©es (par exemple, on retrouve peu de donn√©es de l‚Äôesp√®ce <span class="math inline">\(A\)</span>, que l‚Äôon retrouve peu de donn√©es √† un pH inf√©rieur √† 5 ou que l‚Äôon a peu de donn√©es crois√©es de l‚Äôesp√®ce <span class="math inline">\(A\)</span> √† ph inf√©rieur √† 5), il y a un danger qu‚Äôune trop grande part, voire toute les donn√©es, se retrouvent dans le tableau d‚Äôentra√Ænement (certaines situations ne seront ainsi pas test√©es) ou dans le tableau de test (certaines situations ne seront pas couvertes par le mod√®le). L‚Äôanalyste doit s‚Äôassurer de s√©parer le tableau au hasard, mais de mani√®re consciencieuse.</p>
</div>
<div id="sousapprentissage-et-surapprentissage" class="section level3">
<h3><span class="header-section-number">12.3.3</span> Sousapprentissage et surapprentissage</h3>
<p>Une difficult√© en mod√©lisation ph√©nom√©nologique est ce qui tient de la structure et ce qui tient du bruit. Lorsque l‚Äôon consid√®re une structure comme du bruit, on est dans un cas de sousapprentissage. Lorsque, au contraire, on interpr√®te du bruit comme une structure, on est en cas de surapprentissage. Les graphiques suivant pr√©sentent ces deux cas, avec au centre un cas d‚Äôapprentissage conforme.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">35473</span>)
n &lt;-<span class="st"> </span><span class="dv">50</span>
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">20</span>, <span class="dt">length =</span> n) 
y &lt;-<span class="st"> </span><span class="dv">500</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.4</span> <span class="op">*</span><span class="st"> </span>(x<span class="dv">-10</span>)<span class="op">^</span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">mean=</span><span class="dv">10</span>, <span class="dt">sd=</span><span class="dv">80</span>) <span class="co"># le bruit est g√©n√©r√© par rnorm()</span>

<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
<span class="kw">plot</span>(x, y, <span class="dt">main =</span> <span class="st">&quot;Sousapprentissage&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;#46c19a&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>)
<span class="kw">lines</span>(x, <span class="kw">predict</span>(<span class="kw">lm</span>(y<span class="op">~</span>x)), <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>)

<span class="kw">plot</span>(x, y, <span class="dt">main =</span> <span class="st">&quot;Apprentissage conforme&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;#46c19a&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>)
<span class="kw">lines</span>(x, 
      <span class="kw">predict</span>(<span class="kw">lm</span>(y<span class="op">~</span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">3</span>))),
      <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>)

<span class="kw">plot</span>(x, y, <span class="dt">main =</span> <span class="st">&quot;Surapprentissage&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;#46c19a&quot;</span>, <span class="dt">pch=</span><span class="dv">16</span>)
<span class="kw">lines</span>(x, 
      <span class="kw">predict</span>(<span class="kw">lm</span>(y<span class="op">~</span>x <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">                   </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">6</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">7</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">8</span>) <span class="op">+</span>
<span class="st">                   </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">9</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">10</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">11</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">12</span>) <span class="op">+</span>
<span class="st">                   </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">13</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">14</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">15</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(x<span class="op">^</span><span class="dv">16</span>))),
      <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-398-1.png" width="672" /></p>
<p>Afin d‚Äô√©viter les cas de <em>m√©sapprentissage</em> on peut avoir recours √† la validation crois√©e.</p>
</div>
<div id="validation-croisee" class="section level3">
<h3><span class="header-section-number">12.3.4</span> Validation crois√©e</h3>
<p>Souvent confondue avec le fait de s√©parer le tableau en phases d‚Äôentra√Ænement et de test, la validation crois√©e est un principe incluant plusieurs algorithmes qui consiste √† entra√Æner le mod√®le sur un √©chantillonnage al√©atoire des donn√©es d‚Äôentra√Ænement.</p>
<p>La technique la plus utilis√©e est le <em>k-fold</em>, o√π l‚Äôon s√©pare al√©atoirement le tableau d‚Äôentra√Ænement en un nombre <em>k</em> de tableaux. √Ä chaque √©tape de la validation crois√©e, on calibre le mod√®le sur tous les tableaux sauf un, puis on valide le mod√®le sur le tableau exclu. La performance du mod√®le en entra√Ænement est jug√©e sur les validations.</p>
</div>
<div id="choix-de-lalgorithme-dapprentissage" class="section level3">
<h3><span class="header-section-number">12.3.5</span> Choix de l‚Äôalgorithme d‚Äôapprentissage</h3>
<p>Face aux centaines d‚Äôalgorithmes d‚Äôapprentissages qui vous sont offertes, choisir l‚Äôalgorithme ou les algorithmes ad√©quats pour vos donn√©es n‚Äôest pas facile. Ce choix sera motiv√© par les tenants et aboutissants des algorithmes, votre exp√©rience, l‚Äôexp√©rience de la litt√©rature, l‚Äôexp√©rience de vos coll√®gues. Une approche raisonnable est de tester plusieurs mod√®les et d‚Äôapprofondir si ce n‚Äôest d√©j√† fait la math√©matique des options retenues. Il existe des algorithmes g√©n√©tiques, qui ne sont pas couverts ici, permettent de s√©lectionner des mod√®les d‚Äôautoapprentissages optimaux. Un de ces algorithmes est offert par le module Python <a href="https://epistasislab.github.io/tpot/"><code>tpot</code></a>.</p>
</div>
<div id="deploiement" class="section level3">
<h3><span class="header-section-number">12.3.6</span> D√©ploiement</h3>
<p>RData, Shiny</p>
<hr />
<p>En r√©sum√©,</p>
<ol style="list-style-type: decimal">
<li>Explorer les donn√©es</li>
<li>S√©lectionner des algorithmes</li>
<li>Effectuer un pr√©traitement</li>
<li>Cr√©er un ensemble d‚Äôentra√Ænement et un ensemble de test</li>
<li>Lisser les donn√©es sur les donn√©es d‚Äôentra√Ænement avec validation crois√©e</li>
<li>Tester le mod√®le</li>
<li>D√©ployer le mod√®le</li>
</ol>
</div>
</div>
<div id="algorithmes" class="section level2">
<h2><span class="header-section-number">12.4</span> Algorithmes</h2>
<p>Il existe des centaines d‚Äôalgorithmes d‚Äôapprentissage. Je n‚Äôen couvrirai que quatre, qui me semblent √™tre appropri√©s pour la mod√©lisation ph√©nom√©nologique des syst√®mes vivants, et utilisables pour la r√©gression et la classification.</p>
<ul>
<li>Les k plus proches voisins</li>
<li>Les arbres de d√©cision</li>
<li>Les r√©seaux neuronaux</li>
<li>Les processus gaussiens</li>
</ul>
</div>
<div id="lautoapprentissage-en-r" class="section level2">
<h2><span class="header-section-number">12.5</span> L‚Äôautoapprentissage en R</h2>
<p>Plusieurs options sont disponibles.</p>
<ol style="list-style-type: decimal">
<li>Les modules que l‚Äôon retrouve en R pour l‚Äôautoapprentissage sont nombreux, et parfois sp√©cialis√©s. Il est possible de les utiliser individuellement.</li>
<li>Chacun de ces modules fonctionne √† sa fa√ßon. Le module <code>caret</code> de R a √©t√© con√ßu pour donner acc√®s √† des centaines de fonctions d‚Äôautoapprentissage via une interface commune.</li>
<li>Le module <code>mlr</code> occupe sensiblement le m√™me cr√©neau que <code>caret</code>, mais utilise plut√¥t une approche par objets connect√©s. Au moment d‚Äô√©crire ces lignes, <code>mlr</code> est peu document√©, donc <em>a priori</em> plus complexe √† prendre en main.</li>
<li>En Python, le module <code>scikit-learn</code> offre un interface unique pour l‚Äôutilisation de nombreuses techniques d‚Äôautoapprentissage. Il est possible d‚Äôappeler des fonctions de Python √† partir de R gr√¢ce au module <code>reticulate</code>.</li>
</ol>
<p>Dans ce chapitre, nous verrons comment fonctionnent certains algorithmes s√©lectionn√©s, puis nous les appliquerons avec le module respectif qui m‚Äôa sembl√© le plus appropri√©. Vous remarquerez n√©anmoins des r√©f√©rences r√©currentes aux modules de Python. En ce moment, la force de R r√©side dans la gestion des tableaux, les tests statistiques, l‚Äôexploration heuristique et la visualisation de donn√©es. N√©anmoins, Python le surpasse pour l‚Äôautoapprentissage‚Ä¶</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>) <span class="co"># √©videmment</span>
<span class="kw">library</span>(<span class="st">&quot;caret&quot;</span>)</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:compositions&#39;:
## 
##     R2</code></pre>
<pre><code>## The following object is masked from &#39;package:pls&#39;:
## 
##     R2</code></pre>
<pre><code>## The following object is masked from &#39;package:vegan&#39;:
## 
##     tolerance</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
</div>
<div id="les-k-plus-proches-voisins" class="section level2">
<h2><span class="header-section-number">12.6</span> Les <em>k</em> plus proches voisins</h2>
<blockquote>
<p><a href="https://youtu.be/-RpYi_Vuviw?t=6m40s"><img src="images/11_les-voisins.jpg" alt="Les voisins, une pi√®ce de Claude Meunier here" /></a></p>
</blockquote>
<blockquote>
<p>‚ÄúLe‚Ä¶ l‚Äôid√©e en arri√®re pour √™tre‚Ä¶ euh‚Ä¶ simpliste, l√† c‚Äôest que c‚Äôest un peu de‚Ä¶ euhmm‚Ä¶ de la vitamine de vinyle.‚Äù - Georges (Les voisins, une pi√®ce de Claude Meunier)</p>
</blockquote>
<p>Pour dire comme Georges, le‚Ä¶ l‚Äôid√©e en arri√®re des KNN pour √™tre‚Ä¶ euh‚Ä¶ <em>simpliste</em>, c‚Äôest qu‚Äôun objet va ressembler √† ce qui se trouve dans son voisinage. Les KNN se basent en effet sur une m√©trique de distance pour rechercher un nombre <em>k</em> de points situ√©s √† proximit√© de la mesure. Les <em>k</em> points les plus proches sont retenus, <em>k</em> √©tant un entier non nul √† optimiser. Un autre param√®tre parfois utilis√© est la distance maximale des voisins √† consid√©rer: un voisin trop √©loign√© pourra √™tre discart√©. La r√©ponse attribu√©e √† la mesure est calcul√©e √† partir de la r√©ponse des <em>k</em> voisins retenus. Dans le cas d‚Äôune r√©gression, on utiliser g√©n√©ralement la moyenne. Dans le cas de la classification, la mesure prendra la cat√©gorie qui sera la plus pr√©sente chez les <em>k</em> plus proches voisins.</p>
<p>L‚Äôalgorithme des <em>k</em> plus proches voisins est relativement simple √† comprendre. Certains pi√®ges sont, de m√™me, peuvent √™tre contourn√©s facilement. Imaginez que vous rechercher les points les plus rapproch√©s dans un syst√®me de coordonn√©es g√©ographiques o√π les coordonn√©es <span class="math inline">\(x\)</span> sont exprim√©es en m√®tres et les coordonn√©es <span class="math inline">\(y\)</span>, en centim√®tres. Vous y projetez trois points.</p>
<pre class="sourceCode r"><code class="sourceCode r">data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">X =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>),
                   <span class="dt">Y =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>),
                   <span class="dt">row.names =</span> <span class="kw">c</span>(<span class="st">&#39;A&#39;</span>, <span class="st">&#39;B&#39;</span>, <span class="st">&#39;C&#39;</span>))
<span class="kw">options</span>(<span class="dt">repr.plot.width =</span> <span class="dv">4</span>, <span class="dt">repr.plot.height =</span> <span class="dv">4</span>)
<span class="kw">par</span>(<span class="dt">pty=</span><span class="st">&quot;s&quot;</span>)
<span class="kw">plot</span>(data, <span class="dt">cex=</span><span class="dv">3</span>,
     <span class="dt">xlab =</span> <span class="st">&#39;Position X (m)&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;Position Y (cm)&#39;</span>)
<span class="kw">text</span>(data, <span class="dt">labels =</span> <span class="kw">rownames</span>(data))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-400-1.png" width="672" /></p>
<p>Techniquement la distance A-B est 100 plus √©lev√©e que la distance A-C, mais l‚Äôalgorithme ne se soucie pas de la m√©trique que vous utilisez. Il est primordial dans ce cas d‚Äôutiliser la m√™me m√©trique. Cette strat√©gie est √©vidente lorsque les variables sont comparables. C‚Äôest rarement le cas, que ce soit lorsque l‚Äôon compare des dimensions physionomiques (la longueur d‚Äôune phalange ou celle d‚Äôun f√©mur) mais lorsque les variables incluent des m√©langes de longueurs, des pH, des d√©comptes, etc., il est important de bien identifier la m√©trique et le type de distance qu‚Äôil convient le mieux d‚Äôutiliser. En outre, la standardisation des donn√©es √† une moyenne de z√©ro et √† un √©cart-type de 1 est une approche courrament utilis√©e.</p>
<div id="exemple-dapplication-1" class="section level3">
<h3><span class="header-section-number">12.6.1</span> Exemple d‚Äôapplication</h3>
<p>Pour ce premier exemple, je pr√©senterai un cheminement d‚Äôautoapprentissage, du pr√©traitement au test.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># ionome</span></code></pre>
</div>
</div>
<div id="les-arbres-decisionnels" class="section level2">
<h2><span class="header-section-number">12.7</span> Les arbres d√©cisionnels</h2>
<div class="figure">
<img src="images/11_Entmoot.jpg" alt="Les Ents, tir√© du film le Seigneur des anneaux" />
<p class="caption">Les Ents, tir√© du film le Seigneur des anneaux</p>
</div>
<p>Un arbre d√©cisionnel est une collection hi√©rarchis√©e de d√©cisions, le plus souvent binaires. Chaque embranchement est un test √† vrai ou faux sur une variable. La r√©ponse, que ce soit une cat√©gorie ou une valeur num√©rique, se trouve au bout de la derni√®re branche. Les suites de d√©cisions sont organis√©es de mani√®re √† ce que la pr√©cision de la r√©ponse soit optimis√©e.</p>
<p>Par exemple, ‚Ä¶</p>
</div>
<div id="les-reseaux-neuronaux" class="section level2">
<h2><span class="header-section-number">12.8</span> Les r√©seaux neuronaux</h2>
<p>Apr√®s les KNN et les random forests, nous passons au domaine plus complexe des r√©seaux neuronaux. Le terme <em>r√©seau neuronal</em> est une m√©taphore li√©e √† une perception que l‚Äôon avait du fonctionnement du cerveau humain lorsque la technique des r√©seaux neuronaux a √©t√© d√©velopp√©e dans les ann√©es 1950. Un r√©seau neuronal comprend une s√©rie de bo√Ætes d‚Äôentr√©es li√©e √† des fonctions qui transforment et acheminent successivement l‚Äôinformation jusqu‚Äô√† la sortie d‚Äôune ou plusieurs r√©ponse. Il existe plusieurs formes de r√©seaux neuronnaux, dont la plus simple manifestation est le <em>perceptron multicouche</em>. Dans l‚Äôexemple suivant, on retrouve 4 variables d‚Äôentr√©e et trois variables de sortie entre lesquelles on retrouve 5 couches dont le nombre de neurones varient entre 3 et 6.</p>
<p><img src="images/11_deep_neural_network.png" /></p>
<p>Source: <a href="https://www.neuraldesigner.com/">Neural designer</a></p>
<p>Entre la premi√®re couche de neurones (les variables pr√©dictives) et la derni√®re couche (les variables r√©ponse), on retrouve des <em>couches cach√©es</em>. Chaque neurone est reli√© √† tous les neurones de la couche suivante.</p>
<p>Les liens sont des poids, qui peuvent prendre des valeurs dans l‚Äôensemble des nombres r√©els. √Ä chaque neurone suivant la premi√®re couche, on fait la somme des poids multipli√©s par la sortie du neurone. Le nombre obtenu entre dans chaque neurone de la couche. Le neurone est une fonction, souvent tr√®s simple, qui transforme le nombre. La fonction plus utilis√©e est probablement la fonction ReLU, pour <em>rectified linear unit</em>, qui expulse le m√™me nombre aux neurones de la prochaine couche s‚Äôil est positif: sinon, il expulse un z√©ro.</p>
<p><strong>Exercice</strong>. Si tous les neurones sont des fonctions ReLU, calculez la sortie de ce petit r√©seau neuronal.</p>
<p><img src="images/11_nn_ex1_Q.jpg" width="600px"></p>
<p>Vous trouverez la r√©ponse sur l‚Äôimage <code>images/11_nn_ex1_R.jpg</code>.</p>
<p>Il est aussi possible d‚Äôajouter un <em>biais</em> √† chaque neurone, qui est un nombre r√©el additionn√© √† la somme des neurones pond√©r√©e par les poids.</p>
<p>L‚Äôoptimisation les poids pour chaque lien et les biais pour chaque neurone (gr√¢ce √† des algorithmes dont le fonctionnement sort du cadre de ce cours) constitue le processus d‚Äôapprentissage. Avec l‚Äôaide de logiciels et de modules sp√©cialis√©s, la construction de r√©seaux de centaines de neurones organis√©s en centaines de couches vous permettra de capter des patrons complexes dans des ensembles de donn√©es.</p>
<p>Vous avez peut-√™tre d√©j√† entendu parler d‚Äôapprentissage profond (ou <em>deep learning</em>). Il s‚Äôagit simplement d‚Äôune appellation des r√©seaux neuronaux modernis√© pour insister sur la pr√©sence de plusieurs couches de neurones. C‚Äôest un terme √† la mode.</p>
<div id="les-reseaux-neuronaux-sur-r-avec-neuralnet" class="section level3">
<h3><span class="header-section-number">12.8.1</span> Les r√©seaux neuronaux sur R avec neuralnet</h3>
<p>Plusieurs modules sont disponibles sur R pour l‚Äôapprentissage profond. Certains utilisent le module <a href="https://github.com/h2oai/h2o-3">H2O.ia</a>, propuls√© en Java, d‚Äôautres utilisent plut√¥t <a href="https://keras.rstudio.com/">Keras</a>, propuls√© en Python par l‚Äôinterm√©diaire de tensorflow. J‚Äôai une pr√©f√©rence pour Keras, puisqu‚Äôil supporte les r√©seaux neuronaux classiques (perceptrons multicouche) autant que convolutifs ou r√©currents. Keras pourrait n√©anmoins √™tre difficile √† installer sur Windows, o√π Python ne vient pas par d√©faut. Sur Windows, Keras ne fonctionne qu‚Äôavec Anaconda: vous devez donc installez <a href="https://www.anaconda.com/download/#windows">Anaconda ou Miniconda</a> (Miniconda offre une installation minimaliste).</p>
<p>Mais pour ce cours, nous utiliserons le module neuralnet. Il est possible de l‚Äôutilser gr√¢ce √† l‚Äôinterface de caret, mais son utilisation directe permet davantage de flexibilit√©. Chargeons les donn√©es.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;neuralnet&quot;</span>)</code></pre>
<pre><code>## 
## Attaching package: &#39;neuralnet&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     compute</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>)</code></pre>
<p>Prenons soin de segmenter nos donn√©es en entra√Ænement et en test.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">8453668</span>)
iris_tr_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y=</span>iris<span class="op">$</span>Species, <span class="dt">p =</span> <span class="fl">0.75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</code></pre>
<p>Nous pouvons ainsi cr√©er nos tableaux d‚Äôentra√Ænement et de test pour les variables pr√©dictives.</p>
<p>Les r√©seaux neuronnaux sont aptes √† g√©n√©rer des sorties multiples. Nous d√©sirons pr√©dire une cat√©gorie, et neuralnet ne s‚Äôoccupe pas de les transformer de facto. Lors de la pr√©diction d‚Äôune cat√©gorie, nous devons g√©n√©r√©e des sorties multiples qui permettront de d√©cider de l‚Äôappartenance exclusive √† une cat√©gorie ou une autre. Nous avons abord√© l‚Äôencodage cat√©goriel aux chapitres <a href="chapitre-biostats.html#chapitre-biostats">5</a> et <a href="chapitre-explorer.html#chapitre-explorer">7</a>. C‚Äôest ce que nous ferons ici.</p>
<pre class="sourceCode r"><code class="sourceCode r">species_oh &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Species, iris)
<span class="kw">colnames</span>(species_oh) &lt;-<span class="st"> </span><span class="kw">levels</span>(iris<span class="op">$</span>Species)
iris_oh &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cbind</span>(species_oh)</code></pre>
<p>Lan√ßons le r√©seau neuronnal avec l‚Äôinterface-formule de R (neuralnet n‚Äôaccepte pas le <code>.</code> pour indiquer <em>prend toutes les variables √† l‚Äôexeption de celles utilis√©es en y</em>): il faut les lsiter. L‚Äôargument <code>hidden</code> est un vecteur qui indique le nombre de neuronnes pour chaque couche. L‚Äôargument <code>linear.input</code> indique si l‚Äôon d√©sire travailler en r√©gression (<code>linear.output = TRUE</code>) ou en classification (<code>linear.output = FALSE</code>). Lorsque les donn√©es sont nombreuses, patience, le calcul prend pas mal de temps. Dans ce cas-ci, nous avons un tout petit tableau.</p>
<pre class="sourceCode r"><code class="sourceCode r">nn &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(setosa <span class="op">+</span><span class="st"> </span>versicolor <span class="op">+</span><span class="st"> </span>virginica <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width <span class="op">+</span><span class="st"> </span>Petal.Length <span class="op">+</span><span class="st"> </span>Petal.Width,
                <span class="dt">data =</span> iris_oh <span class="op">%&gt;%</span><span class="st"> </span>dplyr<span class="op">::</span><span class="kw">slice</span>(iris_tr_index), 
                <span class="dt">hidden =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">5</span>),
                <span class="dt">linear.output =</span> <span class="ot">FALSE</span>)</code></pre>
<p>Un r√©seau neuronnal peu complexe peut √™tre lisible.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(nn)</code></pre>
<p>Il n‚Äôexiste pas de r√®gle stricte sur le nombre de couche et le nombre de noeud par couche. Il est n√©anmoins conseill√© de g√©n√©rer d‚Äôabord un mod√®le simple, puis au besoin de le complexifier graduellement en terme de nombre de noeuds, puis de nombre de couches. Si vous d√©sirez aller plus loin et utiliser keras, le module <a href="https://autokeras.com/"><code>autokeras</code></a>, disponible seulement en Python, est con√ßu pour optimiser un mod√®le Keras.</p>
<pre class="sourceCode r"><code class="sourceCode r">compute_te &lt;-<span class="st"> </span><span class="kw">compute</span>(nn,
                      iris_oh <span class="op">%&gt;%</span>
<span class="st">                        </span><span class="kw">select</span>(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) <span class="op">%&gt;%</span>
<span class="st">                        </span>dplyr<span class="op">::</span><span class="kw">slice</span>(<span class="op">-</span>iris_tr_index))
pred_te &lt;-<span class="st"> </span>compute_te<span class="op">$</span>net.result <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">apply</span>(., <span class="dv">1</span>, which.max) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">levels</span>(iris<span class="op">$</span>Species)[.]</code></pre>
<pre><code>## Warning: `as_tibble.matrix()` requires a matrix with column names or a `.name_repair` argument. Using compatibility `.name_repair`.
## This warning is displayed once per session.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confusionMatrix</span>(iris_oh <span class="op">%&gt;%</span>
<span class="st">                  </span>dplyr<span class="op">::</span><span class="kw">slice</span>(<span class="op">-</span>iris_tr_index) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                  </span><span class="kw">select</span>(Species) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                  </span><span class="kw">pull</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                  </span><span class="kw">as.factor</span>(),
                pred_te <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.factor</span>())</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         12          0         0
##   versicolor      2         10         0
##   virginica       0          0        12
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9444          
##                  95% CI : (0.8134, 0.9932)
##     No Information Rate : 0.3889          
##     P-Value [Acc &gt; NIR] : 2.763e-12       
##                                           
##                   Kappa : 0.9167          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 0.8571            1.0000           1.0000
## Specificity                 1.0000            0.9231           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              0.9167            1.0000           1.0000
## Prevalence                  0.3889            0.2778           0.3333
## Detection Rate              0.3333            0.2778           0.3333
## Detection Prevalence        0.3333            0.3333           0.3333
## Balanced Accuracy           0.9286            0.9615           1.0000</code></pre>
<div id="pour-aller-plus-loin-1" class="section level4">
<h4><span class="header-section-number">12.8.1.1</span> Pour aller plus loin</h4>
<p>En une heure divis√©e en <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">4 vid√©os</a>, Grant Sanderson explique les r√©seaux neuronaux de mani√®re intuitive. En ce qui a trait √† Keras, je recommande le livre <a href="https://www.safaribooksonline.com/library/view/deep-learning-with/9781617295546/?ar">Deep learning with R, de Fran√ßois Allaire</a>, auquel vous avez acc√®s avec un IDUL de l‚ÄôUniversit√© Laval. Si vous vous sentez √† l‚Äôaise √† utiliser Keras avec le langage Python, je vous recommande le cours gratuit en ligne <a href="https://www.youtube.com/watch?v=sRy26qWejOI&amp;list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN"><em>Applications of deep neural networks</em>, de Jeff Heaton</a>.</p>
<p>Des types de r√©seaux neuronaux sp√©cialis√©s ont √©t√© d√©velopp√©s. Je les pr√©sente sans aller dans les d√©tails.</p>
<ul>
<li><strong>R√©seaux neuronaux convolutif</strong>. Ce type de r√©seau neuronal est surtout utilis√© en reconnaissance d‚Äôimage. Les couches de neurones convolutifs poss√®dent, en plus des fonctions des perceptrons classiques, des filtres permettant d‚Äôint√©grer les variables descriptives connexes √† l‚Äôobservation: dans le cas d‚Äôune image, il s‚Äôagit de scanner les pixels au pourtour du pixel trait√©. <a href="https://www.youtube.com/watch?v=YRhxdVk_sIs">Une br√®ve introduction sur Youtube</a>.</li>
<li><strong>R√©seaux neuronaux r√©currents</strong>. Pr√©dire des occurrences futures √† partir de s√©ries temporelles implique que la r√©ponse au temps t d√©pend non seulement de conditions externes, mais aussi le la r√©ponse au temps t-1. Les r√©seaux neuronaux r√©currents. Vous devrez ajouter des neurones particuliers pour cette t√¢che, qui pourra √™tre pris en charge par Keras gr√¢ce aux couches de type <a href="https://www.youtube.com/watch?v=UnclHXZszpw"><em>Long Short-Term Memory network</em>, ou LSTM</a>.</li>
<li><strong>R√©seaux neuronaux probabilistes</strong>. Les r√©seaux neuronaux non-probabilistes offre une estimation de la variable r√©ponse. Mais quelle est la cr√©dibilit√© de la r√©ponse selon les variables descriptives? Question qui pourrait se r√©v√©ler cruciale en m√©decine ou en ing√©nierie, √† la laquelle on pourra r√©pondre en mode probabiliste. Pour ce faire, on pose des distributions <em>a priori</em> sur les poids du r√©seau neuronal. Le module <a href="http://edwardlib.org/"><code>edward</code></a>, programm√© et distribu√© en Python, offre cette possibilit√©. Vous pourrez acc√©der √† <code>edward</code> gr√¢ce au module <code>reticulate</code>, mais √† ce stade mieux vaudra basculer en Python. Pour en savoir davantage, consid√©rez <a href="https://www.youtube.com/watch?v=I09QVNrUS3Q">cette conf√©rence de Andrew Rowan</a>.</li>
</ul>
</div>
</div>
</div>
<div id="les-processus-gaussiens" class="section level2">
<h2><span class="header-section-number">12.9</span> Les processus gaussiens</h2>
<p>Les sorties des techniques que sont les KNN, les arbres ou les for√™ts ainsi que les r√©seaux neuronaux sont (classiquement) des nombres r√©els ou des cat√©gories. Dans les cas o√π la cr√©dibilit√© de la r√©ponse est importante, il devient pertinent que la sortie soit probabiliste: les pr√©dictions seront alors pr√©sent√©es sous forme de distributions de probabilit√©. Dans le cas d‚Äôune classification, la sortie du mod√®le sera un vecteur de probabilit√© qu‚Äôune observation appartienne √† une classe ou √† une autre. Dans celui d‚Äôune r√©gression, on obtiendra une distribution continue.</p>
<p>Les <strong>processus gaussiens</strong> tirent profit des statistiques bay√©siennes pour effectuer des pr√©dictions probabilistes. D‚Äôautres techniques peuvent √™tre utilis√©es pour effectuer des pr√©dictions probabilistes, comme les <a href="http://edwardlib.org/iclr2017">r√©seaux neuronaux probabilistes</a>, que j‚Äôai introduits pr√©c√©demment.</p>
<p>Bien que les processus gaussiens peuvent √™tre utilis√©s pour la classification, son fonctionnement s‚Äôexplique favorablement, de mani√®re intuitive, pas la r√©gression.</p>
<div id="un-approche-intuitive" class="section level3">
<h3><span class="header-section-number">12.9.1</span> Un approche intuitive</h3>
<p>Ayant acquis de l‚Äôexp√©rience en enseignement des processus gaussiens, <a href="http://stat.columbia.edu/~cunningham/">John Cunningham</a> a d√©velopp√© une approche intuitive permettant de saisir les m√©canismes des processus gaussiens. lors de conf√©rences disponible sur YouTube (<a href="https://youtu.be/BS4Wd5rwNwE">1</a>, <a href="https://www.youtube.com/watch?v=Jv25sg-IYHU">2</a>), il aborde le sujet par la n√©cessit√© d‚Äôeffectuer une r√©gression non-lin√©aire.</p>
<p>G√©n√©rons d‚Äôabord une variable pr√©dictive <code>x</code>, l‚Äôheure, et une variable r√©ponse <code>y</code>, le rythme cardiaque d‚Äôun individu en battements par minute (bpm).</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">17</span>)
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>, <span class="dv">69</span>, <span class="dv">67</span>, <span class="dv">78</span>)

<span class="kw">plot</span>(x, y, <span class="dt">xlab=</span><span class="st">&quot;Heure&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">12</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">12</span>, <span class="dv">67</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">16</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">16</span>, <span class="dv">72</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-409-1.png" width="672" /></p>
<p>Poser un probl√®me par un processus gaussien, c‚Äôest se demander les valeurs cr√©dibles qui pourraient √™tre obtenues hors du domaine d‚Äôobservations (par exemple, dans la figure ci-dessus, √† <code>x=12</code> et <code>x=16</code>)? Ou bien, de mani√®re plus g√©n√©rale, <em>quelles fonctions ont pu g√©n√©rer les variables r√©ponse √† partir d‚Äôune structure dans les variables pr√©dictives?</em></p>
<p>Les distributions normales, que nous appellerons <em>gaussiennes</em> dans cette section par concordance avec le terme <em>processus gaussien</em>, sont particuli√®rement utiles pour r√©pondre √† cette question.</p>
<p>Nous avons vu pr√©c√©demment ce que sont les distributions de probabilit√©: des outils math√©matiques permettant d‚Äôappr√©hender la structure des processus al√©atoires. Une distribution gaussienne repr√©sente une situation o√π l‚Äôon tire au hasard des valeurs continues. Une distribution gaussienne de la variable al√©atoire <span class="math inline">\(X\)</span> de moyenne <span class="math inline">\(0\)</span> et de variance de <span class="math inline">\(1\)</span> est not√©e ainsi:</p>
<p><span class="math display">\[ X \sim \mathcal{N} \left( 0, 1\right)\]</span></p>
<p>Par exemple, une courbe de distribution gaussienne du rythme cardiaque √† 7:00 pourrait prendre la forme suivante.</p>
<p><span class="math display">\[ bpm \sim \mathcal{N} \left( 65, 5\right)\]</span></p>
<p>En <code>R</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">x_sequence &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">50</span>, <span class="dv">80</span>, <span class="dt">length=</span><span class="dv">100</span>)
<span class="kw">plot</span>(x_sequence,
     <span class="kw">dnorm</span>(x_sequence, <span class="dt">mean=</span><span class="dv">65</span>, <span class="dt">sd=</span><span class="dv">5</span>),
     <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Densit√©&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-410-1.png" width="672" /></p>
<p>Une distribution <strong>bi</strong>normale, un cas particulier de la distribution <strong>multi</strong>normale, comprendra deux vecteurs, <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_2\)</span>. Elle aura donc deux moyennes. Puisqu‚Äôil s‚Äôagit d‚Äôune distribution binormale, et non pas deux distributions normales, les deux variables ne sont pas ind√©pendantes et l‚Äôon utilisera une matrice de covariance au lieu de deux variances ind√©pendantes.</p>
<p><span class="math display">\[
\binom{x_1}{x_2} \sim \mathcal{N}
\Bigg( 
\binom{\mu_1}{\mu_2},
\left[ {\begin{array}{cc}
\Sigma_{x_1} &amp; \Sigma_{x_1,x_2} \\
\Sigma_{x_1,x_2}^T &amp; \Sigma_{x_2} \\
\end{array} } \right]
\Bigg)
\]</span></p>
<p>La matrice <span class="math inline">\(\Sigma\)</span>, dite de <em>variance-covariance</em>, indique sur sa diagonale les variances des variables (<span class="math inline">\(\Sigma_{x_1}\)</span> et <span class="math inline">\(\Sigma_{x_2}\)</span>). Les covariances <span class="math inline">\(\Sigma_{x_1,x_2}\)</span> et <span class="math inline">\(\Sigma_{x_1,x_2}^T\)</span> sont sym√©triques et indiquent le lien entre les variables.</p>
<p>On pourrait supposer que le rythme cardiaque √† 8:00 soit corr√©l√© avec celui √† 7:00. Mises ensembles, les distributions gaussiennes √† 7:00 et √† 8:00 formeraient une distribution gaussienne binormale.</p>
<p><span class="math display">\[
\binom{bpm_7}{bpm_8} \sim \mathcal{N}
\Bigg( 
\binom{65}{75},
\left[ {\begin{array}{cc}
10 &amp; 6 \\
6 &amp; 15 \\
\end{array} } \right]
\Bigg)
\]</span></p>
<p>En <code>R</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;ellipse&quot;</span>)</code></pre>
<pre><code>## 
## Attaching package: &#39;ellipse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     ellipse</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     pairs</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">means_vec &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">75</span>)
covariance_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">15</span>), <span class="dt">ncol=</span><span class="dv">2</span>)
<span class="kw">par</span>(<span class="dt">pty=</span><span class="st">&#39;s&#39;</span>)
<span class="kw">plot</span>(<span class="kw">ellipse</span>(<span class="dt">x=</span>covariance_mat, <span class="dt">centre=</span>means_vec, <span class="dt">levels=</span><span class="fl">0.95</span>), 
     <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Rythme cardiaque √† 7:00 (bpm)&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque √† 8:00 (bpm)&quot;</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-411-1.png" width="672" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#lines(ellipse(x=covariance_mat, centre=means_vec, level=0.8))</span></code></pre>
<p>On peut se poser la question: √©tant donn√©e que <span class="math inline">\(x_1 = 68\)</span>, quelle serait la distribution de <span class="math inline">\(x_2\)</span>? Dans ce cas bivari√©e, la distribution marginale serait univari√©e, mais dans le cas multivari√© en <span class="math inline">\(D\)</span> dimensions, la distribution marginale o√π l‚Äôon sp√©cifie <span class="math inline">\(m\)</span> variables serait de <span class="math inline">\(D-m\)</span>. de Une propri√©t√© fondamentale d‚Äôune distribution gaussienne est que peu importe l‚Äôendroit o√π l‚Äôangle selon lequel on la tranche, la distribution marginale sera aussi gaussienne. Lorsque l‚Äôon retranche une ou plusieurs variables en sp√©cifiant la valeur qu‚Äôelles prennent, on applique un <em>conditionnement</em> √† la distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;condMVNorm&quot;</span>)

condition_x1 &lt;-<span class="st"> </span><span class="dv">61</span> <span class="co"># changer ce chiffre pour visualiser l&#39;effet</span>

cond_parameters &lt;-<span class="st"> </span><span class="kw">condMVN</span>(<span class="dt">mean=</span>means_vec, <span class="dt">sigma=</span>covariance_mat,
                           <span class="dt">dependent=</span><span class="dv">2</span>, <span class="dt">given=</span><span class="dv">1</span>, <span class="dt">X.given=</span>condition_x1)
cond_mean &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condMean
cond_sd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(cond_parameters<span class="op">$</span>condVar)
x2_sequence &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">50</span>, <span class="dv">90</span>, <span class="dt">length=</span><span class="dv">100</span>)
x2_dens &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x2_sequence, <span class="dt">mean=</span>cond_mean, <span class="dt">sd=</span>cond_sd)

<span class="kw">par</span>(<span class="dt">pty=</span><span class="st">&#39;s&#39;</span>)
<span class="kw">plot</span>(<span class="kw">ellipse</span>(<span class="dt">x=</span>covariance_mat, <span class="dt">centre=</span>means_vec, <span class="dt">levels=</span><span class="fl">0.95</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Rythme cardiaque √† 7:00 (bpm)&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque √† 8:00 (bpm)&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>condition_x1, <span class="dt">col=</span><span class="st">&#39;#f8ad00&#39;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">lty=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="dt">x=</span>condition_x1 <span class="op">+</span><span class="st"> </span>x2_dens<span class="op">*</span><span class="dv">40</span>, <span class="dt">y=</span>x2_sequence, <span class="dt">col=</span><span class="st">&quot;#f8ad00&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">c</span>(condition_x1, condition_x1),
      <span class="dt">y =</span> <span class="kw">c</span>(cond_mean<span class="op">-</span>cond_sd, cond_mean<span class="op">+</span>cond_sd),
      <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>)
<span class="kw">points</span>(condition_x1, cond_mean, 
       <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">2</span>)

n_sample &lt;-<span class="st"> </span><span class="dv">20</span>
<span class="kw">points</span>(<span class="dt">x =</span> <span class="kw">rep</span>(condition_x1, n_sample),
       <span class="dt">y =</span> <span class="kw">rnorm</span>(n_sample, cond_mean, cond_sd),
       <span class="dt">pch=</span><span class="dv">4</span>, <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.5</span>))</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-412-1.png" width="672" /></p>
<p>Les points sur l‚Äôaxe (symbole x) conditionn√©s sont des √©chantillons tir√©s au hasard dans la distribution conditionn√©e.</p>
<p>Une autre mani√®re de visualiser la distribution gaussienne binormale est de placer <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_2\)</span> c√¥te √† c√¥te en abscisse, avec leur valeur en ordonn√©e. Le bloc de code suivant peut sembler lourd au premier coup d‚Äô≈ìil: pas de panique, il s‚Äôagit surtout d‚Äôinstructions graphiques. Vous pouvez vous amuser √† changer les param√®tres de la distribution binormale (section 1) ainsi que la valeur de <span class="math inline">\(x_1\)</span> √† laquelle est conditionn√©e la distribution de <span class="math inline">\(x_2\)</span> (section 2).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">source</span>(<span class="st">&quot;lib/plot_matrix.R&quot;</span>)

<span class="co"># 1. Distribution</span>
means_vec &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">65</span>)
covariance_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">15</span>), <span class="dt">ncol=</span><span class="dv">2</span>)

<span class="co"># 2. Condition</span>
condition_x1 &lt;-<span class="st"> </span><span class="dv">61</span> <span class="co"># changer ce chiffre pour visualiser l&#39;effet</span>

<span class="co"># 3. Densit√© conditionn√©e</span>
cond_parameters &lt;-<span class="st"> </span><span class="kw">condMVN</span>(<span class="dt">mean=</span>means_vec, <span class="dt">sigma=</span>covariance_mat,
                           <span class="dt">dependent=</span><span class="dv">2</span>, <span class="dt">given=</span><span class="dv">1</span>, <span class="dt">X.given=</span>condition_x1)
cond_mean &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condMean
cond_sd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(cond_parameters<span class="op">$</span>condVar)
x2_sequence &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">50</span>, <span class="dv">90</span>, <span class="dt">length=</span><span class="dv">100</span>)
x2_dens &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x2_sequence, <span class="dt">mean=</span>cond_mean, <span class="dt">sd=</span>cond_sd)
x2_draw &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, cond_mean, cond_sd)

<span class="co"># 4. Graphiques</span>
<span class="kw">options</span>(<span class="dt">repr.plot.width =</span> <span class="dv">8</span>, <span class="dt">repr.plot.height =</span> <span class="dv">5</span>)
<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">widths=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>), <span class="dt">pty=</span><span class="st">&#39;s&#39;</span>)

<span class="co">## 4.1 Ellipse</span>
<span class="kw">plot</span>(<span class="kw">ellipse</span>(<span class="dt">x=</span>covariance_mat, <span class="dt">centre=</span>means_vec, <span class="dt">levels=</span><span class="fl">0.95</span>), 
     <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;BPM √† 7:00&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;BPM √† 8:00&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>condition_x1, <span class="dt">col=</span><span class="st">&#39;#f8ad00&#39;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)
<span class="kw">lines</span>(<span class="dt">x=</span>condition_x1 <span class="op">+</span><span class="st"> </span>x2_dens<span class="op">*</span><span class="dv">40</span>, <span class="dt">y=</span>x2_sequence, <span class="dt">col=</span><span class="st">&quot;#f8ad00&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">c</span>(condition_x1, condition_x1),
      <span class="dt">y =</span> <span class="kw">c</span>(cond_mean<span class="op">-</span>cond_sd, cond_mean<span class="op">+</span>cond_sd),
      <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>)
<span class="kw">points</span>(condition_x1, cond_mean, 
       <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span>)
<span class="kw">points</span>(condition_x1, x2_draw, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&quot;#b94a73&quot;</span>)

<span class="co">## 4.2 Covariance</span>
<span class="kw">plot_matrix</span>(covariance_mat)

<span class="co">## 4.3 S√©rie</span>
<span class="kw">plot</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(condition_x1, x2_draw), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">55</span>, <span class="dv">75</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Indice de la variable&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)
<span class="kw">points</span>(<span class="dv">1</span>, condition_x1, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">cex=</span><span class="dv">3</span>)
<span class="kw">points</span>(<span class="dv">2</span>, x2_draw, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#b94a73&#39;</span>, <span class="dt">cex=</span><span class="dv">3</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-413-1.png" width="672" /></p>
<p>Les valeurs que peuvent prendre le rythme cardiaque en <span class="math inline">\(x_2\)</span> sont tir√©es al√©atoirement d‚Äôune distribution conditionn√©e. Sautons maintenant au cas multinormal, incluant 6 variables (<em>hexanormal</em>!). Afin d‚Äô√©viter de composer une matrice de covariance √† la mitaine, je me permets de la g√©n√©rer avec une fonction. Cette fonction particuli√®re est nomm√©e <em>fonction de base radiale</em> ou <em>exponentiel de la racine</em>.</p>
<p><span class="math display">\[K_{RBF} \left( x_i, x_j \right) = \sigma^2 exp \left( -\frac{\left( x_i - x_j \right)^2}{2 l^2}  \right) \]</span></p>
<pre class="sourceCode r"><code class="sourceCode r">RBF_kernel &lt;-<span class="st"> </span><span class="cf">function</span>(x, sigma, l) {
  n &lt;-<span class="st"> </span><span class="kw">length</span>(x)
  k &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> n, <span class="dt">nrow =</span> n)
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
      k[i, j] =<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>l<span class="op">^</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(x[i] <span class="op">-</span><span class="st"> </span>x[j])<span class="op">^</span><span class="dv">2</span>)
    }
  }
  <span class="kw">colnames</span>(k) &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&#39;x&#39;</span>, <span class="dv">1</span><span class="op">:</span>n)
  <span class="kw">rownames</span>(k) &lt;-<span class="st"> </span><span class="kw">colnames</span>(k)
  <span class="kw">return</span>(k)
}</code></pre>
<p>Dans la fonction <code>RBF_kernel</code>, <code>x</code> d√©signe les dimensions, <code>sigma</code> d√©signe un √©cart-type commun √† chacune des dimensions et <code>l</code> est la longueur d√©signant l‚Äôamplification de la covariance entre des dimensions √©loign√©es (dans le sens que la premi√®re dimension est √©loign√©e de la derni√®re). Pour 6 dimensions, avec un √©cart-type de 4 et une longueur de 2.</p>
<pre class="sourceCode r"><code class="sourceCode r">covariance_<span class="dv">6</span> &lt;-<span class="st"> </span><span class="kw">RBF_kernel</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">sigma=</span><span class="dv">4</span>, <span class="dt">l=</span><span class="dv">2</span>)
<span class="kw">round</span>(covariance_<span class="dv">6</span>, <span class="dv">2</span>)</code></pre>
<pre><code>##       x1    x2    x3    x4    x5    x6
## x1 16.00 14.12  9.70  5.19  2.17  0.70
## x2 14.12 16.00 14.12  9.70  5.19  2.17
## x3  9.70 14.12 16.00 14.12  9.70  5.19
## x4  5.19  9.70 14.12 16.00 14.12  9.70
## x5  2.17  5.19  9.70 14.12 16.00 14.12
## x6  0.70  2.17  5.19  9.70 14.12 16.00</code></pre>
<p>Changez la valeur de <code>l</code> permet de bien saisir son influence sur la matrice de covariance. Avec un <code>l</code> de 1, la covariance entre <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_6\)</span> est pratiquement nulle: elle est un peut plus √©lev√©e avec <code>l=2</code>. Pour reprendre l‚Äôexemple du rythme cardiaque, on devrait en effet s‚Äôattendre √† retrouver une plus grande corr√©lation entre celles mesur√©es aux temps 4 et 5 qu‚Äôentre les temps 1 et 6.</p>
<p>De m√™me que dans la situation o√π nous avions une distribution binormale, nous pouvons conditionner une distribution multinormale. Dans l‚Äôexemple suivant, je conditionne la distribution multinormale de 6 dimensions en sp√©cifiant les valeurs prises par les deux premi√®res dimensions. Le r√©sultat du conditionnement est une distribution en 4 dimensions. Puisqu‚Äôil est difficile de pr√©senter une distribution en 6D, le graphique en haut √† gauche ne comprend que les dimensions 1 et 6. Remarquez que la corr√©lation entre les dimensions 1 et 6 est faible, en concordance avec la matrice de covariance g√©n√©r√©e par la fonction <code>RBF_kernel</code>. Lancez plusieurs fois le code et voyez ce qui advient des √©chantillonnages dans les dimensions 3 √† 6 selon le conditionnement en 1 et 2.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(<span class="st">&quot;MASS&quot;</span>)

<span class="co"># 1. Distribution</span>
means_vec &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">65</span>, <span class="dv">6</span>)
covariance_mat &lt;-<span class="st"> </span>covariance_<span class="dv">6</span>

<span class="co"># 2. Condition</span>
conditions_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>) <span class="co"># changer ces chiffres pour visualiser l&#39;effet</span>

<span class="co"># 3. Densit√© conditionn√©e</span>
cond_parameters &lt;-<span class="st"> </span><span class="kw">condMVN</span>(<span class="dt">mean=</span>means_vec, <span class="dt">sigma=</span>covariance_mat, 
                           <span class="dt">dependent.ind =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">given.ind=</span><span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,
                           <span class="dt">X.given=</span>conditions_x)
cond_mean &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condMean
cond_sd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(cond_parameters<span class="op">$</span>condVar)
x6_sequence &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">50</span>, <span class="dv">90</span>, <span class="dt">length=</span><span class="dv">100</span>)
x6_dens &lt;-<span class="st"> </span><span class="kw">dnorm</span>(x2_sequence, <span class="dt">mean=</span>cond_mean[<span class="dv">4</span>], <span class="dt">sd=</span>cond_sd[<span class="dv">4</span>, <span class="dv">4</span>])

x_<span class="fl">3.6</span>_draw &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mu =</span> cond_mean, <span class="dt">Sigma =</span> cond_sd<span class="op">^</span><span class="dv">2</span>)

<span class="co"># 4. Graphiques</span>
<span class="kw">layout</span>(<span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">nrow=</span><span class="dv">2</span>), <span class="dt">widths=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>))

<span class="co">## 4.1 Ellipse</span>
<span class="kw">plot</span>(<span class="kw">ellipse</span>(<span class="dt">x=</span>covariance_mat[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>), <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>)], <span class="dt">centre=</span>means_vec[<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">6</span>)], <span class="dt">levels=</span><span class="fl">0.95</span>), 
     <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">xlab=</span><span class="st">&quot;BPM √† 7:00&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;BPM √† 8:00&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>conditions_x[<span class="dv">1</span>], <span class="dt">col=</span><span class="st">&#39;#f8ad00&#39;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)
<span class="kw">lines</span>(<span class="dt">x=</span>condition_x1 <span class="op">+</span><span class="st"> </span>x6_dens<span class="op">*</span><span class="dv">40</span>, <span class="dt">y=</span>x2_sequence, <span class="dt">col=</span><span class="st">&quot;#f8ad00&quot;</span>, <span class="dt">lwd=</span><span class="dv">1</span>)
<span class="kw">lines</span>(<span class="dt">x =</span> <span class="kw">c</span>(conditions_x[<span class="dv">1</span>], conditions_x[<span class="dv">1</span>]),
      <span class="dt">y =</span> <span class="kw">c</span>(cond_mean[<span class="dv">4</span>]<span class="op">-</span>cond_sd[<span class="dv">4</span>, <span class="dv">4</span>], cond_mean[<span class="dv">4</span>]<span class="op">+</span>cond_sd[<span class="dv">4</span>, <span class="dv">4</span>]),
      <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>)
<span class="kw">points</span>(conditions_x[<span class="dv">1</span>], cond_mean[<span class="dv">4</span>],
       <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="dv">1</span>)
<span class="kw">points</span>(conditions_x[<span class="dv">1</span>], x_<span class="fl">3.6</span>_draw[<span class="dv">4</span>], <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&quot;#b94a73&quot;</span>)

<span class="co">## 4.2 Covariance</span>
<span class="kw">plot_matrix</span>(covariance_mat, <span class="dt">cex=</span><span class="fl">0.8</span>)

<span class="co">## 4.3 S√©rie</span>
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="kw">c</span>(conditions_x, x_<span class="fl">3.6</span>_draw), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">6</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">60</span>, <span class="dv">85</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Indice de la variable&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)
<span class="kw">points</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), conditions_x, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">cex=</span><span class="dv">3</span>)
<span class="kw">points</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>, x_<span class="fl">3.6</span>_draw, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#b94a73&#39;</span>, <span class="dt">cex=</span><span class="dv">3</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-416-1.png" width="672" /></p>
<p>La structure de la covariance assure que les dimensions proches prennent des valeurs similaires, assurant une courbe lisse et non en dents de scie. Pourquoi s‚Äôarr√™ter √† 6 dimensions? Prenons-en plusieurs, puis g√©n√©rons plus d‚Äôun √©chantillon. Ensuite, utilisons ces simulations pour de calculer la moyenne et l‚Äô√©cart-type de chacune des dimensions.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. Distribution</span>
n &lt;-<span class="st"> </span><span class="dv">20</span>
means_vec &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">65</span>, n)
covariance_mat &lt;-<span class="st"> </span><span class="kw">RBF_kernel</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span>n, <span class="dt">sigma =</span> <span class="dv">10</span>, <span class="dt">l =</span> <span class="dv">2</span>)

<span class="co"># 2. Condition</span>
conditions_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>) <span class="co"># changer ces chiffres pour visualiser l&#39;effet</span>

<span class="co"># 3. Densit√© conditionn√©e</span>
cond_parameters &lt;-<span class="st"> </span><span class="kw">condMVN</span>(<span class="dt">mean=</span>means_vec, <span class="dt">sigma=</span>covariance_mat, 
                           <span class="dt">dependent.ind =</span> <span class="dv">3</span><span class="op">:</span>n, <span class="dt">given.ind=</span><span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,
                           <span class="dt">X.given=</span>conditions_x)
cond_mean &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condMean
cond_sd &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condVar

<span class="co"># 4. Graphiques</span>
<span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>))

<span class="co">## 4.3 S√©rie</span>
<span class="kw">plot</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, n), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">95</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Indice de la variable&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)

samples &lt;-<span class="st"> </span><span class="dv">50</span>
x_<span class="fl">3.</span>n_draw &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> samples, <span class="dt">mu =</span> cond_mean, <span class="dt">Sigma =</span> cond_sd)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>samples) {
  <span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">c</span>(conditions_x, x_<span class="fl">3.</span>n_draw[i, ]), <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.15</span>))
}
x_<span class="fl">3.</span>n_draw_mean &lt;-<span class="st"> </span><span class="kw">apply</span>(x_<span class="fl">3.</span>n_draw, <span class="dv">2</span>, mean)
x_<span class="fl">3.</span>n_draw_sd &lt;-<span class="st"> </span><span class="kw">apply</span>(x_<span class="fl">3.</span>n_draw, <span class="dv">2</span>, stats<span class="op">::</span>sd)

<span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">c</span>(conditions_x, x_<span class="fl">3.</span>n_draw_mean), <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">c</span>(conditions_x, x_<span class="fl">3.</span>n_draw_mean <span class="op">+</span><span class="st"> </span>x_<span class="fl">3.</span>n_draw_sd), <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, <span class="kw">c</span>(conditions_x, x_<span class="fl">3.</span>n_draw_mean <span class="op">-</span><span class="st"> </span>x_<span class="fl">3.</span>n_draw_sd), <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">points</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), conditions_x, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-417-1.png" width="672" /></p>
<p>Revenons au rythme cardiaque. On pourra utiliser le conditionnement aux temps observ√©s, soit 7:00, 8:00, 10:00, 14:00 et 17:00 pour estimer la distribution √† 12:00 et 16:00, o√π √† des dimensions artificielles quelconques ici fix√©es aux demi-heures.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 1. Distribution</span>
n &lt;-<span class="st"> </span><span class="dv">21</span>
means_vec &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">65</span>, n)
covariance_mat &lt;-<span class="st"> </span><span class="kw">RBF_kernel</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span>n, <span class="dt">sigma =</span> <span class="dv">5</span>, <span class="dt">l =</span> <span class="dv">2</span>)

<span class="co"># 2. Condition</span>
conditions_x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>, <span class="dv">69</span>, <span class="dv">67</span>, <span class="dv">78</span>)
conditions_indices &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">21</span>)
dependent_indices &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>)[<span class="op">!</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">20</span> <span class="op">%in%</span><span class="st"> </span>conditions_indices]

<span class="co"># 3. Densit√© conditionn√©e</span>
cond_parameters &lt;-<span class="st"> </span><span class="kw">condMVN</span>(<span class="dt">mean=</span>means_vec, <span class="dt">sigma=</span>covariance_mat, 
                           <span class="dt">dependent.ind =</span> dependent_indices,
                           <span class="dt">given.ind=</span>conditions_indices,
                           <span class="dt">X.given=</span>conditions_x)
cond_mean &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condMean
cond_sd &lt;-<span class="st"> </span>cond_parameters<span class="op">$</span>condVar
samples &lt;-<span class="st"> </span><span class="dv">100</span>
x_draw &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> samples, <span class="dt">mu =</span> cond_mean, <span class="dt">Sigma =</span> cond_sd)
means_draw &lt;-<span class="st"> </span><span class="kw">apply</span>(x_draw, <span class="dv">2</span>, mean)
sd_draw &lt;-<span class="st"> </span><span class="kw">apply</span>(x_draw, <span class="dv">2</span>, stats<span class="op">::</span>sd)

<span class="co"># 4. Graphiques</span>
<span class="kw">par</span>(<span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">1</span>))

<span class="co">## 4.1 Combiner les pr√©dictions</span>
bpm &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n)
bpm[conditions_indices] &lt;-<span class="st"> </span>conditions_x
bpm[dependent_indices] &lt;-<span class="st"> </span>means_draw

bpm_sd &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, n)
bpm_sd[conditions_indices] &lt;-<span class="st"> </span><span class="dv">0</span>
bpm_sd[dependent_indices] &lt;-<span class="st"> </span>sd_draw


<span class="co">## 4.2 Combiner les tirages et les donn√©es</span>
x_draw_all &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> n, <span class="dt">nrow =</span> samples)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(conditions_x)) x_draw_all[, conditions_indices[i]] &lt;-<span class="st"> </span>conditions_x[i]
x_draw_all[, dependent_indices] &lt;-<span class="st"> </span>x_draw


<span class="co">## 4.3 S√©rie</span>
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span>n, bpm, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>, n), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">90</span>), <span class="dt">type=</span><span class="st">&#39;l&#39;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Indice de la variable&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>samples) {
  <span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, x_draw_all[i, ], <span class="dt">col =</span> <span class="kw">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.1</span>))
}
<span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, bpm<span class="op">+</span>bpm_sd, <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">lines</span>(<span class="dv">1</span><span class="op">:</span>n, bpm<span class="op">-</span>bpm_sd, <span class="dt">col =</span> <span class="st">&quot;#b94a73&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)
<span class="kw">points</span>(conditions_indices, bpm[conditions_indices], <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">col=</span><span class="st">&#39;#46c19a&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-418-1.png" width="672" /></p>
<p>Comme on devrait s‚Äôy attendre, la r√©gression r√©sultant de la mise en indices de la distribution est pr√©cise aux mesures, et impr√©cise aux indices peu garnis en mesures. Nous avions utilis√© 21 dimensions. <strong>Lorsque l‚Äôon g√©n√©ralise la proc√©dure √† une quantit√© infinie de dimensions, on obtient un <em>processus gaussien</em>.</strong></p>
<p><img src="https://media.giphy.com/media/12R2bKfxceemNq/giphy.gif" /></p>
<p>L‚Äôindice de la variable devient ainsi une valeur r√©elle. Un processus gaussien, <span class="math inline">\(\mathcal{GP}\)</span>, est d√©fini par une fonction de la moyenne, <span class="math inline">\(m \left( x \right)\)</span>, et une autre de la covariance que l‚Äôon nomme <em>noyau</em> (ou <em>kernel</em>), <span class="math inline">\(K \left( x, x&#39; \right)\)</span>. Un processus gaussien est not√© de la mani√®re suivante:</p>
<p><span class="math display">\[\mathcal{GP} \sim \left( m \left( x \right), K \left( x, x&#39; \right) \right)\]</span></p>
<p>La fonction d√©finissant la moyenne peut √™tre facilement √©cart√©e en s‚Äôassurant de centrer la variable r√©ponse √† z√©ro (<span class="math inline">\(y_{centr√©} = y - \hat{y}\)</span>). Ainsi, par convention, on sp√©cifie une fonction de moyenne comme retournant toujours un z√©ro. Quant au noyau, il peut prendre diff√©rentes fonctions de covariance ou combinaisons de fonctions de covariance. R√®gle g√©n√©rale, on utilisera un noyau permettant de d√©finir deux param√®tres: la hauteur (<span class="math inline">\(\sigma\)</span>) et la longueur de l‚Äôondulation (<span class="math inline">\(l\)</span>).</p>
<pre class="sourceCode r"><code class="sourceCode r">hyperparameters &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">l=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">9</span>), <span class="dt">sigma=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)

<span class="co"># Graphique</span>
n &lt;-<span class="st"> </span><span class="dv">100</span>

samples_list &lt;-<span class="st"> </span><span class="kw">list</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(hyperparameters)) {
  sample &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">mu =</span> <span class="kw">rep</span>(<span class="dv">0</span>, n), 
                  <span class="dt">Sigma =</span> <span class="kw">RBF_kernel</span>(<span class="dt">x=</span><span class="dv">1</span><span class="op">:</span>n,
                                     <span class="dt">sigma =</span> hyperparameters<span class="op">$</span>sigma[i],
                                     <span class="dt">l =</span> hyperparameters<span class="op">$</span>l[i]))
  samples_list[[i]] &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">sigma =</span> <span class="kw">paste</span>(<span class="st">&quot;sigma =&quot;</span>, hyperparameters<span class="op">$</span>sigma[i]),
                                  <span class="dt">l =</span> <span class="kw">paste</span>(<span class="st">&quot;l =&quot;</span>, hyperparameters<span class="op">$</span>l[i]),
                                  <span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span>n,
                                  <span class="dt">sample =</span> sample)
  
}
samples_df &lt;-<span class="st"> </span><span class="kw">bind_rows</span>(samples_list)</code></pre>
<pre><code>## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character</code></pre>
<pre><code>## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector</code></pre>
<pre><code>## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character</code></pre>
<pre><code>## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector

## Warning in bind_rows_(x, .id): binding character and factor vector,
## coercing into character vector</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">samples_df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> sample)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_grid</span>(l <span class="op">~</span><span class="st"> </span>sigma)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-419-1.png" width="672" /></p>
<p>On pourra ajouter √† ce noyau un bruit blanc, c‚Äôest-√†-dire une variation purement al√©atoire, sans covariance (noyau g√©n√©rant une matrice diagonale).</p>
<p>Le noyau devient ainsi un <em>a priori</em>, et le processus gaussien conditionn√© aux donn√©es devient un <em>a posteriori</em> probabiliste.</p>
<p>Finalement, les processus gaussiens peuvent √™tre extrapol√©s √† plusieurs variables descriptives.</p>
</div>
<div id="les-processus-gaussiens-en-r" class="section level3">
<h3><span class="header-section-number">12.9.2</span> Les processus gaussiens en <code>R</code></h3>
<p>Pas de souci, vous n‚Äôaurez pas √† programmer vos propres fonctions pour lancer des processus gaussiens. Vous pourrez <a href="https://topepo.github.io/caret/train-models-by-tag.html#gaussian-process">passer par <code>caret</code></a>. Vous pourriez, comme c‚Äôest le cas avec les r√©seaux neuronnaux, obtenir davantage de contr√¥le sur l‚Äôautoapprentissage en utilisant directement la fonction <code>gausspr</code> du package <code>kernlab</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(kernlab)</code></pre>
<pre><code>## 
## Attaching package: &#39;kernlab&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:permute&#39;:
## 
##     how</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     cross</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     alpha</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">17</span>)
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>, <span class="dv">69</span>, <span class="dv">67</span>, <span class="dv">78</span>)
y_sc &lt;-<span class="st"> </span>(y <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(y)

m &lt;-<span class="st"> </span><span class="kw">gausspr</span>(x, y_sc, <span class="dt">kernel =</span> <span class="st">&#39;rbfdot&#39;</span>,
             <span class="dt">kpar =</span> <span class="kw">list</span>(<span class="dt">sigma =</span> <span class="dv">4</span>),
             <span class="dt">variance.model =</span> <span class="ot">TRUE</span>, <span class="dt">scaled =</span> <span class="ot">TRUE</span>,
             <span class="dt">var =</span> <span class="fl">0.01</span>,
             <span class="dt">cross =</span> <span class="dv">2</span>)

xtest &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">6</span>, <span class="dv">18</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)
y_sc_pred_mean &lt;-<span class="st"> </span><span class="kw">predict</span>(m, xtest, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
y_pred_mean &lt;-<span class="st"> </span>y_sc_pred_mean <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(y)
y_sc_pred_sd &lt;-<span class="st"> </span><span class="kw">predict</span>(m, xtest, <span class="dt">type=</span><span class="st">&quot;sdeviation&quot;</span>)
y_pred_sd &lt;-<span class="st"> </span>y_sc_pred_sd <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y)

<span class="kw">plot</span>(x, y, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">18</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">45</span>, <span class="dv">90</span>))
<span class="kw">lines</span>(xtest, y_pred_mean)
<span class="kw">lines</span>(xtest, y_pred_mean <span class="op">+</span><span class="st"> </span>y_pred_sd, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">lines</span>(xtest, y_pred_mean <span class="op">-</span><span class="st"> </span>y_pred_sd, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">12</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">12</span>, <span class="dv">67</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">16</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">16</span>, <span class="dv">72</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-420-1.png" width="672" /></p>
</div>
<div id="application-pratique" class="section level3">
<h3><span class="header-section-number">12.9.3</span> Application pratique</h3>
<p>Les processus gaussiens sont utiles pour effectuer des pr√©dictions sur des ph√©nom√®ne sur lesquels on d√©sire √©viter de se commettre sur la structure. Les s√©ries temporelles ou les signaux spectraux en sont des exemples. Aussi, j‚Äôai utilis√© les processus gaussiens pour mod√©liser des courbes de r√©ponse aux fertilisants.</p>
<p>EXEMPLE‚Ä¶</p>
<p>Pr√©diction spatiale:
- <a href="https://www.sciencedirect.com/science/article/pii/S2211675316300033" class="uri">https://www.sciencedirect.com/science/article/pii/S2211675316300033</a>
- <a href="https://stackoverflow.com/questions/43618633/multi-output-spatial-statistics-with-gaussian-processes" class="uri">https://stackoverflow.com/questions/43618633/multi-output-spatial-statistics-with-gaussian-processes</a></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapitre-git.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapitre-geo.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
