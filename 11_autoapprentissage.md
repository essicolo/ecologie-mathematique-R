---
title: "Autoapprentissage"
author: "Serge-√âtienne Parent"
output: github_document
---

Plusieurs cas d'esp√®ces en sciences et g√©nies peuvent √™tre approch√©s en liant un variable avec une ou plusieurs autres √† l'aide de r√©gressions lin√©aires, polynomiales, sinuso√Ødales, exponentielle, sigmo√Ødales, [etc](https://dl.sciencesocieties.org/publications/aj/pdfs/107/2/786). Encore faut-il s'assurer que ces formes pr√©√©tablies repr√©sentent le ph√©nom√®ne de mani√®re fiable.

Lorsque la forme de la r√©ponse est difficile √† envisager, en particulier dans des cas non-lin√©aires ou impliquant plusieurs variables, on pourra faire appel √† des mod√®les dont la structure n'est pas contr√¥l√©e par une √©quation rigide gouvern√©e par des param√®tres (comme la pente ou l'intercept).

L'**autoapprentissage**, apprentissage automatique, ou *machine learning*, vise √† d√©tecter des structures complexes √©mergeant d'ensembles de donn√©es √† l'aide des math√©matiques et de processus automatis√©s afin de pr√©dire l'√©mergence de futures occurrences. Comme ensemble de techniques empiriques, l'autoapprentissage est un cas particulier de l'**intelligence artificielle**, qui elle inclu aussi les m√©canismes d√©terministes et des ensembles d'op√©rations logiques. Par exemple, les premiers ordinateurs √† comp√©titionner aux √©checs se basaient sur des r√®gles de logique (si la reine noire est positionn√©e en c3 et qu'un le fou blanc est en position f6 et que ... alors bouge la tour en g5 - j'√©cris n'importe quoi). Il s'agissait d'intelligence artificielle, mais pas d'autoapprentissage. L'autoapprentissage passera davantage par la simulation de nombreuses parties et d√©gagera la structure optimale pour l'emporter consid√©rant les positions des pi√®ces sur l'√©chiquier.

## Objectifs

* Comprendre les applications possibles de l'autoapprentissage
* Comprendre le flux de travail d'une op√©ration d'autoapprentissage
* Comprendre les principes soutenant les techniques des *k* plus proches voisins, des arbres d√©cisionnels, des r√©seaux neuronnaux et des processus gaussiens.

Plus sp√©cifiquement, vous devrez √† la fin de cette section √™tre en mesure de pr√©dire une variable cat√©gorie ou num√©rique √† partir de donn√©es observ√©es.

## Lexique
L'autoapprentissage poss√®de son jargon particulier. Puisque certains termes peuvent porter √† confusion, voici quelques d√©finitions de termes que j'utiliserai dans ce chapitre.

- **R√©ponse**. La variable que l'on cherche √† obtenir. Il peut s'agir d'une variable continue comme d'une variable cat√©gorielle. On la nomme aussi la *cible*.
- **Pr√©dicteur**. Une variable utilis√©e pour pr√©dire une r√©ponse. Les pr√©dicteurs sont des variables continues. Les pr√©dicteurs de type cat√©goriel doivent pr√©alablement √™tre dummifi√©s (voir chapitre 5). On nomme les pr√©dicteurs les *entr√©es*.
- **Apprentissage supervis√©** et **non-spervis√©**. Si vous avez suivi le cours jusqu'ici, vous avez d√©j√† utilis√© des outils entrant dans la grande famille de l'apprentissage automatique. La r√©gression lin√©aire, par exemple, vise √† minimiser l'erreur sur la r√©ponse en optimisant les coefficients de pente et l'intercept. Un apprentissage supervis√© a une cible, comme c'est le cas de la r√©gression lin√©aire. En revanche, un apprentissage non supervis√© n'en a pas: on laisse l'algorithme le soin de d√©tecter des structures int√©ressantes. Nous avons d√©j√† utilis√© cette approche. Pensez-y un peu... l'analyse en composante principale ou en coordonn√©es principales, ainsi que le partitionnement hi√©rarchique ou non sont des exemples d'apprentissage non supervis√©. En revanche, l'analyse de redondance a une r√©ponse. L'analyse discriminante aussi, bien que sa r√©ponse soit cat√©gorielle. L'apprentissage non supervis√© ayant d√©j√† √©t√© couvert au chapitre 7, ce chapitre ne s'int√©resse qu'√† l'apprentissage supervis√©.
- **R√©gression** et **Classification**. Alors que la r√©gression est un type d'apprentissage automatique pour les r√©ponses continues, la classification vise √† pr√©dire une r√©ponse cat√©gorielle. Il existe des algorithmes uniquement application √† la r√©gression, uniquement applicables √† la classification, et plusieurs autres adaptable aux deux situations.
- **Donn√©es d'entra√Ænement** et **donn√©es de test**. Lorsque l'on g√©n√®re un mod√®le, on d√©sire qu'il sache comment r√©agir √† ses pr√©dicteurs. Cela se fait avec des donn√©es d'entra√Ænement, sur lesquelles on **calibre** et **valide** le mod√®le. Les donn√©es de test servent √† v√©rifier si le mod√®le est en mesure de pr√©dire des r√©ponses sur lesquelles il n'a pas √©t√© entra√Æn√©.
- **Fonction de perte**. Une fonction qui mesure l'erreur d'un mod√®le.

## D√©marche

La premi√®re t√¢che est d'explorer les donn√©es, ce que nous avons couvert au chapitres 3 et 4.

### Pr√©traitement
Pour la plupart des techniques d'autoapprentissage, le choix de l'√©chelle de mesure est d√©terminant sur la mod√©lisation subs√©quente. Par exemple, un algorithme bas√© sur la distance comme les *k* plus proches voisins ne mesurera pas les m√™mes distances entre deux observations si l'on change l'unit√© de mesure d'une variable du m√®tre au kilom√®tre. Il est donc important d'effectuer, ou d'envisager la possibilit√© d'effectuer un pr√©traitement sur les donn√©es. Je vous r√©f√®re au chapitre 6 (en d√©veloppement) pour plus de d√©tails sur le pr√©traitement.

### Entra√Ænement et test

Vous connaissez peut-√™tre l'expression sportive "avoir l'avantage du terrain". Il s'agit d'un principe pr√©tendant que els athl√®tes performent mieux en terrain connu. Idem pour les mod√®les ph√©nom√©nologiques. Il est possible qu'un mod√®le fonctionne tr√®s bien sur les donn√©es avec lesquelles il a √©t√© entra√Æn√©, mais tr√®s mal sur des donn√©es externes. De mauvaises pr√©dictions effectu√©es √† partir d'un mod√®le qui semblait bien se comporter peut mener √† des d√©cisions qui, pourtant prises de mani√®re confiante, se r√©v√®lent fallacieuses au point d'aboutir √† de graves cons√©quences. C'est pourquoi, **en mode pr√©dictif, on doit √©valuer la pr√©cision et la justesse d'un mod√®le sur des donn√©es qui n'ont pas √©t√© utilis√©s dans son entra√Ænement**.

En pratique, il convient de s√©parer un tableau de donn√©es en deux: un tableau d'entra√Ænemnt et un tableau de test. Il n'existe pas de standards sur le ratio √† utiliser. Cela d√©pend de la prudence de l'analyse et de l'ampleur de son tableau de donn√©es. Certaines personnes pr√©f√©rerons couper le tableau √† 50%. D'autres pr√©f√©rerons r√©server le deux-tiers des donn√©es pour l'entra√Ænement, ou 70%, 75%. Rarement, r√©servera-t-on moins plus de 50% et moins de 20% √† la phase de test.

Si les donn√©es sont peu √©quilibr√©es (par exemple, on retrouve peu de donn√©es de l'esp√®ce $A$, que l'on retrouve peu de donn√©es √† un pH inf√©rieur √† 5 ou que l'on a peu de donn√©es crois√©es de l'esp√®ce $A$ √† ph inf√©rieur √† 5), il y a un danger qu'une trop grande part, voire toute les donn√©es, se retrouvent dans le tableau d'entra√Ænement (certaines situations ne seront ainsi pas test√©es) ou dans le tableau de test (certaines situations ne seront pas couvertes par le mod√®le). L'analyste doit s'assurer de s√©parer le tableau au hasard, mais de mani√®re consciencieuse.

### Sousapprentissage et surapprentissage

Une dfficult√© en mod√©lisation ph√©nom√©nologique est ce qui tient de la structure et ce qui tient du bruit. Lorsque l'on consid√®re une structure comme du bruit, on est dans un cas de sousapprentissage. Lorsque, au contraire, on interpr√®te du bruit comme une structure, on est en cas de surapprentissage. Les graphiques suivant pr√©sentent ces deux cas, avec au centre un cas d'apprentissage conforme.

```{r}
set.seed(35473)
n <- 50
x <- seq(0, 20, length = n) 
y <- 500 + 0.4 * (x-10)^3 + rnorm(n, mean=10, sd=80) # le bruit est g√©n√©r√© par rnorm()

par(mfrow = c(1, 3))
plot(x, y, main = "Sousapprentissage")
lines(x, predict(lm(y~x)), col = "red")

plot(x, y, main = "Apprentissage conforme")
lines(x, 
      predict(lm(y~x + I(x^2) + I(x^3))),
      col = "red")

plot(x, y, main = "Surapprentissage")
lines(x, 
      predict(lm(y~x + I(x^2) + I(x^3) + I(x^4) + 
                 I(x^5) + I(x^6) + I(x^7) + I(x^8) +
                 I(x^9) + I(x^10) + I(x^11) + I(x^12) +
                 I(x^13) + I(x^14) + I(x^15) + I(x^16))),
      col = "red")

```

Afin d'√©viter les cas de *m√©sapprentissage* on peut avoir recours √† la validation crois√©e.

### Validation crois√©e

Souvent confondue avec le fait de s√©parer le tableau en phases d'entra√Ænement et de test, la validation crois√©e est un principe incluant plusieurs algorithmes qui consiste √† **entra√Æner** le mod√®le sur un √©chantillonnage al√©atoire des donn√©es d'entra√Ænement.

La technique la plus utilis√©e est le *k-fold*, o√π l'on s√©pare al√©atoirement le tableau d'entra√Ænement en un nombre $k$ de tableaux. √Ä chaque √©tape de la validation crois√©e, on calibre le mod√®le sur tous les tableaux sauf un, puis on valide le mod√®le sur le tableau exclu. La performance du mod√®le en entra√Ænement est jug√©e sur les validations.

### Choix de l'algorithme d'apprentissage

Face aux centaines d'algoritmhes d'apprentissages qui vous sont offertes, choisir l'algorithme ou les algorithmes ad√©quats pour vos donn√©es n'est pas facile. Ce choix sera motiv√© par les tenants et aboutissants des algorithmes, votre exp√©rience, l'exp√©rience de la litt√©rature, l'exp√©rience de vos coll√®gues. Une approche raisonnable est de tester plusieurs mod√®les et d'approfondir si ce n'est d√©j√† fait la math√©matique des options retenues. Il existe des algorithmes g√©n√©tiques, qui ne sont pas couverts ici, permettent de s√©lectionner des mod√®les d'autoapprentissages optimaux. Un de ces algorithmes est offert par le module Python [`tpot`](https://epistasislab.github.io/tpot/).

### D√©ploiement
RData, Shiny

En r√©sum√©,

1. Explorer les donn√©es
1. S√©lectionner des algorithmes
1. Effectuer un pr√©traitement
1. Cr√©er un ensemble d'entra√Ænement et un ensemble de test
1. Lisser les donn√©es sur les donn√©es d'entra√Ænement avec validation crois√©e
1. Tester le mod√®le
1. D√©ployer le mod√®le

## Algorithmes

Il existe des centaines d'algorithmes d'apprentissage. Je n'en couvrirai que quatre, qui me semblent √™tre appropri√©s pour la mod√©lisation ph√©nom√©nologique des syst√®mes vivants, et utilisables pour la r√©gression et la classification.

- Les k plus proches voisins 
- Les arbres de d√©cision
- Les r√©seaux neuronaux
- Les processus gaussiens

## L'autoapprentissage en R

Plusieurs options sont disponibles.

1. Les modules que l'on retrouve en R pour l'autoapprentissage sont nombreux, et parfois sp√©cialis√©s. Il est possible de les utiliser individuellement.
1. Chacun de ces modules fonctionne √† sa fa√ßon. Le module `caret` de R a √©t√© con√ßu pour donner acc√®s √† des centaines de fonctions d'autoapprentissage via une interface commune.
1. Le module `mlr` occupe sensiblement le m√™me cr√©neau que `caret`, mais utilise plut√¥t une approche par objets connect√©s. Au moment d'√©crire ces lignes, `mlr` est peu document√©, donc *a priori* plus complexe √† prendre en main.
1. En Python, le module `scikit-learn` offre un interface unique pour l'utilisation de nombreuses techniques d'autoapprentissage. Il est possible d'appeler des fonctions de Python √† partir de R gr√¢ce au module `reticulate`.

Dans ce chapitre, nous verrons comment fonctionnent certains algorithmes s√©lectionn√©s, puis nous les appliquerons avec le module respectif qui m'a sembl√© le plus appropri√©. Vous remarquerez n√©anmoins des r√©f√©rences r√©curentes aux modules de Python. En ce moment, la force de R r√©side dans la gestion des tableaux, les tests statistiques, l'exploration heuristique et la visualisation de donn√©es. N√©anmoins, Python le surpasse pour l'autoapprentissage...

```{r}
library("tidyverse") # √©videmment
library("caret")
```

## Les *k* plus proches voisins

> [![Les voisins, une pi√®ce de Claude Meunier here](11_les-voisins.jpg)](https://youtu.be/-RpYi_Vuviw?t=6m40s)

> "Le... l'id√©e en arri√®re pour √™tre... euh... simpliste, l√† c'est que c'est un peu de... euhmm... de la vitamine de vinyle." - Geroges (Les voisins, une pi√®ce de Claude Meunier)

Pour dire comme Georges, le... l'id√©e en arri√®re des KNN pour √™tre... euh... *simpliste*, c'est que un objet va ressembler √† ce qui se trouve dans son voisinage. Les KNN se basent en effet sur une m√©trique de distance pour rechercher un nombre $k$ de points situ√©s √† proximit√© de la mesure. Les $k$ points les plus proches sont retenus, $k$ √©tant un entier non nul √† optimiser. Un autre param√®tre parfois utilis√© est la distance maximale des voisins √† consid√©rer: un voisin trop √©loign√© pourra √™tre discart√©. La r√©ponse attribu√©e √† la mesure est calcul√©e √† partir de la r√©ponse des $k$ voisins retenus. Dans le cas d'une r√©gression, on utiliser g√©n√©ralement la moyenne. Dans le cas de la classification, la mesure prendra la cat√©gorie qui sera la plus pr√©sente chez les $k$ plus proches voisins.

L'algorithme des *k* plus proches voisins est relativement simple √† comprendre. Certains pi√®ges sont, de m√™me, peuvent √™tre contourn√©s facilement. Imaginez que vous rechercher les points les plus rapproch√©s dans un syst√®me de coordonn√©es g√©ographiques o√π les coordonn√©es $x$ sont exprim√©es en m√®tres et les coodonn√©es $y$, en centim√®tres. Vous y projetez trois points.

```{r}
data <- data.frame(X = c(0, 1, 0),
                   Y = c(0, 0, 1),
                   row.names = c('A', 'B', 'C'))
options(repr.plot.width = 4, repr.plot.height = 4)
par(pty="s")
plot(data, cex=3,
     xlab = 'Position X (m)', ylab = 'Position Y (cm)')
text(data, labels = rownames(data))
```

Techniquement la distance A-B est 100 plus √©lev√©e que la distance A-C, mais l'algorithme ne se soucie pas de la m√©trique que vous utilisez. Il est promordial dans ce cas d'utiliser la m√™me m√©trique. Cette strat√©gie est √©vidente lorsque les variables sont comparables. C'est rarement le cas, que ce soit lorsque l'on compare des dimensions physionomiques (la longueur d'une phalange ou celle d'un f√©mur) mais lorsque les variables incluent des m√©langes de longueurs, des pH, des d√©comptes, etc., il est important de bien identifier la m√©trique et le type de distance qu'il convient le mieux d'utiliser. En outre, la standardisation des donn√©es √† une moyenne de z√©ro et √†un √©cart-type de 1 est une approche courrament utilis√©e.

### Exemple d'application

Pour ce premier exemple, je pr√©senterai un cheminement d'autoapprentissage, du pr√©traitement au test.

```{r}
# ionome
```

## Les arbres d√©cisionnels

![Les Ents, tir√© du film le Seigneur des anneaux](11_Entmoot.jpg)

Un arbre d√©cisionnel est une collection hi√©rarchis√©e de d√©cisions, le plus souvent binaires. Chaque embranchement est un test √† vrai ou faux sur une variable. La r√©ponse, que ce soit une cat√©gorie ou une valeur num√©rique, se trouve au bout de la derni√®re branche. Les suites de d√©cisions sont organis√©es de mani√®re √† ce que la pr√©cision de la r√©ponse soit optimis√©e.

Par exemple, ...

# Les r√©seaux neuronaux

Apr√®s les KNN et les random forests, nous passons au domaine plus complexe des r√©seaux neuronnaux. Il en existe plusieurs formes, dont la plus simple manifestation est le *perceptron multicouche*. Le terme *r√©seau neuronal* est une m√©taphore li√©e √† une perception que l'on avait du fonctionnement du cerveau humain lorsque la technique des r√©seaux neuronnaux a √©t√© d√©velopp√©e dans les ann√©es 1950. Un r√©seau neuronnal comprend une s√©rie de bo√Ætes d'entr√©es li√©e √† des fonctions qui transforment et acheminent successivement l'information jusqu'√† la sortie d'une ou plusieurs r√©ponse. Dans l'exemple suivant, on retrouve 4 variables d'entr√©e et trois variables de sortie entre lesquelles on retrouve 5 couches dont le nombre de neuronnes varient entre 3 et 6.

![](images/11_deep_neural_network.png)

Source: [Neural designer](https://www.neuraldesigner.com/)

Entre la premi√®re couche de neuronnes (les variables pr√©dictives) et la derni√®re couche (les variables r√©ponse), on retrouve des *couches cach√©es*. Chaque neuronne est reli√© √† tous les neuronnes de la couche suivante.

Les liens sont des poids, qui peuvent prendre des valeurs dans l'ensemble des nombres r√©els. √Ä chaque neuronne suivant la premi√®re couche, on fait la somme des poids multipli√©s par la sortie du neuronne. Le nombre obtenu entre dans chaque neuronne de la couche. Le neuronne est une fonction, souvent tr√®s simple, qui transforme le nombre. La fonction plus utilis√©e est probablement la fonction ReLU, pour *rectified linear unit*, qui expulse le m√™me nombre aux neuronnes de la prochaine couche s'il est positif: sinon, il expulse un z√©ro.

**Exercice**. Si tous les neuronnes sont des fonctions ReLU, calculez la sortie de ce petit r√©seau neuronal.

<img src="images/11_nn_ex1_Q.jpg" width="600px">

Vous trouverez la r√©ponse sur l'image `images/11_nn_ex1_R.jpg`.

Il est aussi possible d'ajouter un *biais* √† chaque neuronne, qui est un nombre r√©el additionn√© √† la somme des neuronnes pond√©r√©e par les poids.

L'optimisation les poids pour chaque lien et les biais pour chaque neuronne (gr√¢ce √† des algorithmes dont le fonctionnement sort du cadre de ce cours) constitue le processus d'apprentissage. Avec l'aide de logiciels et de modules sp√©cialis√©s, la construction de r√©seaux de centaines de neuronnes organis√©s en centaines de couches vous permettra de capter des patrons complexes dans des ensembles de donn√©es.

Vous avez peut-√™tre d√©j√† entendu parler d'apprentissage profond (ou *deep learning*). Il s'agit simplement d'une appellation des r√©seaux neuronnaux modernis√© pour insister sur la pr√©sence de plusieurs couches de neuronnes. C'est un terme √† la mode.

### Les r√©seaux neuronnaux sur R avec Keras

Plusieurs modules sont disponibles sur R pour l'apprentissage profond. Certains utilisent le module [H2O.ia](https://github.com/h2oai/h2o-3), propuls√© en Java, d'autres utilisent plut√¥t [Keras](https://keras.rstudio.com/), propuls√© en Python par l'interm√©diaire de tensorflow. J'ai une pr√©f√©rence pour Keras, puisqu'il supporte les r√©seaux neuronnaux classiques (perceptrons multicouche) autant que circonvutionnels ou r√©curents. Keras pourrait n√©anmoins √™tre difficile √† installer sur Windows, o√π Python ne vient pas par d√©faut. Sur Windows, Keras ne focntionne qu'avec Anaconda: vous devez donc installez [Anaconda ou Miniconda](https://www.anaconda.com/download/#windows) (Miniconda offre une installation minimaliste).

Pour installer Keras, il suffit d'installer le module (avec devtools pour obtenir la version la plus r√©cente, i.e. `devtools::install_github("rstudio/keras")`), puis de lancer la fonction `install_keras()`. Dans mon cas, j'utilise conda.

```{r}
library("keras")
#install_keras(method = "conda")
```

La fonction `install_keras()` installera keras dans un environnement virtuel nomm√© `r-tensorflow`. Si vous utilisez conda, vous y acc√©derez avec cette commande.

```{r}
use_condaenv("r-tensorflow")
```

Chargeons les donn√©es.

```{r}
abalone <- read_csv("http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data",
                    col_names = c('sex', 'length', 'diameter', 'height', 'whole.weight', 'shucked.weight', 'viscera.weight', 'shell.weight', 'rings'))
```

```{r}
set.seed(846368)
abal_tr_index <- createDataPartition(abalone$sex, p = 0.75, list = FALSE)

x <- abalone %>% select(-sex) %>% as.matrix()
x_tr <- x[abal_tr_index, ]
x_te <- x[-abal_tr_index, ]

y_num <- as.numeric(as.factor(abalone$sex)) - 1
y <- to_categorical(y_num)
y_tr <- y[abal_tr_index, ]
y_te <- y[-abal_tr_index, ]

keras_model <- keras_model_sequential() 
keras_model %>% 
  layer_dense(units = 256, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256 * 2, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256 * 4, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256 * 4, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256 * 2, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 256, activation = 'relu', input_shape = ncol(x)) %>% 
  layer_dropout(rate = 0.2) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dense(units = 3, activation = 'softmax')

keras_model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics = c('accuracy')
)

history <- keras_model %>% fit(
  x_tr, y_tr, 
  epochs = 50, batch_size = 128, 
  validation_split = 0.25
)

plot(history)
```

```{r}
keras_model %>% evaluate(x_te, y_te)
```


```{r}
pred_te <- keras_model %>% predict_classes(x_te)
pred_te[pred_te == 0] <- 'F'
pred_te[pred_te == 1] <- 'I'
pred_te[pred_te == 2] <- 'M'

confusionMatrix(factor(abalone$sex[-abal_tr_index]),
                factor(pred_te))
```

### Pour aller plus loin

En une heure divis√©e en [4 vid√©os](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi), Grant Sanderson explique les r√©seaux neuronaux de main√®re intuitive. En ce qui a trait √† Keras, je recommande le livre [Deep learning with R, de Fran√ßois Allaire](https://www.safaribooksonline.com/library/view/deep-learning-with/9781617295546/?ar), auquel vous avez acc√®s avec un IDUL de l'Universit√© Laval. Si vous vous sentez √† l'aise √† utiliser Keras avec le langage Python, je vous recommande le cours gratuit en ligne [*Applications of deep neural networks*, de Jeff Heaton](https://www.youtube.com/watch?v=sRy26qWejOI&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN).

Des types de r√©seaux neuronnaux sp√©cialis√©s ont √©t√© d√©velopp√©s. Je les pr√©sente sans aller dans les d√©tails.

- **R√©seaux neuronnaux convolutif**. Ce type de r√©seau neuronal est surtout utilis√© en reconnaissance d'image. Les couches de neurones convolutifs poss√®dent, en plus des fonctions des perceptrons classiques, des filtres permettant d'int√©grer les variables descriptives connexes √† l'observation: dans le cas d'une image, il s'agit de scanner les pixels au pourtour du pixel trait√©. [Une br√®ve introduction sur Youtube](https://www.youtube.com/watch?v=YRhxdVk_sIs).
- **R√©seaux neuronnaux r√©curents**. Pr√©dire des occurences futures √† partir de s√©ries temporelles implique que la r√©ponse au temps t d√©pend non seulement de conditions externes, mais aussi le la r√©ponse au temps t-1. Les r√©seaux neuronnaux r√©curents. Vous devrez ajouter des neuronnes particuliers pour cette t√¢che, qui pourra √™tre pris en charge par Keras gr√¢ce aux couches de type [*Long Short-Term Memory network*, ou LSTM](https://www.youtube.com/watch?v=UnclHXZszpw).
- **R√©seaux neuronnaux probabilistes**. Les r√©seaux neuronnaux non-probabilistes offre une estimation de la variable r√©ponse. Mais quelle est la cr√©dibilit√© de la r√©ponse selon les variables descriptives? Question qui pourrait se r√©v√©ler crutiale en m√©decine ou en ing√©nierie, √† la laquelle on pourra r√©pondre en mode probabiliste. Pour ce faire, on pose des distributions *a priori* sur les poids du r√©seau neuronal. Le module [`edward`](http://edwardlib.org/), programm√© et distribu√© en Python, offre cette possibilit√©. Vous pourrez acc√©der √† `edward` gr√¢ce au module `reticulate`, mais √† ce stade mieux vaudra basculer en Python. Pour en savoir davantage, consid√©rez [cette conf√©rence de Andrew Rowan](https://www.youtube.com/watch?v=I09QVNrUS3Q).

# Les processus gaussiens

Les sorties des techniques que sont les KNN, les arbres ou les for√™ts ainsi que les r√©seaux neuronaux sont (classiquement) des nombres r√©els ou des cat√©gories. Dans les cas o√π la cr√©dibilit√© de la r√©ponse est importante, il devient pertinent que la sortie soit probabiliste: les pr√©dictions seront alors pr√©sent√©es sous forme de distributions de probabilit√©. Dans le cas d‚Äôune classification, la sortie du mod√®le sera un vecteur de probabilit√© qu‚Äôune observation appartienne √† une classe ou √† une autre. Dans celui d‚Äôune r√©gression, on obtiendra une distribution continue.

Les **processus gaussiens** tirent profit des statistiques bay√©siennes pour effectuer des pr√©dictions probabilistes. D‚Äôautres techniques peuvent √™tre utilis√©es pour effectuer des pr√©dictions probabilistes, comme les [r√©seaux neuronaux probabilistes](http://edwardlib.org/iclr2017), que j'ai intruduits pr√©c√©demment.

Bien que les processus gaussiens peuvent √™tre utilis√©s pour la classification, son fonctionnement s'explique favorablement, de mani√®re intuitive, pas la r√©gression.

## Un approche intuitive

Ayant acquis de l'exp√©rience en enseignement des processus gaussiens, [John Cunningham](http://stat.columbia.edu/~cunningham/) a d√©velopp√© une approche intuitive permettant de saisir les m√©canismes des processus gaussiens. lors de conf√©rences disponible sur YouTube ([1](https://youtu.be/BS4Wd5rwNwE), [2](https://www.youtube.com/watch?v=Jv25sg-IYHU)), il aborde le sujet par la n√©cessit√© d'effectuer une r√©gression non-lin√©aire.

G√©n√©rons d'abord une variable pr√©dictive `x`, l'heure, et une variable r√©ponse `y`, le rythme cardiaque d'un individu en battements par minute (bpm).

```{r}
x <- c(7, 8, 10, 14, 17)
y <- c(61, 74, 69, 67, 78)

plot(x, y, xlab="Heure", ylab="Rythme cardiaque (bpm)")
abline(v=12, lty=3, col='gray50');text(12, 67, '?', cex=2)
abline(v=16, lty=3, col='gray50');text(16, 72, '?', cex=2)
```

Poser un probl√®me par un processus gaussien, c'est se demander les valeurs cr√©dibles qui pourraient √™tre obtenues hors du domaine d'observations (par exemple, dans la figure ci-dessus, √† `x=12` et `x=16`)? Ou bien, de mani√®re plus g√©n√©rale, *quelles fonctions ont pu g√©n√©rer les variables r√©ponse √† partir d'une structure dans les variables pr√©dictrices?*

Les distributions normales, que nous appellerons *gaussiennes* dans cette section par concordance avec le terme *processus gaussien*, sont particuli√®rement utiles pour r√©pondre √† cette question.

Nous avons vu pr√©c√©demment ce que sont les distributions de probabilit√©: des outils math√©matiques permettant d'appr√©hender la structure des processus al√©atoires. Une distribution gaussienne repr√©sente une situation o√π l'on tire au hasard des valeurs continues. Une distribution gaussienne de la variable al√©atoire $X$ de moyenne $0$ et de variance de $1$ est not√©e ainsi:

$$ X \sim \mathcal{N} \left( 0, 1\right)$$

Par exemple, une courbe de distribution gaussienne du rythme cardiaque √† 7:00 pourrait prendre la forme suivante.

$$ bpm \sim \mathcal{N} \left( 65, 5\right)$$

En `R`:

```{r}
x_sequence <- seq(50, 80, length=100)
plot(x_sequence,
     dnorm(x_sequence, mean=65, sd=5),
     type="l",
    xlab="Rythme cardiaque (bpm)",
    ylab="Densit√©")
```

Une distribution **bi**normale, un cas particulier de la distribution **multi**normale, comprendra deux vecteurs, $x_1$ et $x_2$. Elle aura donc deux moyennes. Puisqu'il s'agit d'une distribution biormale, et non pas deux distributions normales, les deux variables ne sont pas ind√©pendantes et l'on utilisera une matrice de coraviance au lieu de deux variances ind√©pendantes.

$$
\binom{x_1}{x_2} \sim \mathcal{N}
\Bigg( 
\binom{\mu_1}{\mu_2},
\left[ {\begin{array}{cc}
\Sigma_{x_1} & \Sigma_{x_1,x_2} \\
\Sigma_{x_1,x_2}^T & \Sigma_{x_2} \\
\end{array} } \right]
\Bigg)
$$

La matrice $\Sigma$, dite de *variance-covariance*, indique sur sa diagonale les variances des variables ($\Sigma_{x_1}$ et $\Sigma_{x_2}$). Les covariances $\Sigma_{x_1,x_2}$ et $\Sigma_{x_1,x_2}^T$ sont sym√©triques et indiquent le lien entre les variables.

On pourrait supposer que le rythme cardiaque √† 8:00 soit corr√©l√© avec celui √† 7:00. Mises ensembles, les distriutions gaussiennes √† 7:00 et √† 8:00 formeraient une distribution gaussienne binormale.

$$
\binom{bpm_7}{bpm_8} \sim \mathcal{N}
\Bigg( 
\binom{65}{75},
\left[ {\begin{array}{cc}
10 & 6 \\
6 & 15 \\
\end{array} } \right]
\Bigg)
$$

En `R`:

```{r}
library("ellipse")
means_vec <- c(65, 75)
covariance_mat <- matrix(c(10, 6, 6, 15), ncol=2)
par(pty='s')
plot(ellipse(x=covariance_mat, centre=means_vec, levels=0.95), 
     type='l',
     xlab="Rythme cardiaque √† 7:00 (bpm)",
     ylab="Rythme cardiaque √† 8:00 (bpm)")
#lines(ellipse(x=covariance_mat, centre=means_vec, level=0.8))
```

On peut se poser la question: √©tant donn√©e que $x_1 = 68$, quelle serait la distribution de $x_2$? Dans ce cas bivari√©e, la distribution marginale serait univari√©e, mais dans le cas multivari√© en $D$ dimensions, la distribution marginale o√π l'on sp√©cifie $m$ variables serait de $D-m$. de  Une propri√©t√© fondamentale d'une distribution gaussienne est que peu importe l'endroit o√π l'angle selon lequel on la tranche, la distribution marginale sera aussi gaussienne. Lorsque l'on retranche une ou plusieurs variables en sp√©cifiant la valeur qu'elles prennent, on applique un *conditionnement* √† la distribution.

```{r}
library("condMVNorm")

condition_x1 <- 61 # changer ce chiffre pour visualiser l'effet

cond_parameters <- condMVN(mean=means_vec, sigma=covariance_mat,
                           dependent=2, given=1, X.given=condition_x1)
cond_mean <- cond_parameters$condMean
cond_sd <- sqrt(cond_parameters$condVar)
x2_sequence <- seq(50, 90, length=100)
x2_dens <- dnorm(x2_sequence, mean=cond_mean, sd=cond_sd)

par(pty='s')
plot(ellipse(x=covariance_mat, centre=means_vec, levels=0.95), type='l',
     xlab="Rythme cardiaque √† 7:00 (bpm)",
     ylab="Rythme cardiaque √† 8:00 (bpm)")
abline(v=condition_x1, col='#f8ad00', lwd=2, lty=2)
lines(x=condition_x1 + x2_dens*40, y=x2_sequence, col="#f8ad00", lwd=2)
lines(x = c(condition_x1, condition_x1),
      y = c(cond_mean-cond_sd, cond_mean+cond_sd),
     lwd=3, col='#00aaf2')
points(condition_x1, cond_mean, 
       col='#00aaf2', pch=16, cex=2)

n_sample <- 20
points(x = rep(condition_x1, n_sample),
      y = rnorm(n_sample, cond_mean, cond_sd),
      pch=4)
```

Les points sur l'axe (symbole x) conditionn√©s sont des √©chantillons tir√©s au hasard dans la distribution conditionn√©e.

Une autre mani√®re de visualiser la distribution gausienne binormale est de placer $x_1$ et $x_2$ c√¥te √† c√¥te en abcisse, avec leur valeur en ordonn√©e. Le bloc de code suivant peut sembler lourd au premier coup d'oeil: pas de panique, il s'agit surtout d'instructions graphiques. Vous pouvez vous amuser √† changer les param√®tres de la distribution binormale (section 1) ainsi que la valeur de $x_1$ √† laquelle est conditionn√©e la distribution de $x_2$ (section 2).

```{r}
source("lib/plot_matrix.R")

# 1. Distribution
means_vec <- c(65, 65)
covariance_mat <- matrix(c(10, 6, 6, 15), ncol=2)

# 2. Condition
condition_x1 <- 61 # changer ce chiffre pour visualiser l'effet

# 3. Densit√© conditionn√©e
cond_parameters <- condMVN(mean=means_vec, sigma=covariance_mat,
                           dependent=2, given=1, X.given=condition_x1)
cond_mean <- cond_parameters$condMean
cond_sd <- sqrt(cond_parameters$condVar)
x2_sequence <- seq(50, 90, length=100)
x2_dens <- dnorm(x2_sequence, mean=cond_mean, sd=cond_sd)
x2_draw <- rnorm(1, cond_mean, cond_sd)

# 4. Graphiques
options(repr.plot.width = 8, repr.plot.height = 5)
layout(matrix(c(1,2,3,3), nrow=2), widths=c(1,2))
par(mar=c(4, 4, 1, 1), pty='s')

## 4.1 Ellipse
plot(ellipse(x=covariance_mat, centre=means_vec, levels=0.95), 
     type='l', xlab="BPM √† 7:00", ylab="BPM √† 8:00")
abline(v=condition_x1, col='#f8ad00', lwd=1)
lines(x=condition_x1 + x2_dens*40, y=x2_sequence, col="#f8ad00", lwd=1)
lines(x = c(condition_x1, condition_x1),
      y = c(cond_mean-cond_sd, cond_mean+cond_sd),
     lwd=2, col='#00aaf2')
points(condition_x1, cond_mean, 
       col='#00aaf2', pch=16, cex=1)
points(condition_x1, x2_draw, pch=16, col="#ff7998")

## 4.2 Covariance
plot_matrix(covariance_mat)

## 4.3 S√©rie
plot(c(1, 2), c(condition_x1, x2_draw), xlim=c(0, 6), ylim=c(55, 75), type='l',
    xlab="Indice de la variable", ylab="Rythme cardiaque (bmp)")
points(1, condition_x1, pch=16, col='#00aaf2', cex=3)
points(2, x2_draw, pch=16, col='#ff7998', cex=3)
```

Les valeurs que peuvent prendre le rythme cardiaque en $x_2$ sont tir√©es al√©atoirement d'une distribution conditionn√©e. Sautons maintenant au cas multinormal, incluant 6 variables (*hexanormal*!). Afin d'√©viter de composer une matrice de covariance √† la mitaine, je me permets de la g√©n√©rer avec une fonction. Cette fonction particuli√®re est nomm√©e *fonction de base radiale* ou *exponentiel de la racine*.

$$K_{RBF} \left( x_i, x_j \right) = \sigma^2 exp \left( -\frac{\left( x_i - x_j \right)^2}{2 l^2}  \right) $$

```{r}
RBF_kernel <- function(x, sigma, l) {
    n <- length(x)
    k <- matrix(ncol = n, nrow = n)
    for (i in 1:n) {
        for (j in 1:n) {
            k[i, j] = sigma^2 * exp(-1/(2*l^2) * (x[i] - x[j])^2)
        }
    }
    colnames(k) <- paste0('x', 1:n)
    rownames(k) <- colnames(k)
    return(k)
}
```

Dans la fonction `RBF_kernel`, `x` d√©signe les dimensions, `sigma` d√©signe un √©cart-type commun √† chacune des dimensions et `l` est la longueur d√©signant l'amplification de la covariance entre des dimensions √©loign√©es (dans le sens que la premi√®re dimension est √©loign√©e de la derni√®re). Pour 6 dimensions, avec un √©cart-type de 4 et une longueur de 2.

```{r}
covariance_6 <- RBF_kernel(1:6, sigma=4, l=2)
round(covariance_6, 2)
```

Changez la valeur de `l` permet de bien saisir son influence sur la matrice de covariance. Avec un `l` de 1, la covariance entre $x_1$ et $x_6$ est pratiquement nulle: elle est un peut plus √©lev√©e avec `l=2`. Pour reprendre l'exemple du rythme cardiaque, on devrait en effet s'attendre √† retrouver une plus grande corr√©lation entre celles mesur√©es aux temps 4 et 5 qu'entre les temps 1 et 6.

De m√™me que dans la situation o√π nous avions une distribution binormale, nous pouvons conditionner une distribution multinormale. Dans l'exemple suivant, je conditionne la distribution multinormale de 6 dimensions en sp√©cifiant les valeurs prises par les deux premi√®res dimensions. Le r√©sultat du conditionnement est une distribution en 4 dimensions. Puisqu'il est difficile de pr√©senter une distribution en 6D, le graphique en haut √† gauche ne comprend que les dimensions 1 et 6. Remarquez que la corr√©lation entre les dimensions 1 et 6 est faible, en concordance avec la matrice de covariance g√©n√©r√©e par la fonction `RBF_kernel`. Lancez plusieurs fois le code et voyez ce qui advient des √©chantillonnages dans les dimensions 3 √† 6 selon le conditionnement en 1 et 2.

```{r}
library("MASS")

# 1. Distribution
means_vec <- rep(65, 6)
covariance_mat <- covariance_6

# 2. Condition
conditions_x <- c(61, 74) # changer ces chiffres pour visualiser l'effet

# 3. Densit√© conditionn√©e
cond_parameters <- condMVN(mean=means_vec, sigma=covariance_mat, 
        dependent.ind = 3:6, given.ind=1:2,
        X.given=conditions_x)
cond_mean <- cond_parameters$condMean
cond_sd <- sqrt(cond_parameters$condVar)
x6_sequence <- seq(50, 90, length=100)
x6_dens <- dnorm(x2_sequence, mean=cond_mean[4], sd=cond_sd[4, 4])

x_3.6_draw <- mvrnorm(n = 1, mu = cond_mean, Sigma = cond_sd^2)

# 4. Graphiques
options(repr.plot.width = 8, repr.plot.height = 5)
layout(matrix(c(1,2,3,3), nrow=2), widths=c(1,2))
par(mar=c(4, 4, 1, 1))

## 4.1 Ellipse
plot(ellipse(x=covariance_mat[c(1, 6), c(1, 6)], centre=means_vec[c(1, 6)], levels=0.95), 
     type='l', xlab="BPM √† 7:00", ylab="BPM √† 8:00")
abline(v=conditions_x[1], col='#f8ad00', lwd=1)
lines(x=condition_x1 + x6_dens*40, y=x2_sequence, col="#f8ad00", lwd=1)
lines(x = c(conditions_x[1], conditions_x[1]),
      y = c(cond_mean[4]-cond_sd[4, 4], cond_mean[4]+cond_sd[4, 4]),
     lwd=2, col='#00aaf2')
points(conditions_x[1], cond_mean[4],
       col='#00aaf2', pch=16, cex=1)
points(conditions_x[1], x_3.6_draw[4], pch=16, col="#ff7998")

## 4.2 Covariance
plot_matrix(covariance_mat, cex=0.8)

## 4.3 S√©rie
plot(1:6, c(conditions_x, x_3.6_draw), xlim=c(0, 6), ylim=c(60, 85), type='l',
    xlab="Indice de la variable", ylab="Rythme cardiaque (bmp)")
points(c(1, 2), conditions_x, pch=16, col='#00aaf2', cex=3)
points(3:6, x_3.6_draw, pch=16, col='#ff7998', cex=3)
```

La structure de la covariance assure que les dimensions proches prennent des valeurs similaires, assurant une courbe lisse et non en dents de scie. Pourquoi s'arr√™ter √† 6 dimensions? Prenons-en plusieurs.

```{r}
# 1. Distribution
n <- 20
means_vec <- rep(65, n)
covariance_mat <- RBF_kernel(x = 1:n, sigma = 10, l = 2)

# 2. Condition
conditions_x <- c(61, 74) # changer ces chiffres pour visualiser l'effet

# 3. Densit√© conditionn√©e
cond_parameters <- condMVN(mean=means_vec, sigma=covariance_mat, 
        dependent.ind = 3:n, given.ind=1:2,
        X.given=conditions_x)
cond_mean <- cond_parameters$condMean
cond_sd <- cond_parameters$condVar
x_3.n_draw <- mvrnorm(n = 1, mu = cond_mean, Sigma = cond_sd)

# 4. Graphiques
options(repr.plot.width = 5, repr.plot.height = 4)
par(mar=c(4, 4, 1, 1))

## 4.3 S√©rie
plot(1:n, c(conditions_x, x_3.n_draw), xlim=c(0, n), ylim=c(40, 90), type='l',
    xlab="Indice de la variable", ylab="Rythme cardiaque (bmp)")
points(c(1, 2), conditions_x, pch=16, col='#00aaf2', cex=1)
points(3:n, x_3.n_draw, pch=16, col='#ff7998', cex=1)
```

On pourrait calculer analytiquement la distribution des points qui suivent les deux points conditionn√©s. Mias lan√ßons plut√¥t des simulations.

```{r}
x_3.n_draw <- mvrnorm(n = 1000, mu = cond_mean, Sigma = cond_sd)
means_draw <- apply(x_3.n_draw, 2, mean)
sd_draw <- apply(x_3.n_draw, 2, sd)

plot(1:n, c(conditions_x, means_draw), xlim=c(0, n), ylim=c(40, 90), type='l',
    xlab="Indice de la variable", ylab="Rythme cardiaque (bmp)")
points(c(1, 2), conditions_x, pch=16, col='#00aaf2', cex=1)
points(3:n, means_draw, pch=16, col='#ff7998', cex=1)
for (i in 1:(n-2)) {
    lines(c(i+2, i+2), c(means_draw[i] - sd_draw[i], 
                         means_draw[i] + sd_draw[i]),
         col = "#ff7998")
}
```

Revenons au rythme cardiaque. On pourra utiliser le conditionnement aux temps observ√©s, soit 7:00, 8:00, 10:00, 14:00 et 17:00 pour estimer la distribution √† 12:00 et 16:00, o√π √† des dimensions artificielles quelconques ici fix√©es aux demi-heures.

```{r}
# 1. Distribution
n <- 21
means_vec <- rep(65, n)
covariance_mat <- RBF_kernel(x = 1:n, sigma = 5, l = 2)

# 2. Condition
conditions_x <- c(61, 74, 69, 67, 78)
conditions_indices <- c(1, 3, 7, 15, 21)
dependent_indices <- (1:20)[! 1:20 %in% conditions_indices]

# 3. Densit√© conditionn√©e
cond_parameters <- condMVN(mean=means_vec, sigma=covariance_mat, 
                           dependent.ind = dependent_indices,
                           given.ind=conditions_indices,
                           X.given=conditions_x)
cond_mean <- cond_parameters$condMean
cond_sd <- cond_parameters$condVar
x_draw <- mvrnorm(n = 500, mu = cond_mean, Sigma = cond_sd)
means_draw <- apply(x_draw, 2, mean)
sd_draw <- apply(x_draw, 2, sd)

# 4. Graphiques
options(repr.plot.width = 5, repr.plot.height = 4)
par(mar=c(4, 4, 1, 1))

bpm <- rep(NA, n)
bpm[conditions_indices] <- conditions_x
bpm[dependent_indices] <- means_draw


## 4.3 S√©rie
plot(1:n, bpm, xlim=c(0, n), ylim=c(40, 90), type='l',
    xlab="Indice de la variable", ylab="Rythme cardiaque (bmp)")
points(conditions_indices, bpm[conditions_indices], pch=16, col='#00aaf2', cex=1)
points(dependent_indices, bpm[dependent_indices], pch=16, col='#ff7998', cex=1)

for (i in 1:length(sd_draw)) {
    lines(c(dependent_indices[i], dependent_indices[i]),
          c(means_draw[i] - sd_draw[i], 
            means_draw[i] + sd_draw[i]),
         col = "#ff7998")
}
```

Comme on devrait s'y attendre, la r√©gression r√©sultant de la mise en indices de la distribution est pr√©cise aux mesures, et impr√©cise aux indices peu garnies en mesures. Nous avions utilis√© 21 dimensions. **Lorsque l'on g√©n√©ralise la proc√©dure √† une quantit√© infinie de dimensions, on obtient un *processus gaussien*.** 

![](https://media.giphy.com/media/12R2bKfxceemNq/giphy.gif)

L'indice de la variable devient ainsi une valeur r√©elle. Un processus gaussien, $\mathcal{GP}$, est d√©fini par une fonction de la moyenne, $m \left( x \right)$, et une autre de la covariance que l'on nomme *noyau* (ou *kernel*), $K \left( x, x' \right)$. Un processus gaussien est not√© de la mani√®re suivante:

$$\mathcal{GP} \sim \left( m \left( x \right), K \left( x, x' \right) \right)$$

La fonction d√©finissant la moyenne peut √™tre facilement √©cart√©e en s'assurant de normaliser la variable r√©ponse. Par convention, on sp√©cifie une fonction de moyenne comme retournant toujours un z√©ro. Quant au noyau, il peut prendre diff√©rentes formes. De plus ces formes peuvent √™tre combin√©es. R√®gle g√©n√©rale, on utilisera un noyau permettant de d√©finir deux param√®tres: la hauteur ($\sigma$) et la longueur de l'ondulation ($l$).

```{r}
# Faites varier ces param√®tres
SIGMA <- 3
L <- 5

# Graphique
n <- 100
sample <- mvrnorm(n = 1, mu = rep(0, n), 
                  Sigma = RBF_kernel(x=1:n, sigma = SIGMA, l = L))
plot(1:n, sample, type='l', ylim=c(-10, 10))
```

On pourra ajouter √† ce noyau un bruit blanc, c'est-√†-dire une variation purement al√©atoire, sans covariance (noyau g√©n√©rant une matrice diagonale).

Le noyau devient ainsi un *a priori*, et le processus gaussien conditionn√© aux donn√©es devient un *a posteriori* probabiliste.

Finalement, les processus gaussiens peuvent √™tre extrapol√©s √† plusieurs variables descriptives.

### Les processus gaussiens en `R`

Pas de souci, vous n'aurez pas √† programmer vos propres fonctions pour lancer des processus gaussiens. Vous pourrez [passer par `caret`](https://topepo.github.io/caret/train-models-by-tag.html#gaussian-process). Vous pourriez, comme c'est le cas avec les r√©seaux neuronnaux, obtenir davantage de contr√¥le sur l'autoapprentissage en utilisant directement la fonction `gp` du package [`gpe`](https://github.com/goldingn/gpe). Mais ce module n'est pas tout √† fait au point. Il reste utile pour se familiariser avec les processus gaussiens.

# UTILISER KERNLAB

```{r}
library("gpe")
x <- c(7, 8, 10, 14, 17)
y <- c(61, 74, 69, 67, 78)
y_sc <- (y - mean(y)) / sd(y)

m <- gp(y ~ rbf('x', sigma = 1, l = 1), data = data.frame(x, y = y_sc), 
        family = gaussian)

x_seq <- seq(min(x), max(x), length = 500)
pred_df <- data.frame(x = x_seq)
y_sc_pred <- predict(m, pred_df, type = 'response', sd = TRUE)
y_pred_m <- y_sc_pred$fit * sd(y) + mean(y)
y_pred_sd <- y_sc_pred$sd * sd(y)

plot(x, y, xlab="Heure", ylab="Rythme cardiaque (bpm)")

lines(x_seq, y_pred_m)
lines(x_seq,  y_pred_m + y_pred_sd, col="red")
lines(x_seq,  y_pred_m - y_pred_sd, col="red")

abline(v=12, lty=3, col='gray50');text(12, 67, '?', cex=2) # üòé
abline(v=16, lty=3, col='gray50');text(16, 72, '?', cex=2) # üòé
```

### Application pratique

Les processus gaussiens sont utiles pour effectuer des pr√©dictions sur des ph√©nom√®ne sur lesquels on d√©sire √©viter de se commettre sur la structure. Les s√©ries temporelles ou les signaux spectraux en sont des exemples. Aussi, j'ai utilis√© les processus gaussiens pour mod√©liser des courbes de r√©ponse aux fertilisants.

EXEMPLE...

Pr√©diction spatiale:
- https://www.sciencedirect.com/science/article/pii/S2211675316300033
- https://stackoverflow.com/questions/43618633/multi-output-spatial-statistics-with-gaussian-processes





